最近工作上在考虑换组的事情，所以这段时间利用一些闲暇的功夫浏览了three的一部分源码，大致对整个体系有了一个粗略的了解。在这里总结一下

## 场景及物体的表示

three中，和一般3d软件的场景描述一致，使用[场景图](https://en.wikipedia.org/wiki/Scene_graph)。具体到实现，其实整个场景是一颗树，树的节点都是继承了core/object3d的一些对象，比如group，或者具体的物体比如mesh。scene也继承了object3d，根节点就是scene对象。

如果是具体的物体，例如mesh，主要的成员还会有这个mesh的geometery，存储几何形状的描述，和material存储材质的描述，这两个属性基本就定义了这个mesh到底是什么样子的。另一堆有重要意义的成员是描述这整个mesh在他自己的物体本地空间内的变换情况（transform），比如position啊，rotation啊，scale这种。这些信息和几何形状是相分离的，当你对整个mesh做这样的操作，并不是说要去改变这个mesh对应geometery的各个顶点。而是整体定义transform的信息。这样，不仅transform的信息便可以单独维护了，而且整个transform最后可以表述一个tranform matrix，所以可以直接在gpu中高效实现。这让我很好理解为什么使用3d软件创建一个物体，也会单独的罗列这些transform信息。 在像mesh这种对象上，还可以指定很底层的drawmode，执行光线相交检测的逻辑也是在这里。

## 几何描述

three中，表述物体形状的主要有geometry和bufferGeometery两个基类，另外还有一个中间对象叫directGeometery用来在他们中间做转化时临时生成。这两个基类的关系我并不是很确定，姑且说下我现在的理解。geometry和bufferGeometery最主要的区别在于存储数据的方式。我们知道，最后喂给gpu的数据是typedArray的buffer，bufferGeometry的数据就是以typedArray来存的，所以bufferGeometry有更好的渲染性能，不需要再去生成buffer格式的数据。geometry则是将那些顶点啊放在普通的list里，这个好处是它可以很容易的被动态修改。所以bg的渲染开销小，g的渲染开销大，bg的修改开销大，g的修改开销小。

细看的话，geometery中不仅有顶点数组，还有顶点颜色数组，面片数组，支持多套uv，每套uv是一个纹理坐标数组。在面片数组中，基本的单元是core/face3，描述了基本的三角面片，包括顶点索引，面法线方向，顶点法线方向数组，顶点颜色数组，当然还有材质id。所以geometry描述的信息非常多，支持多套纹理贴图映射支持多种材质。在bufferGeometry中，这些信息被合并成多个typedArray buffer，存储在一个hashmap中，基本单元是bufferAttribute以及interleavedBufferAttribute的派生类。前者派生出诸如float64BufferAttributr，float32BufferAttributr... 等具体格式的buffer容器。interleavedBufferAttribute则本身继承了interleavedBuffer，这个有没有interleave的其实还是存储格式的区别，似乎是能够将多种格式的buffer interleave成一个buffer。最后，bufferGeometry，interleavedBuffer，bufferAttribute各自又派生出instanced前缀的东西，什么instancedBufferGeometry，我理解应该是可以实例化的意思。不同的bufferGeometry可以公用一个buffer实例，这样做一方面有存储的考虑，另一方面似乎可以通过一个叫ANGLE_instanced_arrays的webgl扩展做渲染优化。bufferGeometry还分为indexed和没有indexed，区别就是有没有面片索引。

在这两个基类上，各自派生出各种特定的geometry和bufferGeometry，比如球啊，盒子啊，它们重用了基类的方法也可以相互转换。除了基类描述具体顶点面片的底层数据，它们还会有更高级别的几何描述，比如球体中球的半径，球的经纬的分段数，有了这些属性再去计算创建实际的三角形和顶点位置等相对底层的数据。最后渲染时再生成并缓存buffer格式的数据交给gpu。

## 材质描述

这部分有点复杂，我会日后单独扩充这部分的内容。还是简略的描述一下我目前所知道的一些东西。

所有材质的基类是Material，这个基类上面挂满了描述渲染的各种参数，需要全部理清楚应该是对整个渲染了解非常透彻才可以。alpha，深度相关的，混合相关的设置，裁剪相关的设置，面的可见性，着色精度，是否接受光照雾效的信息全部都在这个基类上面。然后在这个基础上派生的各种具体材质，比如meshBasicMaterial等，还有一堆各种贴图的属性，ao贴图，反射贴图，凹凸贴图，你能想到的贴图，以及具体的材质特性相关的属性。这些贴图的属性，都是textutre对象，也是不少东西。

## 渲染过程

three有多个渲染器，功能支持最全的也是最重要的毫无疑问就是webglrenderer。webglrenderer有2600多行，以前的版本超过6000行，现在代码被拆散到renderers/webgl下的十几个文件里。几乎每个文件和webglrenderer有关系，所以看的很伤。这应该是我第一次看成规模的开源项目源码，也是对我检索和概念构建能力的锻炼。

gl是个状态机，管理底层渲染状态的是成员变量state，webglState的实例。properties：webglProperties是一个缓存对象的容器，用来集中管理和缓存material的buffer数据。webglrenderer以及一堆东西设计了一套丰富的缓存体系，基本上看起来做到了顶层数据不修改，底层渲染所需数据直接用缓存的优化。这些缓存容器基本都是hashmap，其实就是基本的js键值对对象，键的名字一般就是对应对象uuid的组合，反正就是保证这个场景下的唯一性。renderStates主要是光源信息的缓存，容器是webglrenderStates，缓存逐相机+场景，map中的是webglRenderState，然后它下面还会有lightArray hashmap到webglLights对象，最后最底层uniformCache来管实际数据，提供了不同粒度的缓存机制。webglObjects主要做实际geometery的管理和缓存，底下有webglGeometries，再底下还有webglAttributes，这才是实际存attribute buffer的地方。还有一个重要的容器是和渲染紧密相关的，renderList队列。渲染的基本过程就是，把当前帧需要画的东西放到这个list里，然后遍历它就ok了！ 这个renderlist是webglRenderLists对象，所以其实和前面renderStates一样，也是一个缓存体系。底下有wbglRenderList，里边实际存在renderitem数组里。three使用经典的深度遮挡检测，了解这个原理的同学知道，需要区分物体是否透明走两个pass才能得到正确结果，所以在list的准备阶段，会再分两个有无透明度的list，两个都会做排序。排序的比较函数也设计的比较巧妙，尽可能的减少了渲染状态的切换，并最后以深度来排。具体在准备这个renderList的时候。还会做视锥的剔除等操作。

最核心的渲染是一个render方法。先更新和获取光照的buffer，然后准备renderlist。前面提到在renderList的准备过程中，无论是视锥剔除，还是z深度的计算。这部分的逻辑在projectObject方法里，递归遍历场景图，更新geometry，更新transform matrix，视锥剔除，以物体包围盒中心计算深度，准备并排序renderList。project完成后。我们就可以遍历list来渲染了。

每个list，用renderObjects方法渲染。renderOBjects会调用renderObject渲染单个的物体。物体也是在这里变换到屏幕空间的。最后，调用renderBufferDirect，通过调用setProgram设置当前渲染物体的材质对应的program和uniform，实际负责渲染的是bufferRenderer和indexedBufferRenderer，根据bufferGeometry有没有indexed来区分，同时根据object的类型指定渲染模式，就是最底层的gl-Trangle这种。然后在根据geometry是不是instanced来决定调用renderer的哪个方法。在bufferRenderer中还会记录诸如drawcall和顶点数之类的统计信息。

setProgram里边也是一大堆逻辑和缓存的机制。由于对材质部分的理解不充分，我只能简要的提一下。主要1是判断当前renderObject的material类型有没有变化，如果变化了就调用initMatrial来另一个gl program的缓存体系中获取或创建这个材质对应的program，然后更新材质参数的uniform的buffer。programs的缓存设计也有三层，webglPrograms和webglProgram以及WebGLUniforms，主要的着色器编译链接的逻辑都在webglProgram。three会为每一种material写各自对应的顶点和片元着色器。然后公用的部分比如某种贴图的支持，会提取出来。然后也有一部分着色器代码是通用的，还有一部分着色器是必须的prefix，做一些全局的设置。然后这些着色器片段都会在webglProgram中凭借，公用部分的shader靠three自己实现了#include 和循环展开的编译指令，另外还有写死光源数目的优化。。webglUniforms应该就是维护unifrom的buffer以及location啊这些，有待我再细看下去。

## 场景的导入导出

three和场景相关的对象都有toJSON方法，以实现整个场景的序列化导出。导出时会传递一个meta对象用来收集诸如geometry，texture，image等相互引用的资源。使得同一份引用不会有多份冗余的导出。geometry对应的大量顶点数组是直接导出成json，image是通过canvas来转化成dataurl，无论图片多大也是这样做的。使用objectloader，可以从导出的json数据实现反序列化，由于相引用的资源只保存了一份，所以相引用的关系也直接被还原了回来。

如果你自己扩展了一种东西，比如扩展了mesh，geometry，material等，如果你需要继续使用three的序列化导出，你需要在你的自己的东西上实现toJSON方法。同时，由于objectloader没有提供支持外部对象的反序列化接口（我认为是three的设计缺陷），所以你需要修改或者patch objectloader的相关parse以接入你自己物体的构造过程。

three还有针对标准的数据交换格式gltf的导出，但是由于spec的原因，所以几乎无法扩展，材质的支持也很有限。

## 其他

上述的若干仅仅连three的核心渲染过程也没有囊括完，还有更多的代码支撑了这些。好在three的代码分布很规整，了解了核心过程对于其他的无论是具体功能还是工具库都能快速入手。

这些整理大概耗费了我接近半月的业余时间，看的差不多就开始准备自己搞了。我也会继续更新完善勘误下去，欢迎高手斧正错漏指点迷津。

<img src="{#base#}aa568d6f7a70c2d1ec43423b9d39ff8e-1532964138984threejs.png)">


