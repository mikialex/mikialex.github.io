<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>mikialex</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://mikialex.github.io/"/>
  <updated>2022-04-21T14:40:39.216Z</updated>
  <id>http://mikialex.github.io/</id>
  
  <author>
    <name>miki alex</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>arm mali gpu note</title>
    <link href="http://mikialex.github.io/2022/04/21/arm-mali-gpu-note/"/>
    <id>http://mikialex.github.io/2022/04/21/arm-mali-gpu-note/</id>
    <published>2022-04-20T16:00:00.000Z</published>
    <updated>2022-04-21T14:40:39.216Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.youtube.com/watch?v=tnR4mExVClY&amp;list=PLKjl7IFAwc4QUTejaX2vpIwXstbgf8Ik7" target="_blank" rel="noopener">https://www.youtube.com/watch?v=tnR4mExVClY&amp;list=PLKjl7IFAwc4QUTejaX2vpIwXstbgf8Ik7</a></p><p>摘录此系列视频中提到的一些点，复习一下移动端图形优化（视频提到的顺序）</p><ul><li>功耗问题<ul><li>整个系统的功耗是有预算的（3w），需要在cpu，gpu，isp，npu…之间share</li><li>移动平台cpu，频率约低，能效越高</li><li>带宽就是能耗，per gb per second ⇒ watt</li><li>尽可能多线程，降低每个线程的负载，使得cpu尽可能低频率运行</li></ul></li><li>硬件实现hidden surface removal使得，即便drawcall提交顺序不利于earlyz，优化也能起作用</li><li>TBDR： Immediate模式，cheap几何，expensive着色（高带宽）更好更容易的并行能力。tbdr：expensive几何（分块，带宽），cheap着色（低带宽），较低（粗粒度）的并行能力（pipline各个阶段以renderpass为界进行工作切换），更需注意的api使用。</li><li>基本上大部分移动平台都是tbdr一个原因是，分辨率高，大部分应用的成本在着色上。有了onchip的tile，很多带宽昂贵的操作都free了</li><li>处理器特性：<ul><li>cpu：低线程数量 ⇒ 依赖单核性能 ⇒ 通过降低延迟提高性能</li><li>gpu：高线程数量 ⇒ 依赖整体吞吐量 ⇒ 通过提升能效提高性能</li></ul></li><li>gpu有较多的线程可利用，大量线程在多个任务间切换来避免计算单元闲置，提高并行能力，提高吞吐，即便这样使得延迟大大提升（无所谓）。这种吞吐量提升的方式，避免了硬件设计上比如cpu端对分支预测，乱序预测执行（这些东西的存在其实就是为了主动发现额外的并行能力），和大的多级缓存的支持，降低了复杂程度和能耗。</li><li>mali gpu市占率： 50% 手机设备， 85%智能电视</li><li>constant tile elimination : 跳过没有变化的tile写入来减少带宽</li><li>AFBC arm frame buffer compression：压缩fb减少带宽</li><li>IVDS index driven vertex shading，mali gpu会将顶点着色器提前编译处理成两部分，提取位置计算靠前以提早进行图元剔除</li><li>有限资源下优化的策略： 严格计算budget，有多少带宽可用：对应能支持多大分辨率，多少目标fps，使用什么纹理格式？ 有多少计算能力可用： shader cycles per pixel</li><li>压缩纹理</li><li>仔细设计和考虑render/frame graph 数据流，尽可能避免tile memory外的存储访问</li><li>tile上的操作，可以将多个pass合并，所以事实上，msaa的source target，渲染的中间target只要使用得当，事实上是根本不存在主存里，也不会访问主存，memoryless</li><li>对于vk<ul><li>简单的使用pass load的clear即可，而不单独使用clear command</li><li>简单的使用pass resolve来resolve mass， 而不单独使用resolve command</li></ul></li><li>对于opengl<ul><li>pass的概念在驱动内还是存在的，等于说驱动会推测出pass，load，store的各种operation</li><li>一些操作会导致pass被split，等于说需要重新进行昂贵的load，需要避免，比如fbo绑定状态的修改，同步状态的修改。</li><li>一些操作是有利于驱动作出优化的，例如在绑定完fbo时，立刻调用clear，驱动会推测出此pass是loadop 不需要load。</li><li>AFBC只支持同时attach depth23 stencil8格式的fbo，所以为了减少带宽消耗，故意不绑定stencil之类的做法是错误的。类似的，f32支持但是f16不支持</li></ul></li><li>从graph的角度，可以轻易识别出不必要的写（没有后续pass读的输出），可以识别出可以进行merge的pass。</li><li>AFBC的使用，对于opengl而言，是完全驱动控制的，但是对于vk而言，是通过textureview的flag（IMAGE_TILING_OPtiMAL, IMAGE_USAFE_STORAGE…）显式控制的</li><li>tile的存储大小是固定的，但是物理大小是可变的。使用mrt，msaa，会导致tile物理尺寸变小，降低性能</li><li>移动设备横放和竖放其实是有影响的，如果swapchain的输入方向和屏幕不一致，可能会有昂贵的读取成本。opengl驱动会处理，vk需要用户处理</li><li>prez pass一般不适合移动端，不过例外是可以用来绘制那些不能用hsr优化的动态物体</li><li>尽可能减少几何数据的带宽，甚至使用f16，2 float normal</li><li>由于IVDS的存在，position是先被计算的，所以传统的interleave组织attribute的方式并不是最好的，因为position的访问被interleave的，缓存命中率低。所以最优是将非position的数据interleave，position相关的单独interleave，做两个array of structure</li><li>2d渲染，如果有能力预处理资源，可以在几何上将物体切成需要alphablend的不需要的部分来减少overdraw</li><li>shader的优化一般被高估了，很多优化看起来没有生效其实是因为他们是不合法的（浮点数上界的边界问题）。</li><li>workgroup share memory在mali gpu上和主存没有性能区别</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=tnR4mExVClY&amp;amp;list=PLKjl7IFAwc4QUTejaX2vpIwXstbgf8Ik7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://
      
    
    </summary>
    
      <category term="techology" scheme="http://mikialex.github.io/categories/techology/"/>
    
    
      <category term="arm, optimization, graphics" scheme="http://mikialex.github.io/tags/arm-optimization-graphics/"/>
    
  </entry>
  
  <entry>
    <title>wgpu read notes</title>
    <link href="http://mikialex.github.io/2022/04/21/wgpu-read-notes/"/>
    <id>http://mikialex.github.io/2022/04/21/wgpu-read-notes/</id>
    <published>2022-04-20T16:00:00.000Z</published>
    <updated>2022-04-21T14:40:43.366Z</updated>
    
    <content type="html"><![CDATA[<p>长期以来，各个操作系统，平台，厂商的发展出了多套现代的图形API，使得跨平台图形开发存在巨大的开发成本和兼容性问题。成熟的渲染引擎，一般都实现了一套跨平台的渲染抽象层用以封装和抹平不同图形API接口和使用的差异。但这样一套成体系的抽象层并没有一个公认的实现标准。web graphics，作为跨平台渲染最重要的应用场景，长期以来使用老旧的opengl es标准，无法满足未来图形应用的发展需求，webgpu成为大家的众望所归，不仅解决了web上下一代图形api的形态问题，更重要的是为桌面端跨平台渲染提供了一个最稳固的标准实现。</p><p>wgpu是rust的webgpu实现，目前被应用在firefox，deno等项目中实现webgpu支持。本文将介绍一下wgpu体系的整体架构，并针对性的对核心模块实现进行分析和摘录。此文基于wgpu 0.12.0的实现。</p><p>整个wgpu体系是较为复杂的(core 2w，hal 2w)，无论其核心模块还是hal实现都包含大量的细节，本文不会面面俱到指出所有细节。仅仅是从笔者自己关心的方向，进行探索性的阅读，重点将放在wgpu-core的资源管理上，不保证分析完全的正确性或是是否符合作者的本意。</p><p><img src="/images/wgpu-read-notes/big-picture.png" alt="big-picture"></p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>根据上图：整个体系最重要的有3个crate组成：wgpu-hal：设计和实现了渲染抽象层：同时支持vk，metal，dx，opengl，多个后端。向外暴露出一组unsafe的需要手工管理资源的接口。wgpu-core：wgpu的核心实现，主要完成对标准的实现以及资源管理。对外暴露出真正的native版本的webgpu接口。wgpu：为rust应用提供的上层webgpu接口，完成native，web多实现的封装。</p><p>使用wgpu，可以使得你的rust程序编译为native的应用程序（使用wgpu-core的native实现），或是wasm版本的web应用程序（使用浏览器接口，如果是firefox，firefox底层还是会使用wgpu-core）或是native版的其他语言实现（比如chrome的dawn，这一点通过wgpu-native/wgpu headers完成）wgpu不仅承担了选择native还是web的逻辑，还有具体使用哪个图形api的逻辑，如果不加指定，wgpu会根据你的编译平台自行选择。</p><p>naga是个重要的模块，其完成的职责是shader的转换翻译和validation，webgpu可以使用wgsl，spirv等shader格式，但对于各个后端支持而言，需要进行shader翻译工作。同时webgpu作为safe的api，需要对shader和相关shader绑定的声明进行运行时验证，甚至对shader内部逻辑进行调整以满足安全性需求。naga的内部架构主要是一套树形的IR，支持多个shader语言的前后端，来完成转译工作。naga会基于IR执行一些分析和验证工作，但不会涉及到优化。</p><p>对于有更高性能要求，不希望wgpu-core做任何验证和资源管理的，可以直接使用wgpu-hal unsafe的api，wgpu-hal其实就是gfx-rs的简约版</p><h2 id="抽象层"><a href="#抽象层" class="headerlink" title="抽象层"></a>抽象层</h2><h3 id="web-native抽象层"><a href="#web-native抽象层" class="headerlink" title="web/native抽象层"></a>web/native抽象层</h3><p>这一层是wgpu rust api的主要内容。我们日常使用的对象如buffer，texture，device等就是该层提供的。可以看到，这一层的实现其实都是一些不透明的handle对象。实际的实现通过Context这个trait的抽象层进行转发。ctx定义了若干关联类型和操作的方法。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Buffer</span></span> &#123;</span><br><span class="line">    context: Arc&lt;C&gt;,</span><br><span class="line">    id: &lt;C <span class="keyword">as</span> Context&gt;::BufferId,</span><br><span class="line">    map_context: Mutex&lt;MapContext&gt;,</span><br><span class="line">    usage: BufferUsages,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Texture</span></span> &#123;</span><br><span class="line">    context: Arc&lt;C&gt;,</span><br><span class="line">    id: &lt;C <span class="keyword">as</span> Context&gt;::TextureId,</span><br><span class="line">    owned: <span class="built_in">bool</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Context</span></span>: <span class="built_in">Debug</span> + <span class="built_in">Send</span> + <span class="built_in">Sized</span> + <span class="built_in">Sync</span> &#123;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">AdapterId</span></span>: <span class="built_in">Debug</span> + <span class="built_in">Send</span> + <span class="built_in">Sync</span> + <span class="symbol">'static</span>;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">DeviceId</span></span>: <span class="built_in">Debug</span> + <span class="built_in">Send</span> + <span class="built_in">Sync</span> + <span class="symbol">'static</span>;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">QueueId</span></span>: <span class="built_in">Debug</span> + <span class="built_in">Send</span> + <span class="built_in">Sync</span> + <span class="symbol">'static</span>;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">ShaderModuleId</span></span>: <span class="built_in">Debug</span> + <span class="built_in">Send</span> + <span class="built_in">Sync</span> + <span class="symbol">'static</span>;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">BindGroupLayoutId</span></span>: <span class="built_in">Debug</span> + <span class="built_in">Send</span> + <span class="built_in">Sync</span> + <span class="symbol">'static</span>;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">init</span></span>(backends: Backends) -&gt; <span class="keyword">Self</span>;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">instance_create_surface</span></span>(</span><br><span class="line">        &amp;<span class="keyword">self</span>,</span><br><span class="line">        handle: &amp;<span class="keyword">impl</span> raw_window_handle::HasRawWindowHandle,</span><br><span class="line">    ) -&gt; Self::SurfaceId;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">instance_request_adapter</span></span>(</span><br><span class="line">        &amp;<span class="keyword">self</span>,</span><br><span class="line">        options: &amp;RequestAdapterOptions&lt;<span class="symbol">'_</span>&gt;,</span><br><span class="line">    ) -&gt; Self::RequestAdapterFuture;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">adapter_request_device</span></span>(</span><br><span class="line">        &amp;<span class="keyword">self</span>,</span><br><span class="line">        adapter: &amp;Self::AdapterId,</span><br><span class="line">        desc: &amp;DeviceDescriptor,</span><br><span class="line">        trace_dir: <span class="built_in">Option</span>&lt;&amp;std::path::Path&gt;,</span><br><span class="line">    ) -&gt; Self::RequestDeviceFuture;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">instance_poll_all_devices</span></span>(&amp;<span class="keyword">self</span>, force_wait: <span class="built_in">bool</span>);</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">adapter_is_surface_supported</span></span>(</span><br><span class="line">        &amp;<span class="keyword">self</span>,</span><br><span class="line">        adapter: &amp;Self::AdapterId,</span><br><span class="line">        surface: &amp;Self::SurfaceId,</span><br><span class="line">    ) -&gt; <span class="built_in">bool</span>;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">adapter_features</span></span>(&amp;<span class="keyword">self</span>, adapter: &amp;Self::AdapterId) -&gt; Features;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>在wgpu/src/backend下可以找到direct和web版本的实现。</p><p>对于direct的实现，会直接使用wgpu-core的类型，对于web的实现，会直接使用web sys提供的类型（其实就是js对象）。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Context</span></span>(wgc::hub::Global&lt;wgc::hub::IdentityManagerFactory&gt;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> crate::Context <span class="keyword">for</span> Context &#123;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">AdapterId</span></span> = wgc::id::AdapterId;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">DeviceId</span></span> = Device;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">QueueId</span></span> = wgc::id::QueueId;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">ShaderModuleId</span></span> = wgc::id::ShaderModuleId;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">BindGroupLayoutId</span></span> = wgc::id::Bi</span><br><span class="line">...</span><br></pre></td></tr></table></figure><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span>(<span class="keyword">crate</span>) <span class="class"><span class="keyword">struct</span> <span class="title">Context</span></span>(web_sys::Gpu);</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> crate::Context <span class="keyword">for</span> Context &#123;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">AdapterId</span></span> = Sendable&lt;web_sys::GpuAdapter&gt;;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">DeviceId</span></span> = Sendable&lt;web_sys::GpuDevice&gt;;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">QueueId</span></span> = Sendable&lt;web_sys::GpuQueue&gt;;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">ShaderModuleId</span></span> = Sendable&lt;web_sys::GpuShaderModule&gt;;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">BindGroupLayoutId</span></span> = Sendable&lt;web_sys::GpuBindGroupLayout&gt;;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">BindGroupId</span></span> = Sendable&lt;web_sys::GpuBindGroup&gt;;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">TextureViewId</span></span> = Sendable&lt;web_sys::GpuTextureView&gt;;</span><br></pre></td></tr></table></figure><h3 id="渲染抽象层"><a href="#渲染抽象层" class="headerlink" title="渲染抽象层"></a>渲染抽象层</h3><p>另一套抽象层就是wgpu-core要使用的wgpu-hal，这其实是多套trait,定义了很多类型和他们之间需要交互的protocal。其后端实现在wgpu-hal下可以找到。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">Api</span></span>: <span class="built_in">Clone</span> + <span class="built_in">Sized</span> &#123;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">Instance</span></span>: Instance&lt;<span class="keyword">Self</span>&gt;;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">Surface</span></span>: Surface&lt;<span class="keyword">Self</span>&gt;;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">Adapter</span></span>: Adapter&lt;<span class="keyword">Self</span>&gt;;</span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">Device</span></span>: Device&lt;<span class="keyword">Self</span>&gt;;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">Instance</span></span>&lt;A: Api&gt;: <span class="built_in">Sized</span> + <span class="built_in">Send</span> + <span class="built_in">Sync</span> &#123;</span><br><span class="line">    <span class="keyword">unsafe</span> <span class="function"><span class="keyword">fn</span> <span class="title">init</span></span>(desc: &amp;InstanceDescriptor) -&gt; <span class="built_in">Result</span>&lt;<span class="keyword">Self</span>, InstanceError&gt;;</span><br><span class="line">    <span class="keyword">unsafe</span> <span class="function"><span class="keyword">fn</span> <span class="title">create_surface</span></span>(</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">Surface</span></span>&lt;A: Api&gt;: <span class="built_in">Send</span> + <span class="built_in">Sync</span> &#123;</span><br><span class="line">    <span class="keyword">unsafe</span> <span class="function"><span class="keyword">fn</span> <span class="title">configure</span></span>(</span><br><span class="line">        &amp;<span class="keyword">mut</span> <span class="keyword">self</span>,</span><br><span class="line">        device: &amp;A::Device,</span><br><span class="line">        config: &amp;SurfaceConfiguration,</span><br><span class="line">    ) -&gt; <span class="built_in">Result</span>&lt;(), SurfaceError&gt;;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">Adapter</span></span>&lt;A: Api&gt;: <span class="built_in">Send</span> + <span class="built_in">Sync</span> &#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>如何在上层做类型擦除？</strong></p><p>wgpu的前身的gfx-rs，这个项目是将所有api封装成一套unsafe的vulkan like api。这个项目如果使用不当的话，可能会造成的麻烦的是，后端的类型作为泛型参数，如果不加控制，会一路pop到最上层的用户接口，比如camera。这是非常不合理的。简而言之，将这个类型进行擦除，wgpu的做法是通过cargo feature对指定的类型别名进行条件编译，除了类型别名，大量direct后端实现会直接调用接口会通过gfx_select！宏来转发，而宏展开的内部也会应用相同的feature逻辑</p><h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><p>使用webgpu，而不是其他抽象层，重要的原因，其实是安全性/便捷性。用户不需要手工管理图形资源，不用担心正在使用的资源被错误的释放，不用担心没有插入正确的同步调用，等等。自然这些职责就落在在实现者上。</p><p>理解wgpu如何做好资源管理是比较重要的，原因其一是作为上层用户的使用者，webgpu内部的资源管理显然是一个具有overhead的黑盒，通过阅读实现可以帮助理解和避免高成本的api错误用法。其二是通过阅读实现也能学习到如何高效的安全的合理的对现代unsafe图形api进行资源管理。</p><h3 id="资源管理器结构"><a href="#资源管理器结构" class="headerlink" title="资源管理器结构"></a>资源管理器结构</h3><p>从理解数据结构开始。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Global</span></span>&lt;G: GlobalIdentityHandlerFactory&gt; &#123;</span><br><span class="line"><span class="comment">// 实际渲染后端的instance类型</span></span><br><span class="line">    <span class="keyword">pub</span> instance: Instance,</span><br><span class="line"><span class="comment">// 管理swapchain相关</span></span><br><span class="line">    <span class="keyword">pub</span> surfaces: Registry&lt;Surface, id::SurfaceId, G&gt;,</span><br><span class="line">    hubs: Hubs&lt;G&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实际存储后端的图形资源的容器集合</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Hub</span></span>&lt;A: hal::Api, F: GlobalIdentityHandlerFactory&gt; &#123;</span><br><span class="line">    <span class="keyword">pub</span> adapters: Registry&lt;Adapter&lt;A&gt;, id::AdapterId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> devices: Registry&lt;Device&lt;A&gt;, id::DeviceId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> pipeline_layouts: Registry&lt;PipelineLayout&lt;A&gt;, id::PipelineLayoutId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> shader_modules: Registry&lt;ShaderModule&lt;A&gt;, id::ShaderModuleId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> bind_group_layouts: Registry&lt;BindGroupLayout&lt;A&gt;, id::BindGroupLayoutId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> bind_groups: Registry&lt;BindGroup&lt;A&gt;, id::BindGroupId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> command_buffers: Registry&lt;CommandBuffer&lt;A&gt;, id::CommandBufferId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> render_bundles: Registry&lt;RenderBundle, id::RenderBundleId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> render_pipelines: Registry&lt;RenderPipeline&lt;A&gt;, id::RenderPipelineId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> compute_pipelines: Registry&lt;ComputePipeline&lt;A&gt;, id::ComputePipelineId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> query_sets: Registry&lt;QuerySet&lt;A&gt;, id::QuerySetId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> buffers: Registry&lt;Buffer&lt;A&gt;, id::BufferId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> textures: Registry&lt;Texture&lt;A&gt;, id::TextureId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> texture_views: Registry&lt;TextureView&lt;A&gt;, id::TextureViewId, F&gt;,</span><br><span class="line">    <span class="keyword">pub</span> samplers: Registry&lt;Sampler&lt;A&gt;, id::SamplerId, F&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 存储单个资源类型的容器</span></span><br><span class="line"><span class="comment">// 实际的F实现IdentityHandlerFactory事实上和Storage是配套的</span></span><br><span class="line"><span class="comment">// 由下面若干类型展开看到，某个类型的资源是以generational arena方式进行管理的</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Registry</span></span>&lt;T: Resource, I: id::TypedId, F: IdentityHandlerFactory&lt;I&gt;&gt; &#123;</span><br><span class="line">    identity: F::Filter,</span><br><span class="line">    data: RwLock&lt;Storage&lt;T, I&gt;&gt;,</span><br><span class="line">    backend: Backend, <span class="comment">// 后端类型的枚举</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Storage</span></span>&lt;T, I: id::TypedId&gt; &#123;</span><br><span class="line">    map: <span class="built_in">Vec</span>&lt;Element&lt;T&gt;&gt;,</span><br><span class="line">    kind: &amp;<span class="symbol">'static</span> <span class="built_in">str</span>,</span><br><span class="line">    _phantom: PhantomData&lt;I&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">Element</span></span>&lt;T&gt; &#123;</span><br><span class="line">    Vacant,</span><br><span class="line">    Occupied(T, Epoch), <span class="comment">// Eopch就是generation</span></span><br><span class="line">    Error(Epoch, <span class="built_in">String</span>),</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 管理generational arena的freelist</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">IdentityManager</span></span> &#123;</span><br><span class="line">    free: <span class="built_in">Vec</span>&lt;Index&gt;,</span><br><span class="line">    epochs: <span class="built_in">Vec</span>&lt;Epoch&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所有的资源读写都需要从registry访问，考虑到后续多线程支持，registry本身是添加读写锁的。为了从根本上避免死锁问题，这里采用类型系统的技巧来从编译期避免死锁：即通过限制资源获取锁的顺序，如何限制呢：通过trait，为资源类型之间定义出一整套DAG的关系，每解开锁需要某个前序类型的token，并返回后序类型的token，以此来限制资源获取顺序。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 所有registry获取锁的都需要一个token，某个token的存在意味着当前某个类型的锁已经被打开了</span></span><br><span class="line"><span class="keyword">pub</span>(<span class="keyword">crate</span>) <span class="class"><span class="keyword">struct</span> <span class="title">Token</span></span>&lt;<span class="symbol">'a</span>, T: <span class="symbol">'a</span>&gt; &#123;</span><br><span class="line">    level: PhantomData&lt;&amp;<span class="symbol">'a</span> T&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Type system for enforcing the lock order on shared HUB structures.</span></span><br><span class="line"><span class="comment">/// If type A implements `Access&lt;B&gt;`, that means we are allowed to proceed</span></span><br><span class="line"><span class="comment">/// with locking resource `B` after we lock `A`.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// The implenentations basically describe the edges in a directed graph</span></span><br><span class="line"><span class="comment">/// of lock transitions. As long as it doesn't have loops, we can have</span></span><br><span class="line"><span class="comment">/// multiple concurrent paths on this graph (from multiple threads) without</span></span><br><span class="line"><span class="comment">/// deadlocks, i.e. there is always a path whose next resource is not locked</span></span><br><span class="line"><span class="comment">/// by some other path, at any time.</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">Access</span></span>&lt;A&gt; &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">enum</span> <span class="title">Root</span></span> &#123;&#125;</span><br><span class="line"><span class="comment">//<span class="doctag">TODO:</span> establish an order instead of declaring all the pairs.</span></span><br><span class="line"><span class="keyword">impl</span> Access&lt;Instance&gt; <span class="keyword">for</span> Root &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span> Access&lt;Surface&gt; <span class="keyword">for</span> Root &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span> Access&lt;Surface&gt; <span class="keyword">for</span> Instance &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;Adapter&lt;A&gt;&gt; <span class="keyword">for</span> Root &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;Adapter&lt;A&gt;&gt; <span class="keyword">for</span> Surface &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;Device&lt;A&gt;&gt; <span class="keyword">for</span> Root &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;Device&lt;A&gt;&gt; <span class="keyword">for</span> Surface &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;Device&lt;A&gt;&gt; <span class="keyword">for</span> Adapter&lt;A&gt; &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;PipelineLayout&lt;A&gt;&gt; <span class="keyword">for</span> Root &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;PipelineLayout&lt;A&gt;&gt; <span class="keyword">for</span> Device&lt;A&gt; &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;PipelineLayout&lt;A&gt;&gt; <span class="keyword">for</span> RenderBundle &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;BindGroupLayout&lt;A&gt;&gt; <span class="keyword">for</span> Root &#123;&#125;</span><br><span class="line"><span class="keyword">impl</span>&lt;A: hal::Api&gt; Access&lt;BindGroupLayout&lt;A&gt;&gt; <span class="keyword">for</span> Device&lt;A&gt; &#123;&#125;</span><br><span class="line">......</span><br></pre></td></tr></table></figure><h3 id="生命周期管理"><a href="#生命周期管理" class="headerlink" title="生命周期管理"></a>生命周期管理</h3><p>我们知道，当用户drop了某个buffer，但是如果某个buffer还继续被bindgroup或是其他资源继续引用，是不能在底层直接销毁的。为此，wgpu实现需要考虑如何管理相关资源生命周期的问题。</p><p>整个问题的不能全部使用传统的引用计数来解决，是因为，1 wgpu的资源是以arena方式进行存储的，通信和计算都使用handle类型，2 某个资源即便没有任何引用，如果还在gpu运行中被使用，也是不能删除的。 针对1 wgpu通过自己的refcount raii类型，实现了在arena基础之上提供一套refcount机制，针对2 wgpu为每个resource绑定最后一次commandbuffer submission的index，decive端通过gpu fence来获取当前command执行情况（哪些commnadbuffer已经被执行完毕了），通过比较last submission index便可以知道该资源是否还在gpu中正常运行需要使用。</p><p>数据结构上：对于所有资源都是由device创建和销毁，每个device own这些resource，每个device实例上有此 lifetime tracker，每次resource上面都有对应的LifeGuard。</p><p>引用关系建立，refcount raii clone可以在device创建资源的代码中找到，drop就是各个资源的drop。由于refcount是附加在resource上的，并不是包裹在resource外，所以refcount置空也不会直接释放资源，所以事实上有个类似垃圾回收的pass会定期的回收。实现位于device.maintain. tracker不仅管理资源清理，还管理buffer mapping。maintain的执行结果会返回实际要做的资源清理列表以及map成功的列表。</p><p>用户drop资源，会将资源加入tracker的 suspected_resources中，queue write texture / buffer，创建的临时buffer，会加入到future_suspected_buffers/texture中，用户异步map的buffer会被加入到mapped中。在maintain逻辑中，会调用triage_suspected（检查所有用户当前指定销毁的资源，检查是否被gpu还在使用，如果是的装在active submission list中）， triage_mapped（检查当然map的请求，哪些buffer是否gpu已经使用完毕，装在ready_to_map中）， triage_submissions（检查active submission list，即过去的待销毁但被gpu使用中的资源是否还在被gpu使用）</p><p>maintain的调用时机是每次queue submit command buffer时，或者用户显式的poll device。对于native实现如果没有queue submit，整个event loop是需要定期持续poll的，对于web，浏览器会自动做这件事情，不需要js进行调用。在queue submit时，会更新最新的submission index到各个resource，同时检查引用计数并尝试添加到suspected_resources以供下一波triage_suspected来检查清理资源。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// A struct responsible for tracking resource lifetimes.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Here is how host mapping is handled:</span></span><br><span class="line"><span class="comment">///   1. When mapping is requested we add the buffer to the life_tracker list of `mapped` buffers.</span></span><br><span class="line"><span class="comment">///   2. When `triage_suspected` is called, it checks the last submission index associated with each of the mapped buffer,</span></span><br><span class="line"><span class="comment">/// and register the buffer with either a submission in flight, or straight into `ready_to_map` vector.</span></span><br><span class="line"><span class="comment">///   3. When `ActiveSubmission` is retired, the mapped buffers associated with it are moved to `ready_to_map` vector.</span></span><br><span class="line"><span class="comment">///   4. Finally, `handle_mapping` issues all the callbacks.</span></span><br><span class="line"><span class="keyword">pub</span>(<span class="keyword">super</span>) <span class="class"><span class="keyword">struct</span> <span class="title">LifetimeTracker</span></span>&lt;A: hal::Api&gt; &#123;</span><br><span class="line">    <span class="comment">/// Resources that the user has requested be mapped, but are still in use.</span></span><br><span class="line"><span class="comment">/// 用户请求异步map的buffer会添加至此</span></span><br><span class="line">    mapped: <span class="built_in">Vec</span>&lt;Stored&lt;id::BufferId&gt;&gt;,</span><br><span class="line">    <span class="comment">/// Buffers can be used in a submission that is yet to be made, by the</span></span><br><span class="line">    <span class="comment">/// means of `write_buffer()`, so we have a special place for them.</span></span><br><span class="line">    <span class="keyword">pub</span> future_suspected_buffers: <span class="built_in">Vec</span>&lt;Stored&lt;id::BufferId&gt;&gt;,</span><br><span class="line">    <span class="comment">/// Textures can be used in the upcoming submission by `write_texture`.</span></span><br><span class="line">    <span class="keyword">pub</span> future_suspected_textures: <span class="built_in">Vec</span>&lt;Stored&lt;id::TextureId&gt;&gt;,</span><br><span class="line">    <span class="comment">/// Resources that are suspected for destruction.</span></span><br><span class="line"><span class="comment">// 任何资源在用户侧被删除，会添加至此集合</span></span><br><span class="line">    <span class="keyword">pub</span> suspected_resources: SuspectedResources,</span><br><span class="line">    <span class="comment">/// Resources that are not referenced any more but still used by GPU.</span></span><br><span class="line">    <span class="comment">/// Grouped by submissions associated with a fence and a submission index.</span></span><br><span class="line">    <span class="comment">/// The active submissions have to be stored in FIFO order: oldest come first.</span></span><br><span class="line">    active: <span class="built_in">Vec</span>&lt;ActiveSubmission&lt;A&gt;&gt;,</span><br><span class="line">    <span class="comment">/// Resources that are neither referenced or used, just life_tracker</span></span><br><span class="line">    <span class="comment">/// actual deletion.</span></span><br><span class="line">    free_resources: NonReferencedResources&lt;A&gt;,</span><br><span class="line">    ready_to_map: <span class="built_in">Vec</span>&lt;id::Valid&lt;id::BufferId&gt;&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// resource本身会持有此lifeguard</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">LifeGuard</span></span> &#123;</span><br><span class="line">    ref_count: <span class="built_in">Option</span>&lt;RefCount&gt;,</span><br><span class="line"><span class="comment">// 记录该resource最后一次被commandbuffer submit的index</span></span><br><span class="line">    submission_index: AtomicUsize,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ActiveSubmission</span></span>&lt;A: hal::Api&gt; &#123;</span><br><span class="line">    index: SubmissionIndex,</span><br><span class="line">    last_resources: NonReferencedResources&lt;A&gt;,</span><br><span class="line">    mapped: <span class="built_in">Vec</span>&lt;id::Valid&lt;id::BufferId&gt;&gt;,</span><br><span class="line">    encoders: <span class="built_in">Vec</span>&lt;EncoderInFlight&lt;A&gt;&gt;,</span><br><span class="line">    work_done_closures: SmallVec&lt;[SubmittedWorkDoneClosure; <span class="number">1</span>]&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">NonReferencedResources</span></span>&lt;A: hal::Api&gt; &#123;</span><br><span class="line">    buffers: <span class="built_in">Vec</span>&lt;A::Buffer&gt;,</span><br><span class="line">    textures: <span class="built_in">Vec</span>&lt;A::Texture&gt;,</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span>(<span class="keyword">super</span>) <span class="class"><span class="keyword">struct</span> <span class="title">SuspectedResources</span></span> &#123;</span><br><span class="line">    <span class="keyword">pub</span>(<span class="keyword">super</span>) buffers: <span class="built_in">Vec</span>&lt;id::Valid&lt;id::BufferId&gt;&gt;,</span><br><span class="line">    <span class="keyword">pub</span>(<span class="keyword">super</span>) textures: <span class="built_in">Vec</span>&lt;id::Valid&lt;id::TextureId&gt;&gt;,</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Barrier生成"><a href="#Barrier生成" class="headerlink" title="Barrier生成"></a>Barrier生成</h3><p>webgpu和metal类似，而不是和dx12，vulkan，一样需要用户自行设置resource/execution barriar。对于使用dx12/vulkan等后端的实现而言，需要wgpu自行设置正确的barrier，这需要对所有resource有一套精细的状态管理工作。这部分的实现可以在wgpu-core下的 tracker看到。</p><p><strong>标准回顾</strong></p><p>为了能让底层实现正确的处理barrier，所有的资源都有usage属性需要在用户创建时提供，usage定义了/限制了资源的使用方式，具体的spec是： <a href="https://www.w3.org/TR/webgpu/#programming-model-resource-usages" target="_blank" rel="noopener">https://www.w3.org/TR/webgpu/#programming-model-resource-usages</a> 核心规则是：在任意<strong>usage scope</strong>中，对任意<strong>sub resource</strong>，包含的<strong>internal usage</strong>是必须要相<strong>兼容</strong>的, 满足这样的规则，实现才可能针对所有平台做好barrier，否则是validation bug。</p><p>这里边有四个概念：</p><p>scope：scope可以理解是在某一段api调用范围，标准在 <a href="https://www.w3.org/TR/webgpu/#programming-model-synchronization" target="_blank" rel="noopener">https://www.w3.org/TR/webgpu/#programming-model-synchronization</a> 这一节中定义了这些scope：</p><ul><li>在pass之外每个command独立为一个scope</li><li>在compute pass中，每个dispatch是一个scope，凡是被引用和间接引用到的资源都是被使用到的</li><li>每个render pass是一个独立的scope，以整个renderpass为单位，所有引用和间接引用到的资源都是被使用到的</li></ul><p>定义这个scope是必要的，因为在底层api的实现中，可能是无法做到在任何时刻要求资源进行状态转换（比如vulkan里barrier没法在renderpass(subpass)中途生效）</p><p>sub resource：这个主要是针对texture的处理，因为显然，某个texture可能是有多个layer和level的，某个pass是可以读一个level写另一个level。所以对于一个texture不能使用一个usage来进行区分。简单来说，对于buffer，sub resource就是buffer，对于texture，sub resource是其下的某个level，layer的组合。</p><p>internal usage: 可以理解是对usage的进一步分类，分类为 input（如vertex/index buffer） constant（如uniform/texture） storage storage-read storage-write attachment attachment-read</p><p>兼容的规则：某个resource在某个scope下，所有usage，要么只有作为一个attachment（写），要么只作为storage（写），要么只作为读（input constant storage-read）</p><p>总结一下这个限制就是<strong>resource在某些使用阶段，要求他们没法同时支持读写的同时使用。</strong></p><p>实现：</p><p><strong>state抽象：</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// The main trait that abstracts away the tracking logic of</span></span><br><span class="line"><span class="comment">/// a particular resource type, like a buffer or a texture.</span></span><br><span class="line"><span class="keyword">pub</span>(<span class="keyword">crate</span>) <span class="class"><span class="keyword">trait</span> <span class="title">ResourceState</span></span>: <span class="built_in">Clone</span> + <span class="built_in">Default</span> &#123;</span><br><span class="line">    <span class="comment">/// Corresponding `HUB` identifier.</span></span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">Id</span></span>: <span class="built_in">Copy</span> + fmt::<span class="built_in">Debug</span> + TypedId;</span><br><span class="line">    <span class="comment">/// A type specifying the sub-resources.</span></span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">Selector</span></span>: fmt::<span class="built_in">Debug</span>;</span><br><span class="line">    <span class="comment">/// Usage type for a `Unit` of a sub-resource.</span></span><br><span class="line">    <span class="class"><span class="keyword">type</span> <span class="title">Usage</span></span>: fmt::<span class="built_in">Debug</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Check if all the selected sub-resources have the same</span></span><br><span class="line">    <span class="comment">/// usage, and return it.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// Returns `None` if no sub-resources</span></span><br><span class="line">    <span class="comment">/// are intersecting with the selector, or their usage</span></span><br><span class="line">    <span class="comment">/// isn't consistent.</span></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">query</span></span>(&amp;<span class="keyword">self</span>, selector: Self::Selector) -&gt; <span class="built_in">Option</span>&lt;Self::Usage&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Change the last usage of the selected sub-resources.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// If `output` is specified, it's filled with the</span></span><br><span class="line">    <span class="comment">/// `PendingTransition` objects corresponding to smaller</span></span><br><span class="line">    <span class="comment">/// sub-resource transitions. The old usage is replaced by</span></span><br><span class="line">    <span class="comment">/// the new one.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// If `output` is `None`, the old usage is extended with</span></span><br><span class="line">    <span class="comment">/// the new usage. The error is returned if it's not possible,</span></span><br><span class="line">    <span class="comment">/// specifying the conflicting transition. Extension can only</span></span><br><span class="line">    <span class="comment">/// be done for read-only usages.</span></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">change</span></span>(</span><br><span class="line">        &amp;<span class="keyword">mut</span> <span class="keyword">self</span>,</span><br><span class="line">        id: Valid&lt;Self::Id&gt;,</span><br><span class="line">        selector: Self::Selector,</span><br><span class="line">        usage: Self::Usage,</span><br><span class="line">        output: <span class="built_in">Option</span>&lt;&amp;<span class="keyword">mut</span> <span class="built_in">Vec</span>&lt;PendingTransition&lt;<span class="keyword">Self</span>&gt;&gt;&gt;,</span><br><span class="line">    ) -&gt; <span class="built_in">Result</span>&lt;(), PendingTransition&lt;<span class="keyword">Self</span>&gt;&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Merge the state of this resource tracked by a different instance</span></span><br><span class="line">    <span class="comment">/// with the current one.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// Same rules for `output` apply as with `change()`: last usage state</span></span><br><span class="line">    <span class="comment">/// is either replaced (when `output` is provided) with a</span></span><br><span class="line">    <span class="comment">/// `PendingTransition` pushed to this vector, or extended with the</span></span><br><span class="line">    <span class="comment">/// other read-only usage, unless there is a usage conflict, and</span></span><br><span class="line">    <span class="comment">/// the error is generated (returning the conflict).</span></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">merge</span></span>(</span><br><span class="line">        &amp;<span class="keyword">mut</span> <span class="keyword">self</span>,</span><br><span class="line">        id: Valid&lt;Self::Id&gt;,</span><br><span class="line">        other: &amp;<span class="keyword">Self</span>,</span><br><span class="line">        output: <span class="built_in">Option</span>&lt;&amp;<span class="keyword">mut</span> <span class="built_in">Vec</span>&lt;PendingTransition&lt;<span class="keyword">Self</span>&gt;&gt;&gt;,</span><br><span class="line">    ) -&gt; <span class="built_in">Result</span>&lt;(), PendingTransition&lt;<span class="keyword">Self</span>&gt;&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Try to optimize the internal representation.</span></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">optimize</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>数据结构：</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// state tracking 的基本单元</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Unit</span></span>&lt;U&gt; &#123;</span><br><span class="line">    first: <span class="built_in">Option</span>&lt;U&gt;,</span><br><span class="line">    last: U,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 描述某个类型的资源引用关系</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Resource</span></span>&lt;S&gt; &#123;</span><br><span class="line">    ref_count: RefCount,<span class="comment">// 引用计数clone</span></span><br><span class="line">    state: S, <span class="comment">// 实现一般是上面的unit</span></span><br><span class="line">    epoch: Epoch,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// tracking 同一类型多个资源的引用关系</span></span><br><span class="line"><span class="keyword">pub</span>(<span class="keyword">crate</span>) <span class="class"><span class="keyword">struct</span> <span class="title">ResourceTracker</span></span>&lt;S: ResourceState&gt; &#123;</span><br><span class="line">    <span class="comment">/// An association of known resource indices with their tracked states.</span></span><br><span class="line">    map: FastHashMap&lt;Index, Resource&lt;S&gt;&gt;,</span><br><span class="line">    <span class="comment">/// Temporary storage for collecting transitions.</span></span><br><span class="line">    temp: <span class="built_in">Vec</span>&lt;PendingTransition&lt;S&gt;&gt;,</span><br><span class="line">    <span class="comment">/// The backend variant for all the tracked resources.</span></span><br><span class="line">    backend: wgt::Backend,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 描述所有类型资源的引用关系</span></span><br><span class="line"><span class="keyword">pub</span>(<span class="keyword">crate</span>) <span class="class"><span class="keyword">struct</span> <span class="title">TrackerSet</span></span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> buffers: ResourceTracker&lt;BufferState&gt;,</span><br><span class="line">    <span class="keyword">pub</span> textures: ResourceTracker&lt;TextureState&gt;,</span><br><span class="line">    <span class="keyword">pub</span> views: ResourceTracker&lt;PhantomData&lt;id::TextureViewId&gt;&gt;,</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>TrackerSet 由bindgroup，renderpassInfo，commandbuffer， bundle，device分别持有，来管理资源的状态和引用关系。</p><p><strong>流程：</strong></p><p>hal command buffer上的insert_barriers是最终的pass上主要的barrier生成（调用底层api）的方法（当然其他地方也有手工barrier设置，比如copy，clear）。从这个方法可以看到，barrier主要是由base和target的trackerset交互生成的，merge_replace会将目标的state，转移到base上，并且生成transition信息，交由底层生成barrier。insert_barriers 会在renderpass录制结束，每次compute dispatch，queue submit 时提交，正好对应spec中usage scope的定义。</p><p>以renderpass录制为例，会通过renderpassInfo上的tracker来收集当前动态提交的资源绑定命令，比如会merge_extend 来自bindgroup上trackerset缓存的usage，index/vertex buffer的usage，merge_extend bundle的trackerset缓存的usage，这个renderpassInfo上的tracker就是下面insert_barriers使用的target set。同时，当barrier被insert之后，意味着resource的state要被同步，意味着cmdbuffer上的state要被target merge。当cmdbuffer被submit时，同样的，会和device上的tracker state进行merge，并生成正确的barrier。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span>(<span class="keyword">crate</span>) <span class="function"><span class="keyword">fn</span> <span class="title">insert_barriers</span></span>(</span><br><span class="line">        raw: &amp;<span class="keyword">mut</span> A::CommandEncoder,</span><br><span class="line">        base: &amp;<span class="keyword">mut</span> TrackerSet,</span><br><span class="line">        head_buffers: &amp;ResourceTracker&lt;BufferState&gt;,</span><br><span class="line">        head_textures: &amp;ResourceTracker&lt;TextureState&gt;,</span><br><span class="line">        buffer_guard: &amp;Storage&lt;Buffer&lt;A&gt;, id::BufferId&gt;,</span><br><span class="line">        texture_guard: &amp;Storage&lt;Texture&lt;A&gt;, id::TextureId&gt;,</span><br><span class="line">    ) &#123;</span><br><span class="line">        profiling::scope!(<span class="string">"insert_barriers"</span>);</span><br><span class="line">        <span class="built_in">debug_assert_eq!</span>(A::VARIANT, base.backend());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> buffer_barriers = base.buffers.merge_replace(head_buffers).map(|pending| &#123;</span><br><span class="line">            <span class="keyword">let</span> buf = &amp;buffer_guard[pending.id];</span><br><span class="line">            pending.into_hal(buf)</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">let</span> texture_barriers = base.textures.merge_replace(head_textures).map(|pending| &#123;</span><br><span class="line">            <span class="keyword">let</span> tex = &amp;texture_guard[pending.id];</span><br><span class="line">            pending.into_hal(tex)</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">unsafe</span> &#123;</span><br><span class="line">            raw.transition_buffers(buffer_barriers);</span><br><span class="line">            raw.transition_textures(texture_barriers);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><strong>想法</strong></p><p>wgpu将对象引用关系和state维护建模在一起，是好的做法。可以理解整个state管理的架构是非常清晰的：同一个资源，在整个绘制流程中，可能会涉及到状态的切换，所以：</p><ul><li>在创建资源时，同步引用关系的同时，就指定好合适的目标状态</li><li>时刻都存在一个当前真实的状态记录（tracker set），开始是是device的，然后是commandbuffer的，然后真实绘制时是passinfo的</li><li>在使用资源时，凡是遇到真实的状态记录需要切换即同步的，意味着需要插入barrier</li><li>标准对资源限定的用法保证了我们总是可以在正确的时机插入barrier</li></ul><p>resource上面标记的usage仅仅是为了帮助配合spec做validation，实际usage在进行相关调用时当场决定，实际usage的存在是为了正确生成barrier调用。所以可以说根据现在的实现，如果在使用过程中，对资源标记额外的usage类型，即便没有使用，也不会有性能影响。</p><p>renderpass中收集use，并生成target的trackerset，其实是比较重的操作（可能仅次于validation）。bundle的trackerset其实是被缓存的，也是为什么使用bundle cpu的消耗较低的原因之一。</p><h3 id="buffer-texture初始化"><a href="#buffer-texture初始化" class="headerlink" title="buffer/texture初始化"></a>buffer/texture初始化</h3><p>webgpu标准要求，为了安全起见，所有的新创建的buffer/texture初始化必须是全零的（至少对于用户感知而言），但是从后端分配的资源，很可能是被重用、或是存在其他脏数据。需要实现某机制以lazy的方式控制初始化的流程来保证符合这一要求。具体的实现可以在wgpu-core下的init_tracker中看到，这里以buffer举例。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Most of the time a resource is either fully uninitialized (one element) or initialized (zero elements).</span></span><br><span class="line"><span class="class"><span class="keyword">type</span> <span class="title">UninitializedRangeVec</span></span>&lt;Idx&gt; = SmallVec&lt;[Range&lt;Idx&gt;; <span class="number">1</span>]&gt;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Tracks initialization status of a linear range from 0..size</span></span><br><span class="line"><span class="comment">// 记录需要初始化的范围</span></span><br><span class="line"><span class="keyword">pub</span>(<span class="keyword">crate</span>) <span class="class"><span class="keyword">struct</span> <span class="title">InitTracker</span></span>&lt;Idx: <span class="built_in">Ord</span> + <span class="built_in">Copy</span> + <span class="built_in">Default</span>&gt; &#123;</span><br><span class="line">    <span class="comment">// Ordered, non overlapping list of all uninitialized ranges.</span></span><br><span class="line">    uninitialized_ranges: UninitializedRangeVec&lt;Idx&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span>(<span class="keyword">crate</span>) <span class="class"><span class="keyword">enum</span> <span class="title">MemoryInitKind</span></span> &#123;</span><br><span class="line">    <span class="comment">// The memory range is going to be written by an already initialized source, thus doesn't need extra attention other than marking as initialized.</span></span><br><span class="line">    ImplicitlyInitialized,</span><br><span class="line">    <span class="comment">// The memory range is going to be read, therefore needs to ensure prior initialization.</span></span><br><span class="line">    NeedsInitializedMemory,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span>(<span class="keyword">crate</span>) <span class="class"><span class="keyword">struct</span> <span class="title">BufferInitTrackerAction</span></span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> id: BufferId,</span><br><span class="line">    <span class="keyword">pub</span> range: Range&lt;wgt::BufferAddress&gt;,</span><br><span class="line">    <span class="keyword">pub</span> kind: MemoryInitKind,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Buffer</span></span>&lt;A: hal::Api&gt; &#123;</span><br><span class="line">    <span class="keyword">pub</span>(<span class="keyword">crate</span>) raw: <span class="built_in">Option</span>&lt;A::Buffer&gt;,</span><br><span class="line"><span class="comment">// 每一个buffer都持有此tracker</span></span><br><span class="line">    <span class="keyword">pub</span>(<span class="keyword">crate</span>) initialization_status: BufferInitTracker,</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 InitTracker记录未初始化范围并不是全部的，即所谓按需是指，在command submit阶段，会根据各个资源的使用范围，以及之前保存在tracker上未初始化的范围，收集需要手工初始化的范围，并在commandbuffer bake结束后，执行init(wgpu-core/src/command)，init会直接调用HAL encoder的clear方法，同时会处理好barrier方面的问题。</p><p>未初始化的数据也有可能被用户通过copy的方式隐式初始化，这种情况就不需要wgpu进行初始化，相关的逻辑可以从MemoryInitKind 的枚举值看出。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>wgpu-core的实现，除了资源管理，另一个重要部分就是validation，这部分比较无趣，涉及到的基本都是spec的细节，这里就不展开介绍了。我想，另一个有趣的问题可能更多的位于hal的后端实现部分，webgl2目前已经被部分支持了，考虑到我们做项目的需求，如果能直接使用那将对维护性有很大好处（不需要自行开发webgl/webgpu的抽象层），那么，支持的局限性如何？降级的成本如何？有没有可能进一步做到webgl1的支持？可能是我们下一个讨论的话题</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;长期以来，各个操作系统，平台，厂商的发展出了多套现代的图形API，使得跨平台图形开发存在巨大的开发成本和兼容性问题。成熟的渲染引擎，一般都实现了一套跨平台的渲染抽象层用以封装和抹平不同图形API接口和使用的差异。但这样一套成体系的抽象层并没有一个公认的实现标准。web gr
      
    
    </summary>
    
      <category term="techology" scheme="http://mikialex.github.io/categories/techology/"/>
    
    
      <category term="webgpu, wgpu, graphics" scheme="http://mikialex.github.io/tags/webgpu-wgpu-graphics/"/>
    
  </entry>
  
  <entry>
    <title>Native GUI research in 2021</title>
    <link href="http://mikialex.github.io/2021/09/21/gui-2021/"/>
    <id>http://mikialex.github.io/2021/09/21/gui-2021/</id>
    <published>2021-09-20T16:00:00.000Z</published>
    <updated>2021-09-24T10:25:43.933Z</updated>
    
    <content type="html"><![CDATA[<p>整理一些native GUI架构方面的想法。</p><h2 id="Motivation-amp-Wishlist"><a href="#Motivation-amp-Wishlist" class="headerlink" title="Motivation &amp; Wishlist"></a>Motivation &amp; Wishlist</h2><p>有点迷恋于客户端技术。（这里的客户端是指的广义的客户端，泛指用户能接触到的最终产品）。在RRF的开发中，缺少用户界面来帮助我验证调试某些功能，展示作出的一些东西，是件遗憾的事情。我并不想引入外部的框架来做这件事情，因为本身UI的开发也是对RRF整个graphics stack的不错的检验机会。</p><p>与此同时，我认为研究GUI如何impl from ground，可以让我对2d渲染，客户端架构有一些深刻的了解和学习的机会，所以一个新的宏伟的巨轮又出现在了项目计划之中</p><p>我理想中的native的gui架构需要满足以下特新，这些特性不可缺一，其重要性主要按照以下顺序排列：declarative（expressive），high performance（and efficiency），composable（modularity）</p><h4 id="声明式编程"><a href="#声明式编程" class="headerlink" title="声明式编程"></a>声明式编程</h4><p>所谓declarative，就是诸多现代流行的框架核心提供的能力，也是众所周知的概念：用户通过声明式的代码，直接指出数据与界面之间的映射关系，由框架负责更新工作，由此避免大量繁琐的数据和视图手工同步实现，巨幅提升界面编写效率和维护性。相关的概念可以说是深入人心的，也是vue、react等框架成功之处。甚至可以确定的说，现在没有人会再去使用没有双向绑定支持的UI框架了。双向绑定的支持对于用户是否能高效的编写业务是至关重要的。</p><h4 id="关于性能"><a href="#关于性能" class="headerlink" title="关于性能"></a>关于性能</h4><p>这里我不仅提到了performance，还有个重要的观点是efficiency。随着硬件的发展，事实上常见用户设备的图形能力能够吞吐非常大规模的UI图元显示，这意味着在整个UI管线的后端图形部分很可能并不需要复杂的增量/脏绘制实现，甚至某些情况<em>实现不佳</em>的增量绘制的cpu检查成本高过了暴力绘制的gpu实际成本。但是我的观点是我们不仅要performance，还要efficiency。</p><p>依赖GPU的全量绘制能力，使得具体的客户端性能表现依赖于实际的图形硬件配置。缺乏增量绘制更新的能力，也意味着你无法为你的GUI提供一个软件实现的图形后端，意味着无法在低端机器，受限的环境，嵌入式系统等情形下正常工作。</p><p>另一方面，efficiency意味着移动设备的续航能力。时间尺度下，假设没有必要的计算在GPU加速的情况下事实上不会有性能影响，但从空间角度/消耗的角度来看，依然是需要被优化的。做到完美的高性能增量更新是相当难做的，这对技术上提出了新的考验。</p><h4 id="模块化，可组合可扩展能力"><a href="#模块化，可组合可扩展能力" class="headerlink" title="模块化，可组合可扩展能力"></a>模块化，可组合可扩展能力</h4><p>举例而言：用户可以自行实现UI组件，比如某个定制化的panel。用户可以自行实现全局主题。用户可以通过底层api实现高度定制化的样式。用户自定义组件的更新优化逻辑。用户可以扩展底层api，添加扩展性功能。</p><h2 id="Prior-art-amp-Complexity"><a href="#Prior-art-amp-Complexity" class="headerlink" title="Prior art &amp; Complexity"></a>Prior art &amp; Complexity</h2><p>实现丰富复杂native的桌面程序非常困难，因为做的完善的话，事实上就是在实现浏览器。但这是不可能的。但浏览器是一个好的比喻，因为我们要解决的一些问题其实是差不多的。</p><p>简单而言，典型结构分为三层：</p><p>底层部分：需要搞定windowing：窗体管理，作为呈现的容器。基于这个容器做 输入：来自窗体或者设备的事件。和输出：UI渲染的结果。这一层需要完成windowing，events，presentation的跨平台封装（这些工作主要是调用操作系统的API），可以理解是一个类似提供shell的能力。具体实现细节可以简单也可以非常复杂，比如支持多窗体？子窗体？全屏？不同系统任务栏？系统内置的menu？drag and drop？多显示器？，dpi？文件选择（不会让上层实现自己画一个file explorer吧），奇怪的设备（游戏手柄）？系统提供的合成器（compositor）？硬件视频加速（是的这个和渲染没关系，是操作系统的api）？web支持？</p><p>视图层部分：提供一个界面的描述方式的视图数据结构view，接受底层的事件，转化成界面上逻辑的事件（比如这个按钮被点击了） 触发对应的业务逻辑回调。以及将view渲染到窗体上。这部分实现内部也会分为多层实现，最上层是设计一套描述view的API，一般来说是树结构，比如DOM tree，widget tree。这套tree描述了样式和结构方面的原始信息，第二层会根据这些信息计算layout，生成displaylist显示列表，其中可能会有大量的优化实现，大量的中间数据结构和缓存（比如额外的layout tree、render tree），第三层是渲染实现，会翻译displaylist成不同图形后端的GPU渲染命令并提交，同时实现纹理，字体，几何缓存，渲染调度，使用系统合成器等。这里每一层可以说内部由分了好几块，每一块都有海量的细节。</p><p>应用部分：构建和维护view：监听事件，触发业务逻辑，修改业务数据，再反向更新view。一般响应式框架也会构建于这一层完成自动的双向绑定工作。</p><p>在游戏开发领域，更多的会推崇另一种Immediate mode的架构方案，与之相对的上面这种则称之为retain mode。游戏中UI只是配角，因为优化UI的性能一般没有收益，而界面风格可能高度定制化，一个高度优化非常复杂，扩展能力差的view层就完全没有存在的价值，更重要的是不像web开发领域，view和应用部分没有成熟好用的双向绑定机制，所以不如没有view。immediate mode就是这种1 不在乎性能（每一帧几乎不缓存什么计算，暴力全刷，像画游戏一样画UI），2 full declarative（直接traverse 应用state生成渲染命令，由于是每一帧都绘制，事件处理的代码直接被封装进渲染里了）。非常适合并且容易集成在游戏引擎中。但是缺点也显而易见，因为stateless，比如复杂的animation，layout，这些功能难以实现（某些具有内部state的UI实现，其state还是需要交给业务，等于说上层还是要完成view的工作），因为stateless，所以优化很难搞（所谓优化本质是维护cache，增量计算，本质是由大量 state cache 来实现的）。</p><p>我个人并不认可纯粹的immediate mode这种方式， 结合我对重要性的考量，正如上述提到的缺点一样：对于高静态的应用，performance和efficiency方面的优化缺乏可控性，需要付出更多的实现成本，以至于引入partial的retain mode。同样的，immediate mode其实本质上和3d渲染引擎并无太大区别，对于高动态内容，也不失于是一种不错的view输出模式。所以，对于retain还是immediate之争，我真正推崇的是hybrid的方式，有机的吸收两种做法在不同场景下的可取之处，而不局限于教条。</p><p>GUI的底层支持是个复杂的事情，我不认为我们需要一个大而全的解决方案，一步到位像浏览器一样做一个巨大的runtime，而是可以将这个逐个的功能支持点独立成一个个可组合的crate，各取所需。在开发框架时也要充分考虑到这些部件的替换扩展能力。根据上述的分层架构，事实上结合rust现有的生态，搭建一个minimal，但是扩展性不错的框架是可以做到的。</p><h2 id="CaseStudy-amp-Experiment"><a href="#CaseStudy-amp-Experiment" class="headerlink" title="CaseStudy &amp; Experiment"></a>CaseStudy &amp; Experiment</h2><p><a href="https://github.com/linebender/druid" target="_blank" rel="noopener">druid</a> 这个UI框架在rust的GUI社区生态方面还是有一定影响力，druid的作者就是xieditor的作者，在native ui，graphics方面研究非常深入。这个库我在去年年初还集中研究过一段时间，但当时看的不是很明白，但现在得益于技术的长进，可以说大致上是了解清楚了，我觉得他的视图层部分很有可取之处。</p><p>druid的核心在于widget这个trait，整个UI的view，就是一个实现了这个trait的数据结构，然后任意的widget都可通过combinator的模式组合起来形成新的widget。整个widget tree就是这么靠combinator套娃套起来的。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">Widget</span></span>&lt;T&gt; &#123;</span><br><span class="line">  <span class="comment">// 事件处理，可以自己触发自定义事件，修改应用数据</span></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">event</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, ctx: &amp;<span class="keyword">mut</span> EventCtx, event: &amp;Event, data: &amp;<span class="keyword">mut</span> T, env: &amp;Env);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 相当于react的一堆生命周期hook</span></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">lifecycle</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, ctx: &amp;<span class="keyword">mut</span> LifeCycleCtx, event: &amp;LifeCycle, data: &amp;T, env: &amp;Env);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 接受应用数据（T），更新自己的view</span></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">update</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, ctx: &amp;<span class="keyword">mut</span> UpdateCtx, old_data: &amp;T, data: &amp;T, env: &amp;Env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现layout</span></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">layout</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, ctx: &amp;<span class="keyword">mut</span> LayoutCtx, bc: &amp;BoxConstraints, data: &amp;T, env: &amp;Env) -&gt; Size;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 实现渲染</span></span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">paint</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, ctx: &amp;<span class="keyword">mut</span> PaintCtx, data: &amp;T, env: &amp;Env);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>举例来说，flex布局事实上就是实现了widget的数据结构<code>Vec&lt;dyn widget&gt;</code>,差不多主要是实现layout。然后其他的event/paint直接转发子节点的实现。某个事件处理器也是一个widget，只不过实现了event，其他的都是套娃转发的。</p><p>我认为这真是绝妙的设计！我愿意称之为combinator套娃式的架构。</p><p>这套思想的核心就是定义面向数据流的最核心的抽象（trait）然后针对某个单独功能特性做实现，然后做一堆组合器的实现，最后通过组合器和原子化的功能，将你最后的实际需求组装起来。 比如Rx的事件流，promise，future，全都是这样的。这个做法和GUI放在一起同样绝佳的解决了组合性方面的问题。</p><p>除了解决了架构上功能模块化和扩展的的问题。对于rust这门底层语言，用户有能力控制内存，组合器链接子节点的过程可以自由的选择dyn trait动态连接，或者是通过泛型静态连接。得益于rust如此的零开销抽象机制，用户可以通过控制这个来显式的优化每个组件实际最后的内存布局，以避免过度零散的组合导致额外的间接调用和缓存不友好情况。比如你组合出了一个slider，可能下面有十几个小的widget，但是我可以保证这个slider在内存上是连续的，几十个函数调用最后编译出来只有几个，仿佛你手写了一个超级复杂的slider widget。</p><p>这种做法还提供了另一块额外的性能优化能力。假设你的view结构的逻辑也是被组合的数据结构，比如，某个子view是否要渲染，是通过特制实现if组件来控制，列表视图通过for组件实现，本质上你就是定义了一个类似vue的模版，只不过是个编译期高度优化过的形式。同样的，正如同vue的模版设计对于vue的性能优化起到了很大的作用，对于我们来说就是logic，branching，looping，等控制流结构被encode到combinator的数据结构里了，而针对每一种数据结构，我们的combinator可以定制的实现优化行为，比如memo，caching，differing，这些combinator本质上就是用户数据state，或者input event的transformer，transform整个view的change到下一层的combinator，整个UI更新的增量架构实现完全就是做在这些transformer/combinator上的，第二点就是对于某些子view的片段是constant的，即便他们有更新的逻辑，但其实是不需要运行的，得益于编译期优化强大，这些代码大概率可以在编译期就被优化掉。</p><p>我认为最好的设计不应该限制用户编写代码的方式，或者说逼迫用户采用某种范式进行开发。模版式的做法虽然有相当可取之处，但像react一样通过自由的逻辑来生成视图也是可以被允许的，react使用了统一的view描述结构virtual dom和不可变数据结构（optional）来做增量更新，而我们认为view的数据结构不应该由框架控制，那么如何做增量式更新呢。druid给出的答案是必须依赖不可变数据结构，我觉得这个想法还是可以接受的。做增量的事情，我看是逃不了做diff，要减少diff的成本，要么对view的实现做规定/侵入式实现（RP，virtual dom），要么对用户state做侵入式实现（immutable， reactive）。而甚至两边看场景都需要，因为如果小的state生成巨量的view，那肯定得diff state，如果大的state生成小的view，应该diff view。</p><p>除了diff，做自由式数据界面映射的增量实现还有个非常关键之处，如何解决move语义？比如你diff出change了，但是这个change本质是个move，如果不做任何处理，还是执行销毁重建流程，那么不仅浪费性能，还会触发不必要的生命周期。react和vue都通过key来确定子组件identity来执行move，我很确定我们的for/list组件也能实现。但如果是自由式数据界面映射呢？毕竟我们没有vdom。另外假设你有两个相同类型的子组件，条件渲染第一个并出现，如何自动move第二个组件而不全量更新，当然我很确定模版或者if的做法也不会有这个问题，因为条件渲染被体现在数据里了（第一个坑总归留着的）但如果是自由式数据界面映射呢？</p><p>这个问题的本质是通过调用函数来组合生成view的过程，缺乏函数调用点对view实例的映射信息，以至于无法在运行时通过缓存的view实例来判断是否是当前相同的view function调用产生的。解决这个问题一般需要编译器介入使得函数内能访问函数调用的元信息，而rust正好有个#[track_caller]的宏可以在某个函数内获得当前调用对调用点的unique信息，于是问题就被魔法般的解决了，另一个rust框架 moixe主要就是利用这个来做incremental的。</p><p>我真的非常喜欢druid作者对incremental ui的论述，甚至从big picture来看，所谓incremental就是优化的本质。UI framework从数据到界面的映射，中间历经结构化，样式，布局，动画，渲染，每一层都有每一层的数据结构，整个framework incremental就是实现一条无比复杂的增量数据流pipeline，让每一层都最小化更新成本。又比如实现编译器的增量编译，language server，也是input一个小的change，然后一路pipeline下去。所以我想应该会有一套增量计算的框架来共同抽象出这类优化问题，可能是提供类似一套immutable的数据和更新元语的东西，也不排除这些特性升级到语言的层面。我能看到一些研究，但是依然还不得要领。</p><p>对比druid的做法和prior art，druid view，application并没有空间上的强隔离，你可以看到用户数据是直接通过<code>Widget&lt;T&gt;</code> 直接注入进来的。我认为这个是正确的做法，减少一层indirect，提高了性能。直接反映了应用数据生成视图的思想，体现了应用数据在视图转化中的过程，非常干脆利落。而避免了传统retain mode UI 强行 MV分离 大量callback，引用到处指，各种indirect调用同步数据，编译器运行时根本无法作出良好的优化。而事实上传统的这种大量callback的做法在rust这种没有GC的语言里是非常痛苦的，非常不ergonomic。虽然空间上是一体的，但是从实现上，职责区分是清楚干净的。</p><h2 id="目前实践"><a href="#目前实践" class="headerlink" title="目前实践"></a>目前实践</h2><p>我的整体架构还是会使用druid style的reactive programing。但是允许无缝的接入一些freestyle的做法（比如即时模式）。目前已经可以绘制textbox和button等简单组件，但距离理想情况还有很大差距。</p><p>我也会尝试作出一些新的尝试，作出更加模块化的设计。比如incremental方面，layout，animation protocol，，这里边每一点都可以展开细说，如果有兴致我可能后续连载于此。</p><p>##</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;整理一些native GUI架构方面的想法。&lt;/p&gt;&lt;h2 id=&quot;Motivation-amp-Wishlist&quot;&gt;&lt;a href=&quot;#Motivation-amp-Wishlist&quot; class=&quot;headerlink&quot; title=&quot;Motivation &amp;amp; 
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>编译原理入门之旅</title>
    <link href="http://mikialex.github.io/2021/04/05/compiler101/"/>
    <id>http://mikialex.github.io/2021/04/05/compiler101/</id>
    <published>2021-04-04T16:00:00.000Z</published>
    <updated>2021-08-20T13:03:23.619Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景：-为何学习编译原理"><a href="#背景：-为何学习编译原理" class="headerlink" title="背景： 为何学习编译原理"></a>背景： 为何学习编译原理</h3><p>在过去的两年内，无论是我在工作还是业余的开发内容，都和图形渲染引擎的材质系统紧密相关。材质系统/框架本质上由这么几个部分组成：如何抽象着色逻辑，如何以最高的性能完成数据从应用程序到GPU的提交和更新，以及相关的资源管理。其中第一个部分，如何描述着色逻辑，对于大部分引擎而言就是shader构造的相关问题，这其中的相关问题我认为如果不在编译技术上投入精力进行学习和研究则会导致一些技术实现上的瓶颈。</p><p>可能一些人认为问题仅限于拼接shader字符串，的确，最基本的需求是可以通过拼接字符串，或者通过纯字符串操作得以解决。但以下高级需求很难做到：跨平台/功能降级，运行时优化，逻辑/依赖 的 提取/融合等，这些功能要求我们需要实现以真实程序的视角，而不是字符串的视角看待shader。</p><h3 id="进展"><a href="#进展" class="headerlink" title="进展"></a>进展</h3><p>仓库地址位于：<a href="https://github.com/mikialex/rxsl" target="_blank" rel="noopener">https://github.com/mikialex/rxsl</a>。目前已经实现了从输入到一个线形IR的转化，其中分部实现了从原始输入经lexer得到tokenstream，再经 parser得到ast tree，再经过irgenerator 得到 ir的完整流程。</p><p>我的参考书籍就是编译原理龙书，此书我2015年便已购得，当然后续没有深入看下去，很多细节都只了解了大概，只能说对知识的框架有个粗略的认识。阅读此类较为晦涩的技术类书籍，特别是完全没有人指导和讲解的情况下，是富有挑战性的经历。很多时候某一页内容没有真正理解，后续都很难推进下去，而某些概念又写的颇为精妙和概括，的确遇到了一些困难。</p><p>对于阅读这种高深的技术书籍遇到的这种看不懂，又找不到人问的问题，经过我的实践，一般可以这么缓解：1 大量搜索其他网上的资料，交叉参考各自说法，或者去合适的社区提问 。2强行反复看，强行反复理解，很可能就能看懂。3 找现成代码研究和调试实现辅助理解。</p><h3 id="一些认识和有趣之处"><a href="#一些认识和有趣之处" class="headerlink" title="一些认识和有趣之处"></a>一些认识和有趣之处</h3><p>我想，这个世界上已经有太多文章教你怎么写parser了，所以我不想展开具体的技术细节，而是谈谈其中我认为有所认识，有所自我突破之处。</p><p>除了龙书，我还想推荐另一部偏理论的书：《有限自动机理论》，这本书让我了解到一些更本质的理论，比如：正则语言可以被一个简单的状态转化图的自动机识别，这就是正则表达式的实现。上下文无关语言可以被一个简单的状态转化图加一个状态的栈识别，这就是parser。</p><p>所谓自顶向下递归下降LL parser，由函数调用完成状态图的状态转化，由整个调用栈表达状态栈。所谓自底向上LR parser，则其实是根据文法显式的生成状态图转化，和状态栈的转化。</p><p>LR基本不能手写，需要parsergenerator生成，解析能力较强。LL手写很方便，而且非常直观，重要的是易于做错误恢复和调试，一般LL完全够用了，LR可以实现一遍了解了解细节。LR parser还是比较难以理解的，我在去年用ts写过一个简单的LR的parser generator来学习简单LR parser的细节，但我现在基本上又把细节都忘记了。</p><p>LL需要想一下的是文法的左递归消除。对于编程语言而言，左递归在文法中是常见的，消除左递归有一套完备的理论做法，即对文法做一系列等价的改写，其解法在形式上会引入一项新的非终结符号，而通过对这一新的终结符号进行解析可以使得分词器继续消费下去，避免陷入无限递归之中。</p><p>运算符优先级和结合性：对于编程语言中的二元运算符，语言设计上基本上都是通过优先级和结合性进行去歧义化，实践上来说，优先级表现哪个parser先进行调用上，优先级越低的parser越先在上层调用，使得对应的节点位于最后产生的语法树上层，反之亦然。而结合性则反映在最后树产生的形状。我们是自左向右读取输入的，所以左结合的parser编写起来较为自然，而右结合的parser，由于运算符左侧是optional的，我目前的做法就是简单的保存状态进行回溯。优先级和结合性有另一种灵活parser实现叫pratt parser：<a href="https://matklad.github.io/2020/04/13/simple-but-powerful-pratt-parsing.html" target="_blank" rel="noopener">https://matklad.github.io/2020/04/13/simple-but-powerful-pratt-parsing.html</a>，这种做法比较高级，写法也很优雅。</p><p>IR设计和生成方面目前还在学习阶段，在我的实现中，IR的指令集非常简陋，很多语法树的部分都还没有写完实现，这些需要后续推进。在IR生成方面，我遇到的当时比较难以理解的部分是生成纯goto的控制流/生成控制流图，其中尤其是逻辑运算符也会产生控制流的问题。实话说我真的把书上写的那几页用代码实现一边我才基本搞清了细节。</p><p>在这个问题上，本质就是生成正确的goto指令，即插入goto指令并goto到正确的位置，其中难点在于后者。在插入goto后，我们是不能确定goto位置的，而是需要等到我们真的开始为goto到的代码生成指令时才知道，也是这时才对之前未确定的goto指令进行回填（back patch）。代码的控制流可能会交汇，即多个goto指令的目标很可能是一个，所以在goto resolver的内部数据结构上，具有相同跳转目标的为解决goto是个list，生成器可以按需对list进行合并（merge），而回填也是基于list进行。对于任何一段代码/语法树上的结构，<em>我们对其进行代码生成使总是要获得其首行指令位置以及其中未解决的goto</em>，当然这两个都是optional的（不一定生成了指令，不一定有未解决的控制流），而如果有更外层的跳转，比如loop continue/break return，那么内部未解决的控制流会和这些保存在代码生成器上的未解决的goto进行合并，在loop/function结束时便可以正确进行回填。总之代码生成器在生成控制流代码时，基于上面的统一的return值，要做的无非是生成goto指令以及未确定的跳转目标，合并未确定的跳转目标，回填未确定的跳转目标。</p><p>但是，当考虑到布尔表达式隐含的逻辑控制流时，事实上意味着如果某个表达式是布尔值，那么遇到逻辑运算符时不仅要生成逻辑运算的指令，还要生成跳转的指令，而这意味着一个布尔值在运行时的true和false是两条不一样的控制流（goto目标），所以，为表达式生成上述的控制流跳转结果是，要额外抽象成枚举，即对于类型是布尔值的表达式，需要返回两条潜在的未解决控制流语句，以供后续代码生成进行正确的合并和回填。</p><h3 id="后续计划"><a href="#后续计划" class="headerlink" title="后续计划"></a>后续计划</h3><p>后续我会继续将ast的其他ir部分补全，然后实现一个简单的VM来对IR进行执行和测试，然后会调整IR到一个真正的控制流图的结构，并进行SSA化，然后生成spirv代码，再后续会学习一下优化方面的内容。听起来越来越有趣了</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景：-为何学习编译原理&quot;&gt;&lt;a href=&quot;#背景：-为何学习编译原理&quot; class=&quot;headerlink&quot; title=&quot;背景： 为何学习编译原理&quot;&gt;&lt;/a&gt;背景： 为何学习编译原理&lt;/h3&gt;&lt;p&gt;在过去的两年内，无论是我在工作还是业余的开发内容，都和图形渲
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>About Rust Programming Language</title>
    <link href="http://mikialex.github.io/2021/02/16/about-rust/"/>
    <id>http://mikialex.github.io/2021/02/16/about-rust/</id>
    <published>2021-02-15T16:00:00.000Z</published>
    <updated>2021-02-19T07:45:25.907Z</updated>
    
    <content type="html"><![CDATA[<p>结合实际工作和编码的经验，谈一下rust这门编程语言，以及些非语言性质的领悟。</p><p>在2018年h2我在公司的工作内容很多方面涉及到修复令人头疼的内存释放不掉的问题。（我这里不再说内存泄漏了，因为脚本语言就没有内存泄漏的的概念。）但是即便有devtools的堆快照神助，依然是非常令人恶心。具体而言就是某些操作前后截取快照，compare，看看那些对象多了，为什么多了，是被谁持有释放不掉？然后修复问题。这个话说是轻巧，但是这个引用链看起来真的是头晕目眩，各种闭包，各种浏览器内置的对象，甚至编译工具，React本身就是有问题的。至此我也不觉得垃圾回收是万能的内存管理方案，只要不顾一切，总是能把事情搞砸。垃圾回收的另一个致命的问题是当我们试图支持无限大场景，实现了一套磁盘/网络交换系统，但是由于我们无法控制垃圾回收何时触发，内存是否能真正释放，所以最后整个项目以失败告终。</p><p>虽然那个半年做的非常失败，我现在觉得那段时间对我的提升是巨大的，包括在那年的h2retro中总结的一样，比如，当我们实现一个功能，不能说看到那个对象有我们要的东西，就直接引用过来，直接搞。整个项目里全是引用乱指，对象之间相互依赖，没有职责能力划分，一团麻花。所以后来我写代码是会比较关注对象引用结构的。我总结下来一个比较重要的实践是：当一个对象持有另一个的时候却仅仅是为了messaging，他们没有依赖上的关系时，我们应该将另一个对象作为方法参数来引入，而不是直接持有这个对象。等等，有一系列诸如此类的感想吧。在当时业余我也逐步开始着重做我的图形引擎，作为框架作者的角度来思考事情，这些事情包括但不仅限与上述的引用关系，状态的划分，逻辑的组织，接口的设计，这些从现在的视角下都是常识，但基本上都是从反面例子中自行体会和总结。</p><p>作为一个图形渲染引擎工程师，我的工作其实主要解决渲染性能方面的问题，但不幸的是我们是在web平台上做渲染，只能使用非常糟糕的JavaScript（当然其实是Typescript）和落后的WebGL。很多时候，我们编写一些我们以为可能运行的高效的代码，但是实际执行速度感人，很难猜测js引擎能否优化如何优化，当所有算法/做法层面的潜力都尝试干净了，我们完全无法在实现层面作出任何有效的改进，这令人窒息。</p><p>总结为技术上的瓶颈就是：用脚本语言在做一个追求一个高性能的底层引擎项目时逃离不了的若干问题，以及连锁导致代码质量崩溃的问题。</p><hr><p>最早听说rust是在17年左右，主要是知乎和 hacker news。 我经常听到一些关于这门语言很酷的点，比如这门语言是Mozilla为了写浏览器引擎而做的语言，当然除了servo，rust后来的确成就了quantum firefox的传奇。出于上面遇到的瓶颈，于是在令人颇为不适的工作之外我试图开始接触较为底层的技术，当时经过一番研究和权衡选择rust而不是c++主要原因在于：c++太难了坑太多了，rust虽然也不简单，但是难有难的道理，而不是难在坑点上，既然as a better c++，我也不在乎哪一天把这c++ best practice/ good parts 写回c++里。重在思想上的学习而不是语法和历史坑点的掌握，精通回的四种写法并没有实际的用处。另一个不得不说的点是，cargo等工具链是在是太好用了，完全不用搞依赖，搞配置，搞编译搞环境，又免去了太多我认为不是重点的东西。</p><p>开始正式学习和业余使用是在18年末，顿时真的觉得解决了我很多的困扰。以至于在19年下半年开始，我开始全量使用rust进行业余项目的开发。因为毕竟不是脚本了，自然免去了垃圾回收的诸多问题，同时实践上rust的确证明了自己是c++级别的性能。在此我想更多的谈一下取舍的问题和代码质量上的正面作用。</p><p>在我入行的第一年，我就深刻意识到一个真理，就是人一定是不能被相信的，如果一个事情不是由机器做，而是人，那么没过多久就一定出问题，而试图让人不出问题的体系效率一定是非常低下，成本一定是非常高昂的。我们为什么要有静态类型，js写的不是很爽吗，为什么要发明ts？因为静态类型系统使得类型检查从运行期转移到了编译期，使得我们不执行代码就能保证代码里没有类型错误。同样的，就rust的重要特点：内存和并发安全而言，就是c++写的不是很爽吗，为什么要发明rust？因为rust的类型系统能够在编译期检查引用有效性和并发安全性，使得我们不执行代码就能保证代码里没有内存错误和并发不安全情况。我个人认为这一点比ts之于js还要重要，因为类型错误通过测试代码能保证检查的出来，而内存错误，尤其是不安全的并发，不但不能保证能检查出来，甚至实际出错点和错误暴露点相隔甚远，后期事后排查修复成本巨大，这基本上没有其他一门成熟语言可以做到。</p><p>关于义务和权利同样的类比：ts的代码因为采用了静态类型，导致一些非常动态/完全动态的代码无法表达，但又同时能随意as any as known绕过类型系统，将检查的义务返回给开发者，由开发者承担类型检查的责任和风险以换取表达上的自由不被类型系统所约束的权利。rust的代码因为采用了静态生命周期检查，导致一些生命周期非常动态/完全动态的代码无法表达，而只能将一些检查以某些手段延迟到运行期进行，但如果开发者对逻辑充满信心非常了解也不愿意牺牲性能，rust又能同时随意unsafe绕过类型系统，将检查的义务返回给开发者，由开发者承担生命周期检查的责任和风险以换取表达上的自由不被类型系统所约束的权利。</p><p>关于喜好同样的类比，大部分的人在写了ts之后就不愿意写js了，同样的少部分人无论如何都不愿意写ts，这不可强求，毕竟有些人生性自由不愿收到一点点限制。rust同样如此。但我想只要是写过一点成规模正经代码的，恐怕都能意识到我入行第一年意识到的问题，而作出正确的选择。从编程语言历史发展的角度来看，语言的发展几乎是往特性中添加约束的过程，汇编没有任何约束，后来提倡if else loop结构化的编程而避免goto，后来我们提倡RAII。。</p><p>相信对”权利和义务“ 的讨论能够说明一些所谓批评说rust写个链表都费劲的人其实是并不理解设计上的取舍，严谨和自由始终是相互平衡的，更严谨也并没有限制自由，所以这些批评是完全不成立的。</p><p>因为没有垃圾回收的语言过于危险和复杂，所以相当多的语言都牺牲了极致的性能来换取安全性。而rust成为第一个“我全都要”的语言，并且我认为做的相当成功，“A language empowering <strong>everyone</strong> to build <strong>reliable</strong> and <strong>efficient</strong> software.”</p><hr><p>除了更多的编译期检查带来的硬性约束，我想从几个具体的角度再来谈谈一些对项目山比较soft但是又solid的impact：</p><p>不使用unsafe及内部可变性的rust的代码无法表达任何包含自引用类型的数据结构，这使得正常情况下你的整体应用的数据结构会尽可能的形成一颗树，这潜在意义上意味着你没法轻易的随意引用不应该持有的数据，从而不得不完全的根据逻辑/模块设计数据结构，往往数据结构设计合理了，就成功一半了。如果不加思考的使用错误的设计，在后续写逻辑的时候编译器会非常抱怨，你又如果强行用rc refcell等内部可变性机制绕过，那么最后代码会写的很丑陋。这一层限制反而对项目质量产生了正面影响。</p><p>同样的，更多的约束带来更好的质量：语言为提供了数据访问能否独占的能力，在不使用内部可变性的情况下只要独占访问才能修改数据，一些好的模式可以利用这一特点来保证特定数据结构在给定环节不被意外修改，比如在webgpu renderpass录制command时，renderpass持有encoder来避免encoder调用mutable方法产生bug，比如webgl的ctx状态缓存，在给定drawcall提交时交由提交者独占，防止错误的状态同步。而这种独占对于阅读代码的效率也有正面作用，你很容易追踪这个链路上数据是如何被修改，访问，分享的。</p><p>虽然所有权让一些共享所有权的情况变得难受一点，也导致了上述数据组织上的额外思考，但从接口的角度而言，对比其他语言，引用/指针的所有权只能通过文档来说明，如果用户稍加不注意则会搞出可怕的事情来，而现在这种事情是不存在的了，我要是不move给你，你是没法持有我的数据的，ownership是编译器检查的，这就是对质量的强力保证。在对外结构的设计上也大可直接干脆和安全的多了。</p><p>因为没有继承的缘故，所以用户不得不以组合代替继承，以trait提取抽象，这虽然对于大部分熟悉于面向对象的开发者难以适应。但是！当你适应了从面向对象到面向数据的范式转变之后你就再也回不到过去了，关于DOD我不是很想再展开，当你顿悟了ECS，CGS，背后的深刻的灵活和强大，就能感受感受到思想上的解放。当你从数据和数据流的角度观察和编写程序，你仿佛就是在搭建一个处理数据的工厂流水线，安全精确的利用各种语言特性摆弄拼接各种形状的内存容器和算法来完成你的任务。而这一切都通过编码过程中和编译器的反复对话完成，不断的polish不断的演进。</p><p>除了数据思想，在接触这门语言另一个领悟是来自trait系统。我觉得trait完全不亚于内存安全，也值得算是杀手级的特性。一套语法同时统一编译期和运行期的多态，这才是真正的大道至简好不好（golang是什么垃圾）。我在rust编码过程中的最大乐趣就是写trait，trait真的是那种描述抽象最佳的做法，当你用trait把一些非常微妙的共性提取出来，把一些结构上数据上职责上的依赖，精确优美的切割的干净利落，能感受到一种逻辑上精神上的升华。当你需要极致性能的时候，泛型能展开内联调用生成高度优化的代码，当你需要动态灵活的时候，dyn trait又能轻松的把东西包装起来。即便我没怎么写过c++的人，阅读了effective c++时对其中的最佳实践，瞬间从等价的rust概念完成了相互理解（比如这里对应的虚函数，模版）之后，更觉得trait才是正确而优美的存在。</p><p>这里仅罗列了我的视角下比较亮眼之处，相信随着语言继续发展和使用的深入，有机会可撰写和记录更多心得。</p><hr><p>在过去的三个月，我已经开始在公司内fulltime写rust了，并且取得了非常正面的效果，完美解决了性能/质量方面的问题。这在过去恐怕是难以想象的。作为第一个吃螃蟹的人，在此诚实推荐这门语言👍</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;结合实际工作和编码的经验，谈一下rust这门编程语言，以及些非语言性质的领悟。&lt;/p&gt;&lt;p&gt;在2018年h2我在公司的工作内容很多方面涉及到修复令人头疼的内存释放不掉的问题。（我这里不再说内存泄漏了，因为脚本语言就没有内存泄漏的的概念。）但是即便有devtools的堆快照神
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>高性能Rust wasm最佳实践</title>
    <link href="http://mikialex.github.io/2020/11/21/high-perf-rust/"/>
    <id>http://mikialex.github.io/2020/11/21/high-perf-rust/</id>
    <published>2020-11-20T16:00:00.000Z</published>
    <updated>2020-11-20T18:23:32.374Z</updated>
    
    <content type="html"><![CDATA[<p>在我司项目里写rust一小段时间了。记得在前年年底（2018）小组聚餐的时候我第一次给前manager提rust这门语言的时候，完全是想不到我会有今天这样的机会。目前这个语言用于wasm的加速上，也是主要由我推动的。预计到明年上半年之前这么语言会在性能优化的主题上起到至关重要的作用，几乎所有的cpu端的重型计算模块，都会被迁移进rust实现的wasm内，并由wasm-bindgen提供接口供中层建筑调用，其性能提升的关键指标原型都已经得到了认证。经过这一段时间，以及我长期业余时间内的rust开发经验。这里简单谈一下性能方面的最佳实践。</p><h3 id="inline"><a href="#inline" class="headerlink" title="inline"></a>inline</h3><p>强烈建议对所有小函数都标记<code>#[inline]</code>,如果非常简短的函数调用可以标记<code>#[inline(always)]</code>。 比方说数学库，很多小函数，又比如说调用上的封装，都最好加上。虽然即便不加，在最高优化等级下，编译器也会自己做很多激进的inline，但是我遇到的几个case，只要我检查了调用上是否应该inline的地方，然后手工添加这些标记，大概都直接收获了10-20%的性能提升。</p><p>我是怎么发现关键的小函数没有inline呢，其实还是主要通过开发者工具profile工具的火焰图。正常情况下是不可能sample到小函数调用的，如果有，且整个逻辑不是非常复杂，那么就应该尝试inline。这里逻辑不是非常复杂指的是inline的结果如果造成函数体过大，因为代码cache命中降低的原因，反而会对性能产生影响。如果你的逻辑其实还是很复杂的，编译器完成inline以后，不一定能通过后续的优化，无论是死代码消除还是窥孔来减少代码量，还是会自行取消inline。</p><p>要特别注意高频率调用函数的inline情况，一般而言，如果有inline的可能，我们一定要确保inline。某些情况下这可能造成30-40%的性能差异。记得我的同事写了一段和排序相关的逻辑，结果比较原版的ts实现反而变慢了。我分析了wasm的变异结果，看到其比较函数没有inline，仔细分析比较函数的编译结果，发现逻辑过于复杂，其中包含了多个pattern match，所以为了触发inline，我简单的将比较函数内的pattern match移出，取而代之的编写多个比较函数来选择调用。这一做法的确奏效了，内联之后性能有了巨大提升。</p><p>inline是非常非常重要的事情，相当多的优化和分析都是函数内的，inline是触发后续优化的前提。除了上面函数体过大，还有一些原因使得inline无法发生也需要注意：</p><h3 id="dynamic-dispatch"><a href="#dynamic-dispatch" class="headerlink" title="dynamic dispatch"></a>dynamic dispatch</h3><p>我上周重构了一小段代码，但是写完发现性能稳定的衰退的20%。仔细看我的改动，发现造成性能衰退的原因是我改变了trait的抽象结构，导致其中一处高频的方法调用走了trait object的dynamic dispatch，而我改动之前是static dispatch。这真是教科书级别的例子（dynamic的性能慢于static dispatch）。</p><p>当然不是说dynamic dispatch一无是处，这个东西是非常好非常有用的，只不过我们要衡量好tradeoff，到底是不是我们愿意牺牲编译时间，代码体积翻倍膨胀，代码范型写的到处都是来换取20%的性能。如果是我这样的case，这个逻辑是如此的高频，我希望我为这个东西的每一种具体的实例化的类型都生成高度优化的代码，那么就要确保这个性能sensitive的地方要走static dispatch，编译器一定不能让我失望。而那些低频率的接口，dynamic其实是很有必要的，因为它完成了类型概括的功能，能让代码写的合理和简单。</p><p>我发现我对trait的摆弄，那些build nice abstractions的事情，其实无非是把原本存在于运行时的值中的信息编码到类型系统里，来大幅提升系统的类型上的安全保证和维护性。而很多时候你在代码中还是要抹去一些类型上的差异的，这就是dynamic dispatch存在的意义，它就是cpp的虚函数，它就是通过虚表来完成多个不同的类型间的统一。</p><p>dynamic的性能慢于static dispatch的原因很简单，就是不能内联了。因为代码调用走的是虚表，除非编译器有更全局的信息和推导，不到运行时是不能确定具体的函数调用。</p><h3 id="heap-allocation"><a href="#heap-allocation" class="headerlink" title="heap allocation"></a>heap allocation</h3><p>每一个对性能上点心的人都不会忽视堆内存分配的成本。如果你的代码出发了堆内存的分配和释放，那么inline就不可能的，而分配这件事情成本也很高，更别说触发wasm memeory grow，触发系统调用。如果可以，禁止不必要的堆内存分配，比如随随便便<code>Vec::new()</code>,等随意变出个容器，用两下扔了？</p><p>避免堆分配的另一个重要话题是，如果可以，严格预分配正确大小的内存，检查所有collect的迭代器都实现<code>size_hint</code>。不然你在高频操作时push/insert容器会触发容器扩容，如果是vec则会memcopy，如果是hashmap则会是代价更加高昂的rehash。在我的实践中这大概能减少了1-2ms的时间。</p><h3 id="尽可能避免高频使用智能指针操作"><a href="#尽可能避免高频使用智能指针操作" class="headerlink" title="尽可能避免高频使用智能指针操作"></a>尽可能避免高频使用智能指针操作</h3><p>这里不是指不用，而是Rc， Arc， RefCell的某些调用开销比你想象的要高。如果追求性能，则不应在高频部分做引用计数增减，borrow等操作。这些操作事实上很多时候把内存读附加了一次内存写。inline废了，cache也受到影响。</p><h3 id="如无必要，不要使用hashmap"><a href="#如无必要，不要使用hashmap" class="headerlink" title="如无必要，不要使用hashmap"></a>如无必要，不要使用hashmap</h3><p>rust标准库的hashmap有simd的加速，wasm simd还没做完。</p><p>即便非要用记得换更高性能但是没有密码学安全的hasher实现</p><h3 id="避免不必要的大对象clone-move"><a href="#避免不必要的大对象clone-move" class="headerlink" title="避免不必要的大对象clone/move"></a>避免不必要的大对象clone/move</h3><p>wasm的memcopy没有simd支持，相关标准可能还在设计，要比native慢很多。</p><p>不过这个平时都很注意的，没啥可说的</p><h3 id="严格禁止高频wasm-IO"><a href="#严格禁止高频wasm-IO" class="headerlink" title="严格禁止高频wasm IO"></a>严格禁止高频wasm IO</h3><p>IO性能很差，千万别乱来。实践上还是走批处理的做法，获取指针位置/大小，从js侧建立数据的view，按布局直接批量直接读写，这个是最佳实践。其他要是小接口，或者没啥高频调用的，走wasm-bindgen也挺好。</p><h3 id="Prefer-struct-of-array"><a href="#Prefer-struct-of-array" class="headerlink" title="Prefer struct of array"></a>Prefer struct of array</h3><h3 id="了解编译原理，了解编译结果，了解底层"><a href="#了解编译原理，了解编译结果，了解底层" class="headerlink" title="了解编译原理，了解编译结果，了解底层"></a>了解编译原理，了解编译结果，了解底层</h3><p>建议对性能有追求的同学，学习编译原理后端优化方面的内容。这样你能很自信知道你代码里的漂亮写法是零开销抽象，你能知道哪些事情哪些做法不是free的。阅读编译结果，调整抽象，调整hint，和编译器一起完成工作。同样的，你对其他底层知识知道的越多，优化的空间就越大。</p><h3 id="数据驱动"><a href="#数据驱动" class="headerlink" title="数据驱动"></a>数据驱动</h3><p>这里推荐一下rust一个benchmark的框架 <a href="https://github.com/bheisler/criterion.rs，看起来比较高端也好用。" target="_blank" rel="noopener">https://github.com/bheisler/criterion.rs，看起来比较高端也好用。</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在我司项目里写rust一小段时间了。记得在前年年底（2018）小组聚餐的时候我第一次给前manager提rust这门语言的时候，完全是想不到我会有今天这样的机会。目前这个语言用于wasm的加速上，也是主要由我推动的。预计到明年上半年之前这么语言会在性能优化的主题上起到至关重
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ECS的一些理解</title>
    <link href="http://mikialex.github.io/2020/08/25/ecs-2020/"/>
    <id>http://mikialex.github.io/2020/08/25/ecs-2020/</id>
    <published>2020-08-24T16:00:00.000Z</published>
    <updated>2020-09-09T11:39:37.903Z</updated>
    
    <content type="html"><![CDATA[<p>我不认为ECS是专门为了解决游戏逻辑而存在的架构思想，而是一种全新的，一般的，普适的建模方法。游戏领域更容易暴露出传统面向对象体系下的各种问题而prefer ECS，但这并不是将这种架构思想限制于游戏的理由。ECS我认为是一种比面向对象更加一般，更加优秀的建模方法。</p><p>在面向对象中，当我们描述世界中某个概念，某个实体，就会写新的class，或者继承某些已有的class，我要继承某个对象，往往为的是往上面添加某些新的行为/方法，或者数据。继承结构是编译期确定的，在运行时，每一种类的能力都不能发生变化。</p><p>但ECS中，我们的做法是，组合一些component，或者添加新的component类型并组合，组合的结果是entity。任何概念和实体都是entity。原先用类描述一个物体，现在我们用entity。如果我要给某个entity添加新的数据/能力，那么我就添加它需要的component。相比面向对象，由于entity只是component的组合，所以任何物体，在运行时可以动态增加/删除 行为和能力，这个相比编译期的类非常非常灵活。面向对象的类，其能力和行为都是通过静态的继承树/图（多继承）完成的，不可变的。但在ECS中，一个实体，具体有什么能力/行为，这个东西本身就被数据化了，数据化的结果就是可以让我们在运行时能够添加修改删除查询任意实体的能力和行为。我想这是一种建模思想和建模能力的飞跃。</p><p>我想，很多架构上的改进，或者说设计模式，其实本质上就是将原先写死在代码里的逻辑，数据化，使得原先不灵活的东西，变成灵活的可操控的东西，以应对需求变化/演进，甚至你可以针对数据化的逻辑写代码。举一些例子比如观察者模式，如果没有观察者模式，那么对象之间的依赖，通信，都只能是写死在各个类上的方法，这个类call另一个类，在代码里写死调用，写死依赖。而观察者模式本质上把这种依赖数据化了，原先写死的方法调用依赖，变成统一装载在eventdispatcher里回调函数，变成了一个function的array，每一个function都是原先的依赖，数据化的结果就是对象直接可以动态的建立联系，on off emit，而不是写死在代码里。 又比如我们实现的rendergraph框架，也是把整个复杂的多变的渲染流程描述变成了数据，正因为完成了数据化，我们才能实现针对这种数据的逻辑，即自动依赖分析等。所以我一直觉得，架构改进，就是数据化的过程，而数据化的终极形态，就是ecs，ecs里我们都不会为了世界中的实体写类了，任何东西都是组合出来的，任何东西都是数据的组合。everthing is about data.</p><p>在ecs中，你的所有东西，或者说你的世界，你的场景，你的业务数据，事实上全部都在一个database中。entity就是这个database的index，你可以想想一个巨大的table，每一列是一种component类型，每一行是entity，里边单元格装着component的实例。 你的everything都在这里边，无比的simple，整齐，统一，只有数据。这是EC</p><p>那么数据都在这里整齐的放置着，我的业务逻辑呢，这就是S， System。逻辑其实就是处理数据的过程，system就是一个处理过程的单元，具体怎么处理数据呢，很简单，我们有个database，那么你在这个database上运行某些查询条件，读取你关心的数据，做处理，再写入你指定的地方。仿佛就是写web后端一样，模式高度简单统一。我们实际的逻辑其实比较复杂，应该拆分成若干小的sysytem，这些小的system就实现了处理逻辑的复用（对应的数据字段的复用体现在component组合上）。每一个system可能依赖其他system，那么事实上整个system构成了有向无环图，和rendergraph一样。这下，事实上正如同我们解决渲染pass间的依赖关系一样，逻辑之间的依赖关系也被自动解决了。。更amazing的是，由于依赖关系变成数据（图），多线程瞬间就支持了，systemgraph的执行器完全可以搞threadpool发任务。我们知道多线程很恶心数据竞争的问题，事实上这个也瞬间被解决了，因为你声明system的时候，system要运行的EC数据库查询条件，无论是写还是读，都是确定的，所以执行器完全可以判断某个时刻EC数据库的哪些部分正在被哪些sysytem进行访问，避免同时写就ok了。更amazing的是由于ec的存储基本都是array，稍加考虑缓存命中都相对随机访问很好，性能会有额外的好处，在我看到的ecs的实现中，有的甚至有在budget时间内整理内存的接口来优化这个事情。</p><p>下面，我简单设想一下如果将ecs作为场景层架构，具体的形态可能是怎么样的：</p><p>matrix, worldMatrix, modelViewMatrix，或者说，所有的uniformLike的数据 全部都是独立的component，这样，只有拥有这些component的物体才会被更新这些数据，而不是像现在一样统一更新（毕竟可能有些物体的绘制不需要matrix）同理，任意一种uniformlike的数据，也都是按需被组合在entity上，会有具体的system完成他们的更新，不会有额外的数据，不会有额外的逻辑。</p><p>层次结构： 层次结构是个component，具体的数据是parent和children的entityID.</p><p>如何完成变化监测：我能想到有两种思路： 1 事实上任意一种component，我们可以统一支持其额外的state，就是自上一次同步前，哪些change，add，delete，sysytem在查询数据库时，可以为某些component的查询附加额外的查询条件，比如我只想查询所有上次同步前所有新加的的 A component ，另一种思路2，是component对应的change信息也是数据，也是component，我们提供一个封装良好的结构，可以让用户包装某些component，使其实际变成多个component并实现change的功能</p><p>场景更新流程：每一种场景内容相关的component，都应当实现上面提到的watchable的装饰。所以更新的系统们可以完整知道整个场景数据的change情况，便可以执行更新逻辑。以我们现有的更新逻辑同步举例：</p><p>step0 业务逻辑完成场景更新</p><p>这部分是业务逻辑，不属于引擎范畴，如果业务逻辑也是ecs，那么这里放的是业务逻辑的sysytem</p><p>step1 完成层次结构的更新（matrix，visible等受层次结构影响的数据）</p><p>查询所有 （有层次结构组件，所有可能有（任意受层次结构影响 且 发生变更）的若干组件），<br>system逻辑触发所有子tree change，change标记在层次结构组件上<br>forach所有发生变更的组件，完成更新，其中，各种component各自从parent更新的方法使用一个统一的特殊trait约束，其中更新方法对数据需求都是optional的，因为更新的组件这时候也是optional的</p><p>step2 完成GPU数据更新</p><p>查询所有ubo，vao，vbo，ibo，texture，sample，所有的GPU资源的变更组件，各种sysytem完成更新操作</p><p>step3 drawcalllist 生成和剔除</p><p>查询所有renderobject（drawcall）这个也是component，但这个component里其实是其他component的ID，表现上看起来是entity）且具有Bounding的component。走剔除system得到rawlist多pass，每个节点依赖的camera是不一样的，所以这个system会被调用多次，生成的list本身也是component。其他drawcalllist 过滤，分叉，变换都是各个实现好的sysytem，读写listcomponent数据</p><p>step4 rendergraph execution</p><p>因为rendergraph和system dispatch graph本质是一样的，所以新的系统会使用一套实现，你可以理解成，整个ECS系统的dispatch部分，就是rendergraph。 每个pass是system，每个pass前的小更新操作也是system。整个引擎使用一整套Systemgraph作为流程抽象和逻辑组织，整个场景使用一个Entity Component数据库存储所有绘制信息</p><p>最后我对ecs还有一些疑虑之处比如：</p><p>前文我提到某些component事实上有些数据是其他的component的reference（ID）。所以事实上我们是通过typed id来完成引用关系的数据化，那么数据删除的话，id失效怎么办，难道runtime check and panic吗。所以我们针对这种reference的data，需要提供引用计数回收吗？ 如果你认为entity本身也是一个component，事实上为什么不呢？所以最后的概念模型就是我有一堆的component，这些component以id的形式相互引用，这感觉就像是一堆heap一样，每个id就是某个heap内的指针（地址），感觉就是自己维护了堆。。如果从这个角度想，那要真的正确回收component，引用计数能work，似乎再搞个garbage collection 也没什么问题？</p><p>将数据拆分成多个component，我的另一个疑虑是是否会增加额外的遍历次数和成本，在没有ecs的情况下，我要的数据的访问往往可以集中在一次循环中完成，而且不需要动态的根据条件来过滤component组合，这其实也是额外的开销。当然我也知道基于原型的ecs可以解决这个问题，但也会引入其他问题，总觉得还是有tradeoff存在</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我不认为ECS是专门为了解决游戏逻辑而存在的架构思想，而是一种全新的，一般的，普适的建模方法。游戏领域更容易暴露出传统面向对象体系下的各种问题而prefer ECS，但这并不是将这种架构思想限制于游戏的理由。ECS我认为是一种比面向对象更加一般，更加优秀的建模方法。&lt;/p&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>使用Rust trait 抽象三维几何数据类型</title>
    <link href="http://mikialex.github.io/2020/08/23/abs-geometry/"/>
    <id>http://mikialex.github.io/2020/08/23/abs-geometry/</id>
    <published>2020-08-22T16:00:00.000Z</published>
    <updated>2020-08-23T07:02:29.757Z</updated>
    
    <content type="html"><![CDATA[<p>在对rust的trait， generics等概念有了一定理解后，我尝试集中编写一些三维几何数据的容器类作为渲染引擎的基础库。</p><p>如果你对three.js比较了解的话，我这里做的，其实就是使用rust编写Geometry，BufferGeometry等容器类，three的geometry写的是很挫的，寄希望于rust这门优秀的语言，我试图提升一下自我要求，比如：</p><ul><li>尝试将拓扑信息编码在类型之中，这样假设我有一个描述以triangleList为布局的几何数据，不应该赋值给一个以trianglestrip为布局的几何数据。</li><li>可以使用任何用户自定义的顶点数据结构</li><li>提供一个统一的图元迭代器，图元的类型由拓扑类型决定</li><li>同时支持index/无index， interleaved/非interleaved的buffer数据</li></ul><h2 id="统一interleaved和非interleaved的数据"><a href="#统一interleaved和非interleaved的数据" class="headerlink" title="统一interleaved和非interleaved的数据"></a>统一interleaved和非interleaved的数据</h2><p>我们正常在opengl/webgl中使用的数据都是非interleaved的，比如一般来说position是一个单独的buffer，normal也是一个单独的buffer，uv也是。而interleaved版本是position + normal + uv交替存储，只使用一个buffer。</p><p>虽然我一般都是使用非interleave版本，但事实上interleaved才是较为原始的数据存储，假设你如下定义一个struct，标记内存布局使用C语言标准。对于一个<code>Vec&lt;Vertex&gt;</code>, 它的内存事实上完全就是interleaving的，你可以直接transmute一下上传，没有多余的拷贝。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[repr(C)]</span></span><br><span class="line"><span class="meta">#[derive(Clone, Copy, soa_derive::StructOfArray)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Vertex</span></span> &#123;</span><br><span class="line">  <span class="keyword">pub</span> position: Vec3&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">  <span class="keyword">pub</span> normal: Vec3&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">  <span class="keyword">pub</span> uv: Vec2&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> my_geometry_data: <span class="built_in">Vec</span>&lt;Vertex&gt;;</span><br></pre></td></tr></table></figure><p>而我们常用的非interleave版本本质上是这个：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">VertexArray</span></span> &#123;</span><br><span class="line">  <span class="keyword">pub</span> position: <span class="built_in">Vec</span>&lt;Vec3&lt;<span class="built_in">f32</span>&gt;&gt;,</span><br><span class="line">  <span class="keyword">pub</span> normal: <span class="built_in">Vec</span>&lt;Vec3&lt;<span class="built_in">f32</span>&gt;&gt;,</span><br><span class="line">  <span class="keyword">pub</span> uv: <span class="built_in">Vec</span>&lt;Vec2&lt;<span class="built_in">f32</span>&gt;&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> my_geometry_data: VertexArray;</span><br></pre></td></tr></table></figure><p>本质上就是struct of array 和 array of struct 的区别。你也看到，我在Vertex上标记<code>soa_derive::StructOfArray</code>, 这个库可以为我们自动生成 struct of array版本的类型，并实现<code>As&lt;[T]&gt; + Index&lt;usize&gt;</code>这两个trait, 这使得两种容器类型在使用上一模一样。</p><p>所以和这个抹平差异的思想一致。实际数据的存储上，容器要满足的trait是：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">GeometryDataContainer</span></span>&lt;T&gt;:</span><br><span class="line">  <span class="built_in">AsRef</span>&lt;[T]&gt; + <span class="built_in">Clone</span> + Index&lt;<span class="built_in">usize</span>, Output = T&gt; + FromIterator&lt;T&gt;</span><br><span class="line">&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 为普通vec实现</span></span><br><span class="line"><span class="keyword">impl</span>&lt;T: <span class="built_in">Clone</span>&gt; GeometryDataContainer&lt;T&gt; <span class="keyword">for</span> <span class="built_in">Vec</span>&lt;T&gt; &#123;&#125;</span><br><span class="line"><span class="comment">// 为自动的soa derive实现</span></span><br><span class="line"><span class="keyword">impl</span>&lt;T: StructOfArray, A: T::ArrayType&gt; GeometryDataContainer&lt;T&gt; <span class="keyword">for</span> A &#123;&#125;</span><br></pre></td></tr></table></figure><h2 id="顶点，拓扑，和图元的trait约束"><a href="#顶点，拓扑，和图元的trait约束" class="headerlink" title="顶点，拓扑，和图元的trait约束"></a>顶点，拓扑，和图元的trait约束</h2><p>一个几何由很多顶点构成，先不考虑有没有index，这些顶点每一个/两个/三个 形成一个三角形/线段/点，如果再考虑是list还是strip，又可分为每过一个图元步进几个顶点数据。这些如何使用trait来抽象呢？</p><p>先看顶点，这里我们把问题再放窄一点，要求顶点必须是能提供3d空间点的信息， 3d空间点也不再加一层泛型，就f32吧，所以所有顶点应该实现这个trait：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">Positioned3D</span></span>: <span class="built_in">Copy</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">position</span></span>(&amp;<span class="keyword">self</span>) -&gt; Vec3&lt;<span class="built_in">f32</span>&gt;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>顶点构成图元， 图元的约束可以是这样：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">PrimitiveData</span></span>&lt;T: Positioned3D&gt; &#123;</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">IndexIndicator</span></span>;</span><br><span class="line">  <span class="keyword">const</span> DATA_STRIDE: <span class="built_in">usize</span>;</span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">from_indexed_data</span></span>(index: &amp;[<span class="built_in">u16</span>], data: &amp;[T], offset: <span class="built_in">usize</span>) -&gt; <span class="keyword">Self</span>;</span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">create_index_indicator</span></span>(index: &amp;[<span class="built_in">u16</span>], offset: <span class="built_in">usize</span>) -&gt; Self::IndexIndicator;</span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">from_data</span></span>(data: &amp;[T], offset: <span class="built_in">usize</span>) -&gt; <span class="keyword">Self</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>来看几个impl可能会更清楚：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T: Positioned3D&gt; PrimitiveData&lt;T&gt; <span class="keyword">for</span> Triangle&lt;T&gt; &#123;</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">IndexIndicator</span></span> = Triangle&lt;<span class="built_in">u16</span>&gt;;</span><br><span class="line">  <span class="keyword">const</span> DATA_STRIDE: <span class="built_in">usize</span> = <span class="number">3</span>;</span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">from_indexed_data</span></span>(index: &amp;[<span class="built_in">u16</span>], data: &amp;[T], offset: <span class="built_in">usize</span>) -&gt; <span class="keyword">Self</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> a = data[index[offset] <span class="keyword">as</span> <span class="built_in">usize</span>];</span><br><span class="line">    <span class="keyword">let</span> b = data[index[offset + <span class="number">1</span>] <span class="keyword">as</span> <span class="built_in">usize</span>];</span><br><span class="line">    <span class="keyword">let</span> c = data[index[offset + <span class="number">2</span>] <span class="keyword">as</span> <span class="built_in">usize</span>];</span><br><span class="line">    Triangle &#123; a, b, c &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">create_index_indicator</span></span>(index: &amp;[<span class="built_in">u16</span>], offset: <span class="built_in">usize</span>) -&gt; Self::IndexIndicator &#123;</span><br><span class="line">    <span class="keyword">let</span> a = index[offset];</span><br><span class="line">    <span class="keyword">let</span> b = index[offset + <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">let</span> c = index[offset + <span class="number">2</span>];</span><br><span class="line">    Triangle &#123; a, b, c &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">from_data</span></span>(data: &amp;[T], offset: <span class="built_in">usize</span>) -&gt; <span class="keyword">Self</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> a = data[offset];</span><br><span class="line">    <span class="keyword">let</span> b = data[offset + <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">let</span> c = data[offset + <span class="number">2</span>];</span><br><span class="line">    Triangle &#123; a, b, c &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T: Positioned3D&gt; PrimitiveData&lt;T&gt; <span class="keyword">for</span> LineSegment&lt;T&gt; &#123;</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">IndexIndicator</span></span> = LineSegment&lt;<span class="built_in">u16</span>&gt;;</span><br><span class="line">  <span class="keyword">const</span> DATA_STRIDE: <span class="built_in">usize</span> = <span class="number">2</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>DATA_STRIDE</code>就是上文提到的数据宽度，三个方法就是具体从一个slice里读取并构造出图元的实现，IndexIndicator辅助支持indexgeometry。这个trait配合上面的容器抽象，我们就可以在容器的指定位置读取图元。</p><p>基于顶点和图元，我们还需要描述拓扑的信息，显然，拓扑可以使用零尺寸类型表达</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">PrimitiveTopology</span></span>&lt;T: Positioned3D&gt; &#123;</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">Primitive</span></span>: PrimitiveData&lt;T&gt;;</span><br><span class="line">  <span class="keyword">const</span> STRIDE: <span class="built_in">usize</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里不多举例，可以看到拓扑这个trait同时link了对顶点的约束，以及对应的图元类型，和步进长度</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">TriangleList</span></span>;</span><br><span class="line"><span class="keyword">impl</span>&lt;T: Positioned3D&gt; PrimitiveTopology&lt;T&gt; <span class="keyword">for</span> TriangleList &#123;</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">Primitive</span></span> = Triangle&lt;T&gt;;</span><br><span class="line">  <span class="keyword">const</span> STRIDE: <span class="built_in">usize</span> = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">TriangleStrip</span></span>;</span><br><span class="line"><span class="keyword">impl</span>&lt;T: Positioned3D&gt; PrimitiveTopology&lt;T&gt; <span class="keyword">for</span> TriangleStrip &#123;</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">Primitive</span></span> = Triangle&lt;T&gt;;</span><br><span class="line">  <span class="keyword">const</span> STRIDE: <span class="built_in">usize</span> = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="构造我们的几何类型"><a href="#构造我们的几何类型" class="headerlink" title="构造我们的几何类型"></a>构造我们的几何类型</h2><p>Index和非Index版本的数据结构如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">IndexedGeometry</span></span>&lt;</span><br><span class="line">  V: Positioned3D = Vertex,</span><br><span class="line">  T: PrimitiveTopology&lt;V&gt; = TriangleList,</span><br><span class="line">  U: GeometryDataContainer&lt;V&gt; = <span class="built_in">Vec</span>&lt;V&gt;,</span><br><span class="line">&gt; &#123;</span><br><span class="line">  <span class="keyword">pub</span> data: U,</span><br><span class="line">  <span class="keyword">pub</span> index: <span class="built_in">Vec</span>&lt;<span class="built_in">u16</span>&gt;,</span><br><span class="line">  _v_phantom: PhantomData&lt;V&gt;,</span><br><span class="line">  _phantom: PhantomData&lt;T&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">NoneIndexedGeometry</span></span>&lt;</span><br><span class="line">  V: Positioned3D = Vertex,</span><br><span class="line">  T: PrimitiveTopology&lt;V&gt; = TriangleList,</span><br><span class="line">  U: GeometryDataContainer&lt;V&gt; = <span class="built_in">Vec</span>&lt;V&gt;,</span><br><span class="line">&gt; &#123;</span><br><span class="line">  <span class="keyword">pub</span> data: U,</span><br><span class="line">  _v_phantom: PhantomData&lt;V&gt;,</span><br><span class="line">  _phantom: PhantomData&lt;T&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>基于这两种geometry，配合上面的一些内容，可以直接实现出图元的迭代器，包括ExactSizeIterator。很简单，这里就不放出实现了。</p><p>可以看到我们有两个geometry，有index的和无index的，这应该需要统一一下。他们应该要实现同一个trait，这个trait应该是几何数据最基础的trait。 从抽象的角度来看，我们只关心图元，应该是要能返回图元的ExactSizeIterator，以及图元的随机访问能力。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">AbstractGeometry</span></span>: <span class="built_in">Sized</span> &#123;</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">Vertex</span></span>: Positioned3D;</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">Topology</span></span>: PrimitiveTopology&lt;Self::Vertex&gt;;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">wrap</span></span>&lt;<span class="symbol">'a</span>&gt;(&amp;<span class="symbol">'a</span> <span class="keyword">self</span>) -&gt; AbstractGeometryRef&lt;<span class="symbol">'a</span>, <span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">    AbstractGeometryRef &#123; wrapped: <span class="keyword">self</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">primitive_iter</span></span>&lt;<span class="symbol">'a</span>&gt;(&amp;<span class="symbol">'a</span> <span class="keyword">self</span>) -&gt; AbstractPrimitiveIter&lt;<span class="symbol">'a</span>, <span class="keyword">Self</span>&gt; &#123;</span><br><span class="line">    AbstractPrimitiveIter(<span class="keyword">self</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">primitive_at</span></span>(</span><br><span class="line">    &amp;<span class="keyword">self</span>,</span><br><span class="line">    primitive_index: <span class="built_in">usize</span>,</span><br><span class="line">  ) -&gt; <span class="built_in">Option</span>&lt;&lt;Self::Topology <span class="keyword">as</span> PrimitiveTopology&lt;Self::Vertex&gt;&gt;::Primitive&gt;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为返回的迭代器势必要对源数据保持一个借用关系，如果我要把这个迭代器的类型写进AbstractGeometry的关联类型的话，会有个生命周期参数要填。为了解决这个问题我参考了一些做法做了一些尝试，最后做法是再间接return中间的迭代器结构，让这个中间的迭代器实现IntoIterator，而这个实现我们在为AbstractGeometry实现一些通用方法的时候加上这个trait约束即可，其中生命周期参数通过HRTB注入。比如下面这个为<strong>所有几何类型实现获得光线相交点的列表</strong>的实现：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">'a</span>, V, P, T, G&gt; IntersectAble&lt;AbstractGeometryRef&lt;<span class="symbol">'a</span>, G&gt;, IntersectionList3D, Config&gt; <span class="keyword">for</span> Ray3</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">  V: Positioned3D,</span><br><span class="line">  P: IntersectAble&lt;Ray3, NearestPoint3D, Config&gt; + PrimitiveData&lt;V&gt;,</span><br><span class="line">  T: PrimitiveTopology&lt;V, Primitive = P&gt;,</span><br><span class="line">  G: AbstractGeometry&lt;Vertex = V, Topology = T&gt;,</span><br><span class="line">  <span class="keyword">for</span>&lt;<span class="symbol">'b</span>&gt; AbstractPrimitiveIter&lt;<span class="symbol">'b</span>, G&gt;: <span class="built_in">IntoIterator</span>&lt;Item = T::Primitive&gt;,</span><br><span class="line">&#123;</span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">intersect</span></span>(&amp;<span class="keyword">self</span>, geometry: &amp;AbstractGeometryRef&lt;<span class="symbol">'a</span>, G&gt;, conf: &amp;Config) -&gt; IntersectionList3D &#123;</span><br><span class="line">    IntersectionList3D(</span><br><span class="line">      geometry</span><br><span class="line">        .primitive_iter()</span><br><span class="line">        .into_iter()</span><br><span class="line">        .filter_map(|p| p.intersect(<span class="keyword">self</span>, conf).<span class="number">0</span>)</span><br><span class="line">        .collect(),</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个实现等价于threejs分散在各个class内的raycast方法，在我们的抽象体系下只有短短这么一点。从类型上可以看到，除了为了支持AbstractGeometry的trait约束，我只要要求图元实现了和光线相交的trait，那么任意满足这组约束的几何就可以直接支持这个行为。而由于完全是静态的trait的分发，编译时rust会根据你实际使用到的所有可能的图元/顶点/拓扑/几何/类型的组合生成代码，然后再层层内联高度优化，而这些代码原先都是手写的，科学技术真是第一生产力。</p><p>通用渲染用的mesh几何数据的实现还在开发中，实际实现可参考：<br><a href="https://github.com/mikialex/rendiation/tree/master/mesh-buffer/src/geometry" target="_blank" rel="noopener">https://github.com/mikialex/rendiation/tree/master/mesh-buffer/src/geometry</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在对rust的trait， generics等概念有了一定理解后，我尝试集中编写一些三维几何数据的容器类作为渲染引擎的基础库。&lt;/p&gt;&lt;p&gt;如果你对three.js比较了解的话，我这里做的，其实就是使用rust编写Geometry，BufferGeometry等容器类，th
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>RenderGraph review</title>
    <link href="http://mikialex.github.io/2020/08/14/render-graph-2020/"/>
    <id>http://mikialex.github.io/2020/08/14/render-graph-2020/</id>
    <published>2020-08-13T16:00:00.000Z</published>
    <updated>2020-09-09T11:45:01.077Z</updated>
    
    <content type="html"><![CDATA[<p>一个图形框架主要分为两部分，描述画什么以及怎么画，前者往往抽象为场景，而后者就是我们要讨论的主题。</p><p>我们目前见到的绝大多数渲染框架，都主要集中在资源的角度来进行抽象，比如geometry， material，这些抽象为库的使用者减少和抹去了管理创建资源，以及渲染的实现的负担。但是这些库并没有在如何组织渲染流程上提供太多的抽象。在面对复杂的后处理，多个pass间的依赖关系时，这些依赖一般都是手工维护，rendertarget的复用也是需要手工维护，当这些依赖关系需要由多项配置决定时，整个事情就非常难做了，以至于变成工程上不可能的事情。</p><p>去年我在artgl里通过一些业余实践实现了一套渲染流程上的框架，称之为rendergraph： 用户通过一套声明式的api构建pass/target依赖的有向无环图，框架完成依赖解析，fbo重用，等工作。最后可以说解决的非常干净漂亮。这套体系经过定制修改目前已经集成于实际工程项目，一举解决了诸多维护性上的问题。</p><p>现在回想整个设计过程和解决方案，给我带来几个关键的认识：</p><h3 id="尽可能从data-flow的角度思考解决问题，而不是传统的control-flow。"><a href="#尽可能从data-flow的角度思考解决问题，而不是传统的control-flow。" class="headerlink" title="尽可能从data flow的角度思考解决问题，而不是传统的control flow。"></a>尽可能从data flow的角度思考解决问题，而不是传统的control flow。</h3><p>如果没有graph，所有的数据依赖处理，都是分散在各个pass的类里，由大量的配合外部配置项的if else所决定，通过控制流来决定一步一步该做什么，控制流的代码是写死的，写死在各个类的方法里。</p><p>在graph下，核心其实变成了数据流，api直接描述数据间的依赖关系，框架来组织什么数据在什么时候需要给谁。而原本的控制流即实际的依赖关系，或者说流程，是通过运行时计算出的，而不是靠控制流写死在代码里。</p><h3 id="流程即是数据，数据即是流程"><a href="#流程即是数据，数据即是流程" class="headerlink" title="流程即是数据，数据即是流程"></a>流程即是数据，数据即是流程</h3><p>这个基本上就是代码即是数据，数据即是代码的一个小的体现。</p><p>前面说到 原本的控制流即实际的依赖关系，或者说流程，是通过运行时计算出的。这个计算结果简单说比如就是拓扑排序的结果，这个结果就包含了这个流程完整的内容，不多不少。就是一个array，就是数据。这个数据，这个实际的流程，我们也是直接cache的。对于任意一个能影响图结构的配置项，直接计算出流程或者从cache得到。将代码/算法/流程直接变成数据。</p><p>理论上如果我们知道会用到的配置组合，那么从这个数据直接生成流程的代码也是可行的，不过没什么意义。只是计算到底是编译期还是运行期的问题。</p><p>没有graph，执行流程是写死在代码里超集，通过配置和控制流代码来决定哪些部分真的要执行，直接造成了实现上的灾难</p><h3 id="graph这个设计是通用做法，正常做法"><a href="#graph这个设计是通用做法，正常做法" class="headerlink" title="graph这个设计是通用做法，正常做法"></a>graph这个设计是通用做法，正常做法</h3><p>我后来了解到很多桌面端的引擎，都采取了graph结构。我觉得他们不得不用，为什么，因为比如vulkan，要是不用图我觉得代码就没法写了。vulkan 是要你自己完全控制各个pass间的依赖的，这包括但不仅限于你要在target和pass依赖的点，各种数据的依赖点自己加semaphore，内存屏障，各种同步源语，不然你根本不知道什么时候gpu真正执行到哪个pass，不知道什么时候可以拿到正确的数据。</p><p>事实上，在有的游戏引擎中，整个流程，不仅是渲染部分也使用了graph的架构，rendergraph，解决的是渲染数据流的问题，而相同的思想用来解决gameplay部分的数据依赖完全是没有问题的，整个游戏引擎，整个世界更新逻辑就是一个超大的graph，渲染只是其中一部分。</p><h3 id="基于graph，我们还能做更多优化"><a href="#基于graph，我们还能做更多优化" class="headerlink" title="基于graph，我们还能做更多优化"></a>基于graph，我们还能做更多优化</h3><p>为了解决依赖问题，拓扑排序就够了。但是有了graph我们能做更多事情。</p><p>就 fbo 重用来说，目前很简单就是按需重用，没有主动优化。什么意思呢：一个graph，满足拓扑顺序的结果有很多，如果真的要好的fbo重用，我们应该找到这个解的集合中fbo并行量最小的一个。所以fbo重用就变成了一个图优化的问题。</p><p>又比如，现在对于每个effect，假设需要depth，那么我自己做图构建的时候，还是要手工的重用depth对应pass的node，比如从外层传入这个node。ok，事情变复杂了以后我怎么保证我能靠人肉充分复用某些pass的计算呢。从理想的角度，我希望我不要考虑这些事情，让框架自动找到可复用的pass计算。这种重用本质上是流程的重用，而本质上是另一个图优化的问题，如何识别和复用图中的子结构的问题。</p><p>那么state切换方面的优化是不是图的问题呢，我想过其实也使得，不过这个是scenegraph，就不展开了。</p><h3 id="Rendering-engines-are-becoming-compilers"><a href="#Rendering-engines-are-becoming-compilers" class="headerlink" title="Rendering engines are becoming compilers"></a>Rendering engines are becoming compilers</h3><p>比如你手工的提取出可以复用的depth pass计算，和本质上你在一个函数里手工提出重复计算并无不同。而事实上编译器的确是能优化重复计算的，优化重复计算也是把代码转化成计算图解决图优化的问题。</p><p>如果说整个3d框架，渲染引擎，流程上本质就是生成，优化，执行一个数据流图，那和一个compiler后端有什么区别呢？</p><p>我现在搞了套很漂亮的api来做图构建，本质上也太低级，那似乎搞一套dsl也是没啥问题的，正好对应compiler前端，设计一套更高层次的流程描述出来？</p><p>其实如果将renderengine视为compiler的，那不是那种静态的AOT的，而是JIT的，意思是对于执行结果，其实是有feedback的，既然有feedback，那就可以做优化的。我认为render engine as complier最终极的方向，就是compiler能根据实际的场景数据执行情况，分析出场景特点，分析出绘制瓶颈，动态实现各种优化行为。比如配合其他子系统比如场景，动态优化调整输入。配合降级体系，自动挑选最优的效果降级方案，这种降级不是关掉某个pass那么简单，而是能实时获得底层gpu情况，精确的调整某些sample count，size这类。</p><p>当然这个脑洞目前很大，工程上做出来也很有挑战，我相信一些成熟引擎已经开始这个方向的转变了，很有意思。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一个图形框架主要分为两部分，描述画什么以及怎么画，前者往往抽象为场景，而后者就是我们要讨论的主题。&lt;/p&gt;&lt;p&gt;我们目前见到的绝大多数渲染框架，都主要集中在资源的角度来进行抽象，比如geometry， material，这些抽象为库的使用者减少和抹去了管理创建资源，以及渲染
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>跨平台着色组件实现思考</title>
    <link href="http://mikialex.github.io/2020/06/25/shading-component/"/>
    <id>http://mikialex.github.io/2020/06/25/shading-component/</id>
    <published>2020-06-24T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.629Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>去年在artgl中实践了一种以着色组件(Shading component)的材质系统实现，用户通过编写独立的组件并组合这些组件形成完整的shader材质， 每个组件持有自己的材质数据，实现uniform等输入数据的上传，实现shader着色逻辑的注入。 今年年中，就是现在，我在做rendiation的跨平台渲染的场景描述层实现，其中材质的中间层系统被称之为着色抽象层，我认为基于着色组件的材质系统应该是一个非常好的材质框架设计方向，所以我尝试在rust中复刻及重新思考和打磨这一块的API设计，作为rendiation的着色抽象层的框架实现。</p><p>现在我还拿不出一个合理的令人兴奋的设计上的大幅优化方案，但是其中的思考值得记录</p><h3 id="显式计算图还是着色语言？"><a href="#显式计算图还是着色语言？" class="headerlink" title="显式计算图还是着色语言？"></a>显式计算图还是着色语言？</h3><p>在编写跨平台渲染引擎时，由于各个平台使用的着色语言不同，所以这一块是个麻烦。</p><p>第一种做法是自己设计一套着色语言，比如unity，自己再把它编译到各个不同平台的着色语言上。</p><p>第二种是自己使用任意的语言，但是统一编译到底层中间格式，比如spirv，然后只要支持spirv的平台就都可运行。</p><p>第三种是直接将引擎开发语言或其子集直接编译到各个不同平台的着色语言或中间格式。</p><p>第四种是用引擎开发语言实现一套计算图表示，使用开发语言完成计算过程描述，然后编译到各个不同平台的着色语言上。</p><p>这四种各有优劣：</p><p>第一种做法，需要自己设计语言，实现编译器前端和各个target的emitter，实现难度高成本大。用户学习成本高。但是毕竟语言都是自己发明的，定制能力强，很酷。</p><p>第二种做法，不是所有平台都有spirv的支持的，（看向webgl）。而各个语言到spirv等于一堆编译器前端，虽然都是有现成的，但是你只能编译期就确定shader，失去了运行时动态新加shader的能力，除非运行时把你要用的语言的编译器带上，局限大，通用性不佳。 好处就是实现简单。</p><p>第三种做法，额外好处1是不想引入新语言的学习成本，2是希望能复用引擎本身某些代码，另外实现上会容易一些（一般语言都会提供自己的parser）。但是也是局限性的问题，肯定是子集，但是万一有不能表达的东西呢？万一你本身语言就是没类型的呢（看向js）。</p><p>前三种都是基于着色语言的方案，第四种是计算图的方案。</p><p>我在artgl中，做的就是一个简单的计算图方案， 着色组件的对shader逻辑的扩展方式是直接对计算图进行扩展和修改，最后将图编译成shader。我曾经和我的室友开玩笑说我是搞不定编译器只能被迫做计算图，因为本质上，编译器从字符串搞出语法树，后一步的代码生成和优化也是转计算图的。但是后来我一想觉得事情没这么简单，计算图的方案虽然看起来不是那么高明但可能有额外的优势。</p><p>相比显示的计算图描述，语言方案本质上是计算图的字符串隐式描述，从语言得到计算图的实现成本是很高的（编译器前端+图生成）。 而为什么我们需要计算图呢，有了计算图能做什么呢，在我看来计算图才真的是核心。如果引擎层搞不到计算图，那么就很难将着色过程组件化，材质框架事实上是无从谈起的。 着色过程组件化中，每一个组件肯定是要可以依赖其他组件的输入的，这个依赖本质上是外部的输入或者某个计算的结果，除了计算图，没有其他更好的对这些依赖进行描述和定位的方式了。想象一下假设我们没有显式的计算图，而是shader的字符串代码，我们就很难描述我们这一段代码具体依赖另一段代码的中某个变量的依赖关系，难道用变量名吗？</p><p>所以我对最佳方案的思考是hybrid的：</p><p>1 用户可以在封闭的单元（atomic？）来使用任意的着色语言进行编写，比如一个function，input group，这个封闭单元的概念是单元的输入输出是确定的和暴露的，外部不会依赖单元的内部内容。<br>2 引擎层能将单元parse成计算图，得到单元内部对外部单元依赖<br>3 用户可以组装单元形成子图形成新的单元，或者直接完成计算图组织</p><p>几个设计点：<br>1 用户可以有选择/发明 着色语言的自由，但是要能转成引擎内的计算图表示<br>2 引擎内的计算图可以自由反向输出着色语言，是IR<br>3 计算图只本质上描述计算的依赖关系，本质只是对计算单元做link，不设计具体着色能力/feature/语言设计<br>4 材质框架本质基于计算图依赖/link的能力完成组件化，组合能力，重用，抽象</p><h3 id="shader是应该编译期生成还是运行期生成？"><a href="#shader是应该编译期生成还是运行期生成？" class="headerlink" title="shader是应该编译期生成还是运行期生成？"></a>shader是应该编译期生成还是运行期生成？</h3><p>这里的shader指最终交给驱动的东西，可以是spirv，也可是代码。一种看法认为这些东西属于产品的asset，相当于图片等资源，是编译构建时就应该制作完成的，而也不乏能看到实现是所有shader全部是运行时生成的情况。</p><p>运行时生成是必不可少的能力，如果缺少这个则无法支持用户自定义着色。但大部分或者全部的运行时生成一方面会引入额外的overhead，（虽然生成pso开销会更高），另一方面， 我新看到的重要一点是纯的依赖运行时生成的方法不太稳定可靠，说明白就是缺少编译期的检查，使得shader生成逻辑完全依赖外部的运行时测试（虽然事实上这个是起码要有的事情）。</p><p>所以我概括为着色框架最好能支持在编译期支持有限的检查机制以防止运行时shader编译失败的可能，这个是为生产力上锦上添花。</p><p>实现这一特性，两种approach，工程性的和技术性的。工程性的很简单，本质就是测试工作，这个不用讨论，而技术性的方案倒是有些意思。</p><p>回到上一个topic，假设你是全盘使用语言描述，那么本质上你实现这个语言的language server就能完整解决。假设使用的是全盘计算图的方案，那么就很有挑战了。如果框架的语言是动态语言，那么这个需求就搞不定了。如果是静态语言，也非常难做。要实现这一功能，核心是要为每一个node做输出输出的类型标记，这个直接导致写起来非常不ergonomic，更麻烦的是这些node很难使用统一容器存储，不然又涉及不安全的类型转化。这个目前做了一些尝试并没有太好的进展。退而求其次，每一个着色组件是存在外部依赖的，但是这个外部依赖能否做静态类型检查呢？这个我的确尝试出了一个方案，但是也不ergonomic。主要做法类似于Iterator的思想：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">BaseShading</span></span> &#123;</span><br><span class="line">  graph: ShaderGraph,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">PositionAttributeInput</span></span>&lt;T&gt; &#123;</span><br><span class="line">  before: T,</span><br><span class="line">  attribute_input_node: Node,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T&gt; PositionAttributeInput&lt;T&gt; &#123;</span><br><span class="line">  <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">new</span></span>(before: T) -&gt; <span class="keyword">Self</span> &#123;</span><br><span class="line">    todo!()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">trait</span> <span class="title">MVPTransformInput</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">fn</span> <span class="title">position</span></span>(&amp;<span class="keyword">self</span>) -&gt; Node;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// deref into inner type</span></span><br><span class="line"><span class="keyword">impl</span> MVPTransformInput <span class="keyword">for</span> PositionAttributeInput&lt;BaseShading&gt;&#123;</span><br><span class="line">    <span class="function"><span class="keyword">fn</span> <span class="title">position</span></span>(&amp;<span class="keyword">self</span>) -&gt; Node &#123;</span><br><span class="line">        todo!()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">MVPTransform</span></span>&lt;T: MVPTransformInput&gt; &#123;</span><br><span class="line">  before: T,</span><br><span class="line">  mvp_uniform: Node,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;T: MVPTransformInput&gt; MVPTransform&lt;T&gt; &#123;</span><br><span class="line">  <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">new</span></span>(before: <span class="keyword">impl</span> MVPTransformInput) -&gt; <span class="keyword">Self</span> &#123;</span><br><span class="line">    todo!()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">fn</span> <span class="title">test</span></span>() &#123;</span><br><span class="line">  <span class="keyword">let</span> base = BaseShading::new();</span><br><span class="line">  <span class="keyword">let</span> base_with_position = PositionAttributeInput::new(base);</span><br><span class="line">  <span class="keyword">let</span> mvp_trans_formed = MVPTransform::new(base_with_position);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种做法其实是使用泛型容器反复嵌套来合成一个struct，每一个容器都是一个component，component的节点依赖使用trait定义，用户再通过impl trait的方式实现依赖链接。这个解法其实已经非常好了，但是不ergonomic的原因在于如果着色组件切分很细，那么嵌套会非常多，实现链接的代码会写的很丑陋，类型也会很长。</p><p>我们其实需要的是一种做法，就是能在编译期随机组合几个struct成为新的struct，这种需求估计要使用marco来解。我暂时没想到什么写法能够糅合指定任意的class，但是退而求其次还是可以搞泛型是数组的容器：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Combine2</span></span>&lt;A, B&gt;&#123;...&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Combine3</span></span>&lt;A, B, C&gt;&#123;...&#125;</span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Combine4</span></span>&lt;A, B, C, D&gt;&#123;...&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>其中链接的约束可以这样搞？</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Combine4</span></span>&lt;A, B, C, D&gt;</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">B: Link&lt;B, (&amp;A)&gt;,</span><br><span class="line">C: Link&lt;C, (&amp;A, &amp;B)&gt;,</span><br><span class="line">D: Link&lt;D, (&amp;A, &amp;B, &amp;C)&gt;</span><br><span class="line">&#123;...&#125;</span><br></pre></td></tr></table></figure><p>如果要涉及到实际shader生成和编译，那似乎要依赖const function等编译期计算相关的东西了/</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;去年在artgl中实践了一种以着色组件(Shading component)的材质系统实现，用户通过编写独立的组件并组合这些组件形成完整的s
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>QEM 网格模型简化算法</title>
    <link href="http://mikialex.github.io/2020/04/04/mesh-simplification/"/>
    <id>http://mikialex.github.io/2020/04/04/mesh-simplification/</id>
    <published>2020-04-03T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.628Z</updated>
    
    <content type="html"><![CDATA[<p>QEM 是一种常见和流行的网格简化算法。在阅读了一些源码和文章后特此笔记。</p><p>网格的简化是一个复杂的问题，与其全局的想怎么去简化不如从细节入手分而治之。从人的角度而言，手工简化其实也是针对基本图元的简单操作，即每次从网格上删除一个基本图元，一直迭代至满足要求。具体方法有：</p><p>顶点删除：从网格上一次移除一个顶点。移除后，网格上该顶点相关的面被删除，形成新的洞，再重新对这个洞三角化来补面。</p><p>边删除：从网格上一次移除一条边，塌陷这条边的两个顶点为一个。塌陷后再重新连接其他的面。</p><p>顶点合并：从网格上一次选择两个顶点进行塌陷，这两个顶点不一定需要构成边。塌陷后再重新连接其他的面。</p><p>QEM的方法适用于边删除和顶点合并的两种情况：都是把两个顶点合并成一个。后续只是连接性重建的问题。我的理解是边删除的方法能避免拓扑关系被破坏，而有些场景下，拓扑关系不是很重要，比如单纯用于渲染的mesh。而使用边删除因为拓扑的约束所以简模效果没有单纯的顶点合并来的理想。</p><h2 id="什么是QEM"><a href="#什么是QEM" class="headerlink" title="什么是QEM"></a>什么是QEM</h2><p>QEM是 Quadric Error Metrics的缩写。我先不直接解释这个东西是什么，先回归我们面对的具体问题：我们现在要从一个mesh上删除一条边。我们要选择哪一条边？我们选择的这条边，合并后的新顶点位置是什么？</p><p>我们其实只需要考虑后一个问题，因为我们在某个边上能找到的最佳点的质量就决定了这条边的质量，有了所有边的质量我们只需找到最好的就可以了，这就是边的选择的解法。</p><p>既然是网格简化，所以我们要尽可能保证每一步简化和原网格形状差别不大。考虑我们具体的操作是一个图元，所以这是个非常局部性的问题：当我们把一条边从网格上塌陷掉，在形状上的影响就是这条边原先所在的几个面的换成了新的几个面。具体而言就是：当合并前，我们有原先的两个顶点的位置，以及这些顶点周围的若干三角面。当合并后，我们有新的顶点位置，以及新的顶点周围若干三角面。</p><p>QEM方法的原则：<strong>就是合并后的这个顶点，应当到原先合并前两个顶点周围若干三角形所在平面的距离的平方和最小</strong>。有了这个原则，我们就可以计算给定网格上一条边，这个最优点在哪里，以及它有多优秀。</p><p>“到原先合并前两个顶点周围若干三角形所在平面的距离的平方和”，其实就是个函数 <code>d = f(x, y, z)</code>。这个函数在哪个xyz坐标取到最小值，这个坐标就是最优点的位置，这个最小值就是优秀的程度。</p><p>相信讲到这里，网格简化问题已经被说透彻了。而QEM本质上只是解决上面这个问题的数学工具。</p><p>对于一个三角面，其所在平面的方程有 <code>ax + by + cz + d = 0</code>。不难记得高中的几何知识：对于这种平面方程, 空间中任意一点到这个平面的距离就是直接把xyz代入就是，那么距离的平方的函数就是 <code>d = (ax + by + cz + d)^2</code>。那么所有平面的距离平方和就是把所有三角面的这个函数相加就是。然后再求个最小值就ok了。</p><p>Quadric 在数学上叫<a href="https://www.zhihu.com/question/38902714" target="_blank" rel="noopener">二次型</a>。 <code>d = (ax + by + cz + d)^2</code>就是个二次型，所以我们就有展开后写成二次型矩阵的版本：</p><p><img src="/images/mesh-simplification/matrix.png" alt></p><p>一旦这么写了以后，我们原先的这些平方和的函数，就变成的一堆矩阵的和，所以，对于某个顶点周围的三角面，我们只要用这个二次型矩阵就能表达空间中任一点到这些三角面距离平方和的函数。而这个矩阵，就是这个顶点的QEM。而对于我们上面讲到的“到原先合并前两个顶点周围若干三角形所在平面的距离的平方和”，那就是两个顶点的QEM矩阵和。</p><p>我的理解是用QEM存粹是工程上的考量，即便我不懂什么Quadric，我实际上也会实现上把平方和展开然后逐项存储，逐项求和。更有种用矩阵是为了简化运算的表示的意味。</p><p>不过在求最小值方面的确是不清楚不用二次型矩阵有什么更好的办法。</p><p><img src="/images/mesh-simplification/matrix2.png" alt></p><p>我不是很懂矩阵的微积分, 这个求导的推导需要再看看其他资料。只不过这么搞答案立刻就有。</p><h2 id="流程梳理"><a href="#流程梳理" class="headerlink" title="流程梳理"></a>流程梳理</h2><p>1计算mesh上每一顶点的QEM。</p><p>2对于每一个可以合法坍缩的顶点对/边，根据QEM计算最佳坍缩位置和最佳坍缩位置下的平方和最小值作为error</p><p>3通过error最小堆来维护可以合法坍缩的顶点对/边</p><p>4反复迭代从堆中pop出最小的error边进行坍缩，并更新所有收影响边/点/新边的QEM和error以及堆，直到符合简化量预期</p><h2 id="Links"><a href="#Links" class="headerlink" title="Links"></a>Links</h2><p>Paper</p><p><a href="https://www.cs.cmu.edu/~./garland/Papers/quadrics.pdf" target="_blank" rel="noopener">https://www.cs.cmu.edu/~./garland/Papers/quadrics.pdf</a></p><p>开源参考实现：</p><p><a href="https://github.com/sp4cerat/Fast-Quadric-Mesh-Simplification/blob/master/src.cmd/Simplify.h" target="_blank" rel="noopener">https://github.com/sp4cerat/Fast-Quadric-Mesh-Simplification/blob/master/src.cmd/Simplify.h</a></p><p><a href="https://github.com/hhoppe/Mesh-processing-library/blob/master/MeshSimplify/MeshSimplify.cpp" target="_blank" rel="noopener">https://github.com/hhoppe/Mesh-processing-library/blob/master/MeshSimplify/MeshSimplify.cpp</a></p><p>二次型，数学相关</p><p><a href="https://www.zhihu.com/question/38902714" target="_blank" rel="noopener">https://www.zhihu.com/question/38902714</a></p><p><a href="https://www.zhihu.com/question/22455493" target="_blank" rel="noopener">https://www.zhihu.com/question/22455493</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;QEM 是一种常见和流行的网格简化算法。在阅读了一些源码和文章后特此笔记。&lt;/p&gt;&lt;p&gt;网格的简化是一个复杂的问题，与其全局的想怎么去简化不如从细节入手分而治之。从人的角度而言，手工简化其实也是针对基本图元的简单操作，即每次从网格上删除一个基本图元，一直迭代至满足要求。具体
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Side project retro in 2019 and future plan</title>
    <link href="http://mikialex.github.io/2019/12/28/side-project-in-2019/"/>
    <id>http://mikialex.github.io/2019/12/28/side-project-in-2019/</id>
    <published>2019-12-27T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.629Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/side-project-in-2019/github.png" style="width:100%"></p><h2 id="artgl"><a href="#artgl" class="headerlink" title="artgl"></a>artgl</h2><p>今年的side project主要是这个 <a href="https://github.com/mikialex/artgl" target="_blank" rel="noopener">https://github.com/mikialex/artgl</a> 这个项目基本占据了我今年主要的业余编程时间。 <del>我写坑过许多项目，从目前的发展来看，ARTGL应该是不会坑掉了。</del> 今年完成了主要的api设计和开发，主要的关于场景和渲染流程构建方面的API已经成熟。我对目前的整体架构还是较为满意的：经过年底的一番调整，目前整个repo已经完成了模块化的迁移，不同的功能被分割在不同的package里，并使用lerna进行管理。在模块化的迁移中，为了拆解不必要的依赖和耦合关系，做出了不少设计上的变动。这些变动提升了架构上的质量。现在整个项目中，每一个package，每一个类的的职责，界限，已经非常明确，干净。</p><p>详细来说：</p><ul><li><p>实现了一个独立的WebGL封装库： @artgl/webgl。 包装原始api，对webgl状态切换做diff，记录，调试，以及提供了功能级别的webgl1/2的自动降级（比如使用此layer提供的instance draw/VAO，可以无缝切换webgl1/2）。独立性非常高，可以被用于任何其他的项目</p></li><li><p>数学库，@artgl/math, 这里主要是three的数学库，ts化。但还有很多没有完成迁移，基本上是需要什么迁移什么。</p></li><li><p>utils， @artgl/shared， 工具util</p></li><li><p>@artgl/shader-graph, a shader linker。主要是用户可以包装任意glsl字符串函数，我们会简单提取输入输出，以节点的形式，抽象shader中的计算。用户可以使用builder style的API，构建一个完整shader的计算图，两个计算图合在一起，配合一些特殊的IO节点，便可以描述一个program的所有信息。shader graph提供面向 @artgl/webgl的完整program的代码生成。</p></li><li><p>@artgl/core 核心模块。 提供了engine的实现，renderable的抽象。其中renderable中描述shading方式的部分使用的就是 @artgl/shader-graph。当然还引入了构筑于此的更上层的概念，比如shader graph的装饰器，和shader graph uniform的提供器。这部分的抽象我个人认为比较精彩，甚至light， camera等抽象是构建于次的。 当然除了shading，还有其他的诸如geometry。这一模块基本上定义了在artgl里，如何描述一个绘制的物体，以及实际上去进行绘制的实现。</p></li><li><p>@artgl/lib-geometry 和 @artgl/lib-shading 主要是核心实现和库实现的分离。前者放各种geometry， 后者放各种shading decorator，以及glsl片段。</p></li><li><p>@artgl/scene-graph。 当然就是场景图了，将各种renderable以层次结构组合在一起，实现典型的场景整体描述。初次之外还有IO的一些东西，I可以有各种controller loader，O可以有各种exporter。因为现在就没写几种，就没有必要再独立成包了。</p></li><li><p>@artgl/render-graph。 同样是builder style的API，以声明式的方式构建后处理pass graph。</p></li></ul><p>除了这些主要模块之外，还有若干实际应用测试分别是：</p><ul><li><p>@artgl/example， 会有各种小example，兼顾回归测试，可能可以以后codegen出文档，网站。</p></li><li><p>@artgl/viewer， 会是一个比较完善的场景编辑器。</p></li></ul><p>再除了这些，还有些高度实验性质的部分：</p><ul><li><p>wasm-scene， 测试和发掘 Webassembly Rust 潜力，包括框架集成的可能性。</p></li><li><p>parser, 目前有个简单的lr1 parser，主要是想解决shading language在框架集成方面的问题，以及更多可能性的探索。</p></li></ul><h3 id="目前的不足"><a href="#目前的不足" class="headerlink" title="目前的不足"></a>目前的不足</h3><h4 id="性能一般"><a href="#性能一般" class="headerlink" title="性能一般"></a>性能一般</h4><p>目前简单的benchmark下来是不如three的。主要可能是这些原因： 1 过于灵活和丰富的抽象，这导致在three里功能是用代码写死的，直接被JIT了，而我这里要用代码自己走各种数据结构。 2 使用了不利于JIT的特性，在chrome下某些情况相较于three可能慢一倍，然而去fireFox，这个差距就远远没有这么多，至于为什么，那就很难说得清了，总之就是没有走到什么fast path上。 3 细节上没有使用高性能js的最佳实践，比如我就是要用instance of，而不是硬判断标志属性，这样ts会立刻收窄类型。 又比如我没有为了性能而特意替换foreach为普通循环，这些其实都是影响性能表现的。</p><h4 id="测试和用例不足，-完善程度低"><a href="#测试和用例不足，-完善程度低" class="headerlink" title="测试和用例不足， 完善程度低"></a>测试和用例不足， 完善程度低</h4><p>由于时间精力有限的原因，几乎没有什么单元测试，毕竟没法全职搞这个。example太少，不利于找到设计上的缺陷。搜索一下todo，就知道在各个角落都有各种case没有处理全，有些甚至涉及基本功能。只要我自己example没有写到那里我就不会补的那种。其实也主要是上述原因。</p><hr><h3 id="2020-计划"><a href="#2020-计划" class="headerlink" title="2020 计划"></a>2020 计划</h3><p>我最早的考虑是整个项目用rust/wasm 重写，以及first class WebGPU支持。后来经过具体的一番操作和研究，我认为这个几乎是另一个项目了。但是，我依然觉得如果提供js/ts良好的支持，依然是有价值的。这一点比较矛盾。wasm之前也是调研许久，只不过是scope的问题。最早是计划用于加速场景树drawcall生成的。后来发现render的js也很慢，所以engine，renderable也得做进去。 那么webgl也没必要是ts了，所以需要全部重写。</p><p>目前的考虑是，artgl会依然是一个ts项目，不会有任何wasm的东西存在。目前只会维持一个对渲染最基本的东西的轻量级抽象，而不再提供更多的实质性实现。简而言之，如果没有实际应用的话，我在明年不会有太多精力投入到这个项目中来，短期之内不会再开发新的功能。</p><h2 id="rendiation"><a href="#rendiation" class="headerlink" title="rendiation"></a>rendiation</h2><p>取而代之，明年主要focus的side project会是这个 <a href="https://github.com/mikialex/rendiation" target="_blank" rel="noopener">https://github.com/mikialex/rendiation</a>。这会是一个跨平台的rust的图形渲染库，后端是WebGPU，会支持所有常用桌面端移动端平台以及web。</p><p>语言上是的，我现在决定all in rust了。选择一门语言是非常重要的，就像决定在哪里买房子一样。1，我彻底受够了脚本语言的低效，2，我需要极致的性能，所以任何GC的语言都再见了，那么似乎只有c/c++/rust三者可选。经过我一年多的观察和学习，我几乎认定，如果我之后要做特别care性能的项目，都会尽可能的选择rust。我暂时不想写很多内容安利这门语言，懂的人自然懂。 另一个考虑是 rust的跨平台图形的基础设施还不错，即便不完善也是蓬勃发展，特别是会主要使用到的wgpu这个crate，会直接作为firefox自己的webgpu实现。在后端支持上，选择webgpu是为了在使用最现代的图形API且保持最大化的跨平台支持。</p><p>这个项目很大程度更像是在重做我今年做的东西，只不过将会有<strong>极致的性能</strong>，将会使用<strong>最先进的图形API</strong>，将具备<strong>卓越的跨平台能力</strong>。我以后的任何业务图形积累都会使用这个作为底层平台，比如GUI，可视化，等等。</p><p>当然，这其中会遇到很大的挑战，一方面主要是这应该是比较底层的体验，关心内存，关心缓存命中，和编译器做斗争，摸索dod（是的oop不是很work），全新的工具链，等等。另一方面是适应新一代的图形API的挑战，各种耳目一新的概念。明年这个时候，不求能有什么成果，只要是能沉下心琢磨一番，想必也是收获良多。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/side-project-in-2019/github.png&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;&lt;h2 id=&quot;artgl&quot;&gt;&lt;a href=&quot;#artgl&quot; class=&quot;headerlink&quot; title=&quot;artgl
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>FBO reuse in artgl rendergraph</title>
    <link href="http://mikialex.github.io/2019/08/11/fbo-reuse-in-rendergraph-artgl/"/>
    <id>http://mikialex.github.io/2019/08/11/fbo-reuse-in-rendergraph-artgl/</id>
    <published>2019-08-10T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.627Z</updated>
    
    <content type="html"><![CDATA[<p>这周末做了基于RenderGraph的Framebuffer重用。借此机会撰写一些关于reuse fbo的设计。</p><p>当我们在写后处理的时候，我们会写很多pass， 有的pass单纯的使用场景的shader画场景，更多的使用特殊的shader覆盖场景的shader进行绘制，有的pass处理之前pass绘制的结果，还有的pass处理多个之前pass的结果。你构建整个后处理的工作，事实上就是给这些pass分配绘制的target，并把这些target再提供给后续依赖的pass，来组合这些pass得到最终的屏幕效果。</p><p>很显然，整个后处理流程可以使用有向无环图进行抽象， RenderGraph就是我在artgl里完成的实现。</p><p>记得当时在我从前端转职到图形的时候，我最大的感慨是，没有一个顺手的webgl框架可用，对于之前vue什么写惯了的前端来说，组件化的模块化的抽象是深入人心的。市面上很难找到一个webgl框架，提供合理的针对渲染这个行为的模块化抽象。这大概是最早的一些想法。</p><p>后来，公司的项目里开始有一些后处理要做，这些后处理流程越来越多，充斥着大量非常丑陋的实现。于是我看不下去了，设计了一个graph的系统，通过声明式的api模块化后处理管线，希望能重构公司项目里整个后处理流程，我保证说整个后处理管线代码量下降一半，开发效率翻倍，但是我并没有得到机会做这个事情。于是乎我只能在artgl里做了。</p><p>为什么这周末突然做了fbo重用的实现呢？因为上周同事反馈移动端因为fbo大量申请导致崩溃的问题，这显然原因就是fbo没有复用的后果。我不敢想象在公司的项目里，没有graph的抽象，去人肉分辨出用到的十个fbo，谁在什么时候可以释放，谁可以给谁用，和动态配置如何配合，这种代码实在是不敢写，也没法写。</p><p>而这时我想到正因为artgl做了graph的后处理，整个graph，这个pass依赖哪个pass的结果，那个pass的结果在哪一步再也不需要保留内容了，这些优化信息全部可以自动收集，所以基于graph做fbo的自动reuse是很简单的事情。</p><p>如果所有fbo都是一个格式和大小，那么大概是这个效果：</p><p><img src="/images/fbo-reuse-in-rendergraph-artgl/fbo-reuse.png" style="width:100%;max-height:600px"></p><p>具体的做法是三部分：</p><p>1 每个 renderTargetNode 不再有一一对应的fbo，这些fbo也不在图构建的时候直接申请，取而代之，向一个fbo pool请求，fbo pool会根据 renderTargetNode 上的格式信息，比如长宽等，生成formatKey字符串，pool持有一个formatKey -&gt; fbo[] 的map，取一个就pop一个，如果没有符合格式的直接向gl申请，这是取的过程。还有一个还回来的接口表示这个fbo我用完了，上面的内容后续没有依赖了，可以继续重用， push到对应的map里的array里。</p><p>2 每个renderPass不再向对应的output target和dependency的nodes索取fbo，而是 rendergraph的执行器，effectComposer， 在执行pass前完成相应的工作。 composer自己会持有一份targetName到fbo的map， 表示当前哪些fbo的内容需要keep。composer会在renderPass执行前，获取所需的fbo，如果这个是之前keep住的，那么就取keep的fbo，如果没有就问pool申请，并在pass结束后，按需归还不再使用的fbo。</p><p>3 composer需要知道这个pass结束后，哪些kept的fbo可以return给pool，那么在构建图的时候，拓扑排序完，得到的renderPass array，需要计算一个droplist array， 就是走到哪一个pass，哪些之前用的fbo再也不需要保留内容了。根据这个list，composer便可以实现按需归还fbo。</p><p>在某些情况下，某个pass的结果即便后续没有任何引用，依然需要一直keep住。比如temporal的ping pong buffer， 需要让这个target隔帧的进行reuse。 又比如 如果你需要某个target在render之外能支持readPixel， 那么你也需要一直keep。为了支持这种情况， renderGraph api在声明target节点时，提供了 keepContent的 getter， 默认永远返回false</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">interface</span> RenderTargetDefine &#123;</span><br><span class="line">  name: <span class="built_in">string</span>,</span><br><span class="line">  <span class="keyword">from</span>: <span class="function"><span class="params">()</span> =&gt;</span> Nullable&lt;<span class="built_in">string</span>&gt;</span><br><span class="line">  keepContent?: <span class="function"><span class="params">()</span> =&gt;</span> <span class="built_in">boolean</span></span><br><span class="line">  format?: &#123;</span><br><span class="line">    pixelFormat?: PixelFormat,</span><br><span class="line">    dimensionType?: DimensionType,</span><br><span class="line">    width?: <span class="built_in">number</span>,</span><br><span class="line">    height?: <span class="built_in">number</span>,</span><br><span class="line">    enableDepthBuffer?: <span class="built_in">boolean</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是目前的带两个temporal的demo，你可以看到跨帧交替释放是如何支持的，我现在已经可以放心的继续往后叠ao的blur和glow的效果，不用担心要多出四个屏幕大小的fbo了。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line">graph.defineGraph(&#123;</span><br><span class="line">    renderTargets: [</span><br><span class="line">    &#123;</span><br><span class="line">        name: RenderGraph.screenRoot,</span><br><span class="line">        <span class="keyword">from</span>: <span class="function"><span class="params">()</span> =&gt;</span> <span class="string">'CopyToScreen'</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">'sceneResult'</span>,</span><br><span class="line">        format: &#123;</span><br><span class="line">        enableDepthBuffer: <span class="literal">true</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="keyword">from</span>: <span class="function"><span class="params">()</span> =&gt;</span> <span class="string">'SceneOrigin'</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">'depthResult'</span>,</span><br><span class="line">        format: &#123;</span><br><span class="line">        enableDepthBuffer: <span class="literal">true</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="keyword">from</span>: <span class="function"><span class="params">()</span> =&gt;</span> <span class="string">'Depth'</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">'TAAHistoryA'</span>,</span><br><span class="line">        keepContent: <span class="function"><span class="params">()</span> =&gt;</span> !<span class="keyword">this</span>.isEvenTick,</span><br><span class="line">        <span class="keyword">from</span>: <span class="function"><span class="params">()</span> =&gt;</span> <span class="keyword">this</span>.isEvenTick ? <span class="literal">null</span> : <span class="string">'TAA'</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">'TAAHistoryB'</span>,</span><br><span class="line">        keepContent: <span class="function"><span class="params">()</span> =&gt;</span> <span class="keyword">this</span>.isEvenTick,</span><br><span class="line">        <span class="keyword">from</span>: <span class="function"><span class="params">()</span> =&gt;</span> <span class="keyword">this</span>.isEvenTick ? <span class="string">'TAA'</span> : <span class="literal">null</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">'TSSAOHistoryA'</span>,</span><br><span class="line">        keepContent: <span class="function"><span class="params">()</span> =&gt;</span> !<span class="keyword">this</span>.isEvenTick,</span><br><span class="line">        <span class="keyword">from</span>: <span class="function"><span class="params">()</span> =&gt;</span> <span class="keyword">this</span>.isEvenTick ? <span class="literal">null</span> : <span class="string">'TSSAO'</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">'TSSAOHistoryB'</span>,</span><br><span class="line">        keepContent: <span class="function"><span class="params">()</span> =&gt;</span> <span class="keyword">this</span>.isEvenTick,</span><br><span class="line">        <span class="keyword">from</span>: <span class="function"><span class="params">()</span> =&gt;</span> <span class="keyword">this</span>.isEvenTick ? <span class="string">'TSSAO'</span> : <span class="literal">null</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    ],</span><br><span class="line">    passes: [</span><br><span class="line">    &#123; <span class="comment">// general scene origin</span></span><br><span class="line">        name: <span class="string">"SceneOrigin"</span>,</span><br><span class="line">        source: [scene],</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123; <span class="comment">// depth</span></span><br><span class="line">        name: <span class="string">"Depth"</span>,</span><br><span class="line">        shading: <span class="keyword">this</span>.depthShader,</span><br><span class="line">        source: [scene],</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123; <span class="comment">// mix new render and old samples</span></span><br><span class="line">        name: <span class="string">"TAA"</span>,</span><br><span class="line">        inputs: <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            sceneResult: <span class="string">"sceneResult"</span>,</span><br><span class="line">            depthResult: <span class="string">"depthResult"</span>,</span><br><span class="line">            TAAHistoryOld: <span class="keyword">this</span>.isEvenTick ? <span class="string">"TAAHistoryA"</span> : <span class="string">"TAAHistoryB"</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        shading: <span class="keyword">this</span>.taaShader,</span><br><span class="line">        source: [RenderGraph.quadSource],</span><br><span class="line">        enableColorClear: <span class="literal">false</span>,</span><br><span class="line">        beforePassExecute: <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.engine.unJit();</span><br><span class="line">        <span class="keyword">const</span> VP: Matrix4 = <span class="keyword">this</span>.engine.getGlobalUniform(InnerSupportUniform.VPMatrix).value</span><br><span class="line">        <span class="keyword">this</span>.taaShading.VPMatrixInverse = <span class="keyword">this</span>.taaShading.VPMatrixInverse.getInverse(VP, <span class="literal">true</span>); <span class="comment">// TODO maybe add watch</span></span><br><span class="line">        <span class="keyword">this</span>.taaShading.sampleCount = <span class="keyword">this</span>.sampleCount;</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"TSSAO"</span>,</span><br><span class="line">        inputs: <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            depthResult: <span class="string">"depthResult"</span>,</span><br><span class="line">            AOAcc: <span class="keyword">this</span>.isEvenTick ? <span class="string">"TSSAOHistoryA"</span> : <span class="string">"TSSAOHistoryB"</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        shading: <span class="keyword">this</span>.tssaoShader,</span><br><span class="line">        source: [RenderGraph.quadSource],</span><br><span class="line">        enableColorClear: <span class="literal">false</span>,</span><br><span class="line">        beforePassExecute: <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">const</span> VP: Matrix4 = <span class="keyword">this</span>.engine.getGlobalUniform(InnerSupportUniform.VPMatrix).value</span><br><span class="line">        <span class="keyword">this</span>.tssaoShading.VPMatrixInverse = <span class="keyword">this</span>.tssaoShading.VPMatrixInverse.getInverse(VP, <span class="literal">true</span>);</span><br><span class="line">        <span class="keyword">this</span>.tssaoShading.sampleCount = <span class="keyword">this</span>.sampleCount;</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123; <span class="comment">// copy to screen</span></span><br><span class="line">        name: <span class="string">"CopyToScreen"</span>,</span><br><span class="line">        enableColorClear: <span class="literal">false</span>,</span><br><span class="line">        inputs: <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> basic: <span class="built_in">string</span>;</span><br><span class="line">        <span class="keyword">let</span> tssao: <span class="built_in">string</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.enableTAA) &#123;</span><br><span class="line">            basic = <span class="keyword">this</span>.isEvenTick ? <span class="string">"TAAHistoryB"</span> : <span class="string">"TAAHistoryA"</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            basic = <span class="string">"sceneResult"</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.enableTSSAO) &#123;</span><br><span class="line">            tssao = <span class="keyword">this</span>.isEvenTick ? <span class="string">"TSSAOHistoryB"</span> : <span class="string">"TSSAOHistoryA"</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            tssao = <span class="string">"sceneResult"</span> <span class="comment">// TODO consider design a way to bind default empty source? or recompile shader?</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> &#123; basic, tssao &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        beforePassExecute: <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.composeShading.sampleCount = <span class="keyword">this</span>.sampleCount;</span><br><span class="line">        &#125;,</span><br><span class="line">        afterPassExecute: <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.sampleCount++;<span class="string">``</span></span><br><span class="line">        &#125;,</span><br><span class="line">        shading: <span class="keyword">this</span>.composeShader,</span><br><span class="line">        source: [RenderGraph.quadSource],</span><br><span class="line">    &#125;,</span><br><span class="line">    ]</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这周末做了基于RenderGraph的Framebuffer重用。借此机会撰写一些关于reuse fbo的设计。&lt;/p&gt;&lt;p&gt;当我们在写后处理的时候，我们会写很多pass， 有的pass单纯的使用场景的shader画场景，更多的使用特殊的shader覆盖场景的shader进
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Uniform upload optimization and UBO support in Artgl</title>
    <link href="http://mikialex.github.io/2019/08/03/uniform-upload-design/"/>
    <id>http://mikialex.github.io/2019/08/03/uniform-upload-design/</id>
    <published>2019-08-02T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.630Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要讨论和介绍一下artgl的uniform上传优化，到如何支持ubo的设计。 以及，因为ubo的优化，shadergraph的api和其概念模型的调整。</p><h2 id="Uniform-Upload"><a href="#Uniform-Upload" class="headerlink" title="Uniform Upload"></a>Uniform Upload</h2><p>一个经典的图形框架设计问题是:如何减少 uniform 上传?</p><p>在最简单的实现中，⽤户在绘制某个物体前，需要对当前uniform进⾏更新。这些通过调用gl.uniformXXX 等接⼝来完成。当⼀个场景drawcall ⾮常多，draw的东西也⽐较复杂，需要调⽤这个接⼝进行上传的次数也⾮常多，这里会造成cpu端的性能瓶颈。 即便当前gl状态机中的uniform值已经是正确的，并不需要调⽤这个接⼝进⾏更新，但如果不加判断的调⽤，经过实测，依然会造成额外成本。原因可能是浏览器的实现或者驱动的实现，需要对js端传来的数据做额外的检查和同步，但出于某些原因，并没有cache机制。所以，WebGL框架应当提供相应的cache，在上传之前，进⾏diff，如果判断出当前并不需要上传，那么直接略过。引⼊diff机制会带来额外性能成本，⼀般⽽言，这个成本会小于直接调⽤接⼝的成本，但不排除会有⼀些情况不能产⽣优化效果。</p><p>具体的diff的机制是这样的: 如果当前要draw的东⻄，没有切换过program， 且cache的新的数值，和cache的旧数值一致，则不进⾏上传。如果不一致，则copy更新cache旧的数值，进⾏上传。当切换了program，⽆论如何都要进⾏上传。</p><p>如此即可做到：不会上传不需要更新的uniform。但上⾯提到，uniform diff和copy是有成本的，can we do better? 我们能想办法避免⼀部分uniform diff的成本吗? 想想看似乎是可能。⽐如:在⼀批的绘制过程 中，camera的VP matrix 从来都没有变过，我们是知道的，所以可以不⽤diff。⼜⽐如:在⼀批的绘制过程中，light的参数假设也是没有变过的，那么我们也可以提前跳过。这些情况都可以被识别出来，然后在renderer⾥特殊处理掉。</p><p>但是，我认为这样做是糟糕的，即便three.js就是这样做的。原因是:</p><p>1 这样做破坏了引擎设计的⼀致性， 只有被你认可的case才能得到优化。</p><p>2 为了实现这样的优化，渲染逻辑和场景对象强耦合在⼀起， renderer⾥存在⼤量的针对处理这种特殊情况的代码。</p><p>3 为了实现这样的优化，在你使⽤场景的api时，你又必须非常了解这些假设，如果不了解，要么优化不会起作用，要么你期望的API调⽤却竟然没有效果。</p><p>所以， how can we do better than that? 我们应该找到⼀个通⽤的解法。如果从本质上来看这个问题，⼀般⽽⾔，判断数据变化就两种⽅案:</p><p>1 diff，这种⽅案，⽤户在修改和访问数据时，不会有成本，但是在获取数据是否变更时需要付出成本。</p><p>2 watch，这种⽅案，⽤户在修改和访问数据时，会有成本，但是在获取数据变更时没有成本。</p><p>上⽂提到的three的这种特殊的做法，其实还是diff，只不过通过约定来省略⼀部分diff。</p><p>我的解决⽅案是通过结合前⼀种做法，尽可能的减少diff的发⽣。</p><p>⼀处优化是: 假设对于⼀个vector，或者matrix，我们对这个值添加⼀个容器进行包装，实现watch机制，知道了它有没有被change，我们就可以通过diff boolean值，其实就是判断有没有change，来节约逐个数据的diff成本。</p><p>renderer对于⼀个draw的若⼲uniform，会先拿到需要set对应uniform的容器，还会从⼀个cache的Set⾥里里 拿到上⼀个对应该uniform且set过值的容器，如果两个容器本身不是⼀个引⽤，这时候我就知道，这个uniform数值的提供者发⽣了改变，那这种情况下，我需要做diff，容器上⾯的可变标记就⽆效了。如果两个容器是同⼀个引用，那么如果容器上的change标记显示已经发⽣了变化，那么我就可以不diff，直接进行上传，如果标记显示没有发⽣变化，那么我也可以跳过diff，直接不上传。⼀旦发⽣了上传，则更新 change标记false。如果program发⽣生了切换，那我就清空上⼀个draw的容器Set缓存，如果拿不到上⼀个draw的对应uniform的cache容器，那我也可以跳过diff，直接上传。</p><p>这个解法可以缓解⼤部分不需要的diff，⽽而对于watch的成本，在图形开发的常⽤环境下⽽而⾔言，不变的东⻄<br>往往⼤⼤多于变的东⻄，所以是⾮常合算的!</p><h2 id="Uniform-Block-amp-ShaderGraph-decorator-API"><a href="#Uniform-Block-amp-ShaderGraph-decorator-API" class="headerlink" title="Uniform Block &amp; ShaderGraph decorator API"></a>Uniform Block &amp; ShaderGraph decorator API</h2><p>WebGL2⽀持了UBO，UBO可以让⽤户将多个uniform合并成⼀个进⾏绑定，减少了gl调⽤次数，同时也能作为整体在多个WebGL program之间进⾏复⽤。对性能的提升影响很⼤。 我们怎么⽤好这个api呢，can we do better?</p><p>从字⾯意义上讲，既然要UBO，我们需要把⼀个shader中几个相关联的的uniform看成⼀个整体，或者知道他们是有联系的。把它们group起来。如果你⽐较贪，想把它们全部group起来，这样是不合适的，这样没有办法进⾏组合，只能draw⼀个死的东⻄。所以我的想法是把它们之前有关系的东⻄进⾏group:⽐ 如light的位置，颜色，就是⼀个整体，⼀个block。很显然的是，这些需要group的uniform的提供者，似乎都是⼀个对象，所以这个设计就⽐较明确了:</p><p>在artgl的设计中:每个这种可以提供uniform的对象，需要实现uniform provider的接⼝，其中包含⼀个 uniform-key to uniform-watch容器的map， 和⼀个标示uniform block是否change的字段。对象⾃身的⼀些属性，可以被装饰器进⾏装饰，使得⾃动转化成getter和setter， setter会⾃动向uniform-watch容器进⾏更新，以及和block change字段进⾏更新。由此，⽤户可以⾮常⾮常⽅便的接⼊uniform的优化系统。只要对原先的字段添加装饰器并继承⼀个实现了这个接⼝的类就可!</p><p><img src="/images/uniform-upload-design/provider.png" style="max-width:500px"></p><p>在之前的⼀篇⽂章，介绍了artgl的shadergraph的设计，在artgl中，shader是通过graph api显示的构建出来的，shader的uniform依赖，其实就是graph上的uniform input node，所以 can we do better on api design?</p><p>对于那些作为uniform provider的对象，它们之所以能作为uniform的 provider，是因为shader中有需要它们提供的uniform，所以，它们其实是和shader息息相关的。在此，介绍⼀下artgl shadergraph decorator的API，它很好的解决的这⼀层的抽象。本质上uniform provider声明了某个shader需要这些 uniform，所以，provider需要亲⾃修改shadergraph，⾃⼰添加⾃⼰provide的uniform input和⾃身 shader实现的计算逻辑。API上，uniform provider需要实现 decorate接⼝，decorate接⼝输⼊需要装饰 的shadergraph，实现装饰逻辑。</p><p><img src="/images/uniform-upload-design/decorate.png" style="max-width:500px"></p><p>在graph上添加⼀个uniform的input node， 需要名字和类型，默认值等参数，这些显然和provider⾃身的字段声明是冗余的，所以我在provider的基类实现了⼀个util函数，可以直接运⾏时读取属性值，根据数据类型和数据，return你需要的uniform input node，同时，利⽤ts的key of，可以实现静态的字段检查，防止你引⽤⼀个不存在字段。</p><p>比如这个简单的点光源的实现：</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">class</span> PointLight <span class="keyword">extends</span> Light&lt;PointLight&gt; &#123;</span><br><span class="line"></span><br><span class="line">  decorate(decorated: ShaderGraph) &#123;</span><br><span class="line">    decorated</span><br><span class="line">      .setFragmentRoot(</span><br><span class="line">        AddCompose.make()</span><br><span class="line">          .input(<span class="string">"base"</span>, decorated.getFragRoot())</span><br><span class="line">          .input(<span class="string">"light"</span>, pointLightShading.make()</span><br><span class="line">            .input(<span class="string">"fragPosition"</span>, decorated.getVary(WorldPositionFragVary))</span><br><span class="line">            .input(<span class="string">"FragNormal"</span>, decorated.getVary(NormalFragVary))</span><br><span class="line">            .input(<span class="string">"lightPosition"</span>, <span class="keyword">this</span>.getPropertyUniform(<span class="string">'position'</span>))</span><br><span class="line">            .input(<span class="string">"color"</span>, <span class="keyword">this</span>.getPropertyUniform(<span class="string">'color'</span>))</span><br><span class="line">            .input(<span class="string">"radius"</span>, <span class="keyword">this</span>.getPropertyUniform(<span class="string">'radius'</span>))</span><br><span class="line">          )</span><br><span class="line">      )</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@MapUniform</span>(<span class="string">"lightColor"</span>)</span><br><span class="line">  color: Vector3 = <span class="keyword">new</span> Vector3(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="meta">@MapUniform</span>(<span class="string">"lightPosition"</span>)</span><br><span class="line">  position: Vector3 = <span class="keyword">new</span> Vector3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  <span class="meta">@MapUniform</span>(<span class="string">"lightRadius"</span>)</span><br><span class="line">  radius: <span class="built_in">number</span> = <span class="number">3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实不止光照系统，camera， 渲染曝光参数，等等，如果你想要引擎内置的这些功能，那就让他们装饰你的shadergraph吧，他们依赖的uniform，ubo，shader的逻辑，直接全都有了～ 所以shadergraph的api现在将全部以decorator的形式提供：</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">class</span> PureShading <span class="keyword">extends</span> BaseEffectShading&lt;PureShading&gt; &#123;</span><br><span class="line"></span><br><span class="line">  decorate(graph: ShaderGraph) &#123;</span><br><span class="line">    graph</span><br><span class="line">      .setVertexRoot(MVPWorld())</span><br><span class="line">      .setFragmentRoot(uniform(<span class="string">"baseColor"</span>, GLDataType.floatVec4))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在api的另⼀侧，场景接⼝的⽤户，现在构造某个绘制所需要的shading对象，则需要⼿⼯的进⾏依赖的装饰，虽然使⽤上繁琐了⼀些。但是本质上其实就是把更多的⾃由度开给了⽤户，让⽤户更清楚的看到这个draw依赖哪些对象，如何能更好的在数据层⾯上优化绘制。在过去，这样的逻辑是写死在渲染引擎内部的，对于使⽤者的理理解其实也是⼀层不便。</p><p>通过 uniform provider的 API， ⼀⽅⾯，对UBO的引擎层⾯有了很好的抽象，直接⽀持是件易如反掌的事情。另⼀⽅⾯，进⼀步减少了上传时check的成本，毕竟你有了⼀个group的change标记可以略略过⼀整个group的check过程。更重要的是和shadergraph的结合使得在设计上，开发上，概念模型上达成了不错的⼀致和统⼀。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文主要讨论和介绍一下artgl的uniform上传优化，到如何支持ubo的设计。 以及，因为ubo的优化，shadergraph的api和其概念模型的调整。&lt;/p&gt;&lt;h2 id=&quot;Uniform-Upload&quot;&gt;&lt;a href=&quot;#Uniform-Upload&quot; clas
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Graph based shader source management in artgl</title>
    <link href="http://mikialex.github.io/2019/07/16/graph-based-shadersource-management/"/>
    <id>http://mikialex.github.io/2019/07/16/graph-based-shadersource-management/</id>
    <published>2019-07-15T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.628Z</updated>
    
    <content type="html"><![CDATA[<p>目前绝大多数的webgl库都使用字符串替换，并使用预编译指令来控制shader行为。</p><p>这种一般的基于字符串替换的方案存在以下缺陷：</p><ul><li>没有可组合性，只是复用代码，抽象能力弱</li><li>代码包含大量不需要的实现，使用 #include #define 等做区分，调试和阅读困难， 开发效率低</li><li>问题定位只依赖最后编译报错，排错效率低</li><li>修改代码需要在浏览器运行所有依赖的shader，代码难维护</li></ul><p>这些缺陷导致的各自难受之处之前也深有体会, 所以在设计artgl的shader体系时，我一直想要解决这个问题：</p><p><strong>如何找到更好的方案来管理一个webgl框架内的shader代码？</strong></p><p><a href="https://github.com/glslify/glslify" target="_blank" rel="noopener">glslify</a> 可能是一个好的解决方案，但我个人并不是很喜欢这种方式： 在shader里写require, transform shader code。 这种方式是以shader code作为核心，而我希望以框架code为核心，这样做1是ts代码能做更多的事情，而shader只是字符串，即便使用了完整的shader parser，能做的事情还是比较有限，扩展起来也不方便。 最好是使用ts代码，框架的代码，对着色流程进行抽象，shader只是这种抽象的target。2是，glslify太重了，我还是倾向于暂时把事情看的简单一些。</p><p>正常我们写shader，大多数写的是一些function，然后组合起来，执行出结果。所以我设计的组合单元是、ShaderFunction： 比如下面这个shader function，pack float depth到 四通道 rgba中</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> depthPackFunction = <span class="keyword">new</span> ShaderFunction(&#123;</span><br><span class="line">  description: <span class="string">'pack depth to RGBA output'</span>,</span><br><span class="line">  source: <span class="string">`</span></span><br><span class="line"><span class="string">    vec4 depthPack(float frag_depth)&#123;</span></span><br><span class="line"><span class="string">      vec4 bitSh = vec4(256.0 * 256.0 * 256.0, 256.0 * 256.0, 256.0, 1.0);</span></span><br><span class="line"><span class="string">      vec4 bitMsk = vec4(0.0, 1.0 / 256.0, 1.0 / 256.0, 1.0 / 256.0);</span></span><br><span class="line"><span class="string">      vec4 enc = fract(frag_depth * bitSh);</span></span><br><span class="line"><span class="string">      enc -= enc.xxyz * bitMsk;</span></span><br><span class="line"><span class="string">      return enc;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  `</span>,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>ShaderFunction 只是描述这个shader的function，一个shader可能会调用多次shaderFunction进行计算，所以某个使用ShaderFunction的计算我们用 ShaderFunctionNode 来表示：ShaderFunction 事实上是 ShaderFunctionNode 的 factory。！</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> packedDepth = depthPackFunction.make()</span><br></pre></td></tr></table></figure><p>function的调用总归要传参吧：参数从哪里来呢？ 要么是来自shader外部，比如uniform，attribute，texture，对于片元着色器还有vary，要么来自其他function调用的结果。</p><p>我们先看外部的参数可以如何如何构造：</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 这是一个引擎内置支持的全局uniform</span></span><br><span class="line"><span class="keyword">const</span> VPMatrix = innerUniform(InnerSupportUniform.VPMatrix)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这时一个用户自定义的shader uniform</span></span><br><span class="line"><span class="keyword">const</span> sampleCount = uniform(<span class="string">"u_sampleCount"</span>, GLDataType.float).default(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同理一个position attribute</span></span><br><span class="line"><span class="keyword">const</span> position = attribute(<span class="string">"position"</span>, GLDataType.floatVec3);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同理一个depth vary</span></span><br><span class="line"><span class="keyword">const</span> depth = vary(<span class="string">"depth"</span>, GLDataType.float);</span><br></pre></td></tr></table></figure><p>然后我们可以给 packedDepth 喂数据了</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">packedDepth = depthPackFunction.make().input(</span><br><span class="line">  vary(<span class="string">"depth"</span>, GLDataType.float)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>当然，链式调用，我们可以一个一个input， 栗子：</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> worldPosition = MVPTransform.make()</span><br><span class="line">  .input(<span class="string">"VPMatrix"</span>, innerUniform(InnerSupportUniform.VPMatrix))</span><br><span class="line">  .input(<span class="string">"MMatrix"</span>, innerUniform(InnerSupportUniform.MMatrix))</span><br><span class="line">  .input(<span class="string">"position"</span>, attribute(<span class="string">"position"</span>, GLDataType.floatVec3))</span><br></pre></td></tr></table></figure><p>如果 ShaderFunctionNode 依赖其他 ShaderFunctionNode 的计算结果，这也是可以的：</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 比如 先生成一个动态的2d平面上的随机数</span></span><br><span class="line"><span class="keyword">const</span> Random2D1 = rand2DT.make()</span><br><span class="line">  .input(<span class="string">"cood"</span>, vUV)</span><br><span class="line">  .input(<span class="string">"t"</span>, sampleCount)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 再拿它去搞出另一个维度的随机数</span></span><br><span class="line"><span class="keyword">const</span> Random2D2 = rand.make()</span><br><span class="line">.input(<span class="string">"n"</span>, Random2D1)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 然后在拿这两个随机数生成随机方向</span></span><br><span class="line"><span class="keyword">const</span> randDir = dir3D.make()</span><br><span class="line">  .input(<span class="string">"x"</span>, Random2D1)</span><br><span class="line">  .input(<span class="string">"y"</span>, Random2D2)</span><br></pre></td></tr></table></figure><p>通过这些node的连接，我们构造了一个graph，现在有了这个graph，我们要把shader搞出来。</p><p>OK， 我们再回过头来看shader，我们需要的是shader，webgl shader，两个着色器：</p><p>对于顶点着色器，总归有个 gl_Position ，或者 vary 这些。很简单，我们只要指定说：哪个node作为gl_Position，或者哪个node最为 叫什么名字的 vary就可以了。</p><p>对于顶点着色器，总归有个 gl_FragColor ，或者 mrt的输出 这些。很简单，我们只要指定说：哪个node作为 gl_FragColor ，mrt就先从简不考虑了，虽然挺对称的。</p><p>因为其实我们 vary 是构建顶点着色器指定的，所以前面vary也应该从整个graph get，api要改一下。</p><p>这是个画normal颜色的shader，应该好理解：</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> graph = <span class="keyword">new</span> ShaderGraph();</span><br><span class="line"></span><br><span class="line">graph.reset()</span><br><span class="line">  .setVertexRoot(</span><br><span class="line">    MVPTransform.make()</span><br><span class="line">      .input(<span class="string">"VPMatrix"</span>, innerUniform(InnerSupportUniform.VPMatrix))</span><br><span class="line">      .input(<span class="string">"MMatrix"</span>, innerUniform(InnerSupportUniform.MMatrix))</span><br><span class="line">      .input(<span class="string">"position"</span>, attribute(</span><br><span class="line">        &#123; name: <span class="string">'position'</span>, <span class="keyword">type</span>: GLDataType.floatVec3, usage: AttributeUsage.position &#125;</span><br><span class="line">      ))</span><br><span class="line">  )</span><br><span class="line">  .setVary(<span class="string">"color"</span>, attribute(</span><br><span class="line">    &#123; name: <span class="string">'normal'</span>, <span class="keyword">type</span>: GLDataType.floatVec3, usage: AttributeUsage.normal &#125;</span><br><span class="line">  ))</span><br><span class="line">  .setFragmentRoot(</span><br><span class="line">    normalShading.make().input(<span class="string">"color"</span>, <span class="keyword">this</span>.graph.getVary(<span class="string">"color"</span>))</span><br><span class="line">  )</span><br></pre></td></tr></table></figure><p>为了开发方便，很多小功能也被加入进来，比如你可以这么写：而不用自己包装function</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> node1 = vec4(attribute(<span class="string">"position"</span>, GLDataType.floatVec3), constValue(<span class="number">1</span>))</span><br><span class="line"><span class="keyword">const</span> node2 = node1.swizzling(<span class="string">"zyx"</span>)</span><br></pre></td></tr></table></figure><p>这就是 artgl ShaderGraph API的核心接口啦，目前这么写，已经可以work了！</p><p>在通过这些接口构建graph的过程中，每一步都有运行时参数类型的检查。link错的地方很早就能发现，解决了： 「问题定位只依赖最后编译报错，排错效率低」 的问题</p><p>虽然不是静态的检查，至少可以保证只要function写的不错，能link就能运行。所以你可以直接把每个shader构建加在单测里，单测没挂shader就没挂，不用起浏览器环境。解决了： 「修改代码需要在浏览器运行所有依赖的shader，代码难维护」 的问题</p><p>在编译shader的过程中，linker只会收集使用到的function和input依赖，没有任何预处理指令干扰视线，所以不存在： 「代码包含大量不需要的实现，使用 #include #define 等做区分，调试和阅读困难， 开发效率低」 的问题</p><p>shader graph 每一个node其实就是一个有类型的数值节点，所以可组合性非常强。不同的node类型实现不同的功能，易于扩展，比字符串拼接水平高多了。graph更是提供了整个shader的抽象，解决了「没有可组合性，只是复用代码，抽象能力弱」的问题</p><p>框架内置提供了常用的function供用户使用，也可以从独立的package import，shader 代码也正式成为框架的可扩展实现之一。 基于这样的抽象，甚至能解决不同shader version 编译的问题，这个就不展开了//</p><p>基于动态link，使用这种api，构造一个shader，类似于使用react，构造一个view，其实是相似的，有很多想象空间。基本上是我认为是实现框架抽象shader代码的一个好的方向。当然目前的解法还有一些限制，一些问题还有待解决，一些特性还有待设计和支持，如果有反馈和建议欢迎在 <a href="https://github.com/mikialex/artgl" target="_blank" rel="noopener">https://github.com/mikialex/artgl</a> 反馈和交流。</p><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">class</span> TSSAOShading <span class="keyword">extends</span> Shading &#123;</span><br><span class="line">  update() &#123;</span><br><span class="line">    <span class="keyword">const</span> VPMatrix = innerUniform(InnerSupportUniform.VPMatrix);</span><br><span class="line">    <span class="keyword">const</span> sampleCount = uniform(<span class="string">"u_sampleCount"</span>, GLDataType.float).default(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">const</span> depthTex = texture(<span class="string">"depthResult"</span>);</span><br><span class="line">    <span class="keyword">this</span>.graph.reset()</span><br><span class="line">      .setVertexRoot(</span><br><span class="line">        vec4(attribute(</span><br><span class="line">        &#123; name: <span class="string">'position'</span>, <span class="keyword">type</span>: GLDataType.floatVec3, usage: AttributeUsage.position &#125;</span><br><span class="line">      ), constValue(<span class="number">1</span>)))</span><br><span class="line">      .setVary(<span class="string">"v_uv"</span>, attribute(</span><br><span class="line">        &#123; name: <span class="string">'uv'</span>, <span class="keyword">type</span>: GLDataType.floatVec2, usage: AttributeUsage.uv &#125;</span><br><span class="line">      ))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> vUV = <span class="keyword">this</span>.graph.getVary(<span class="string">"v_uv"</span>);</span><br><span class="line">    <span class="keyword">const</span> depth = unPackDepth.make().input(<span class="string">"enc"</span>, depthTex.fetch(vUV))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> worldPosition = getWorldPosition.make()</span><br><span class="line">      .input(<span class="string">"uv"</span>, vUV)</span><br><span class="line">      .input(<span class="string">"depth"</span>, depth)</span><br><span class="line">      .input(<span class="string">"VPMatrix"</span>, VPMatrix)</span><br><span class="line">      .input(<span class="string">"VPMatrixInverse"</span>, uniform(<span class="string">"VPMatrixInverse"</span>, GLDataType.Mat4).default(<span class="keyword">new</span> Matrix4()))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> Random2D1 = rand2DT.make()</span><br><span class="line">      .input(<span class="string">"cood"</span>, vUV)</span><br><span class="line">      .input(<span class="string">"t"</span>, sampleCount)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">const</span> Random2D2 = rand.make()</span><br><span class="line">    .input(<span class="string">"n"</span>, Random2D1)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">const</span> randDir = dir3D.make()</span><br><span class="line">      .input(<span class="string">"x"</span>, Random2D1)</span><br><span class="line">      .input(<span class="string">"y"</span>, Random2D2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> newPositionRand = newSamplePosition.make()</span><br><span class="line">      .input(<span class="string">"positionOld"</span>, worldPosition.swizzling(<span class="string">"xyz"</span>))</span><br><span class="line">      .input(<span class="string">"distance"</span>, uniform(<span class="string">"u_aoRadius"</span>, GLDataType.float).default(<span class="number">1</span>))</span><br><span class="line">      .input(<span class="string">"dir"</span>, randDir)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> newDepth = unPackDepth.make()</span><br><span class="line">      .input(<span class="string">"enc"</span>,</span><br><span class="line">        depthTex.fetch(</span><br><span class="line">          NDCxyToUV.make()</span><br><span class="line">            .input(</span><br><span class="line">              <span class="string">"ndc"</span>, NDCFromWorldPositionAndVPMatrix.make()</span><br><span class="line">                .input(</span><br><span class="line">                  <span class="string">"position"</span>, newPositionRand</span><br><span class="line">                ).input(</span><br><span class="line">                  <span class="string">"matrix"</span>, VPMatrix</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.graph.setFragmentRoot(</span><br><span class="line">      tssaoMix.make()</span><br><span class="line">        .input(<span class="string">"oldColor"</span>, texture(<span class="string">"AOAcc"</span>).fetch(vUV).swizzling(<span class="string">"xyz"</span>))</span><br><span class="line">        .input(<span class="string">"newColor"</span>,</span><br><span class="line">          sampleAO.make()</span><br><span class="line">            .input(<span class="string">"depth"</span>, depth)</span><br><span class="line">            .input(<span class="string">"newDepth"</span>, newDepth)</span><br><span class="line">        )</span><br><span class="line">        .input(<span class="string">"sampleCount"</span>, sampleCount)</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;目前绝大多数的webgl库都使用字符串替换，并使用预编译指令来控制shader行为。&lt;/p&gt;&lt;p&gt;这种一般的基于字符串替换的方案存在以下缺陷：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;没有可组合性，只是复用代码，抽象能力弱&lt;/li&gt;&lt;li&gt;代码包含大量不需要的实现，使用 #include #
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>开源项目的思考</title>
    <link href="http://mikialex.github.io/2019/07/07/opensource2019/"/>
    <id>http://mikialex.github.io/2019/07/07/opensource2019/</id>
    <published>2019-07-06T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.629Z</updated>
    
    <content type="html"><![CDATA[<p>GitHub是我使用的最频繁的网站之一，我有几个属于自己的长期经营的开源项目，在这些项目上工作了很多时间。我也向著名的大型项目提交过pr，有些也成功合并了。我是一个开源爱好者。</p><p>早些时候，我喜欢将自己写的代码公开出来出于很简单的理由：我写的程序是我的作品，我想要把这些公开出来以期望得到别人的认可。正如我会撰写博客一样。如果我是一个计算机专业的学生，我肯定会把我的所有作业，课程设计，读书笔记都会以开源的方式分享出去。因为公开，所以这些材料是我要认真面对认真思考的，这有助于防止浑浑噩噩的度过枯燥的日子，也有助于帮助所有其他有志于此的同学。而更因为可以进行版本控制的原因，所以也为知识网络的构建提供了写作的平台。这些公开的资料也同时能够证明我在某一个领域是有所投入和产出的。如果你熟悉web开发，如果你了解机器学习，如果你在精通编译原理，那么通过你有公开的仓库里你自己开发的网站，自己写的算法，自己写的parser，都可以完美的证明和佐证你在这些领域的能力和实际水平。从这个角度而言，开源项目，其实是长期在开发领域自我学习，自我驱动，自我进行投入和产出的平台。</p><p>我认识的一些朋友，他们持有这这样的一种观点：只有做的非常完善非常拿得出手的东西才有资格开源，否则就是献丑。开源事业在他们眼中是一种“事业”，是一种非常宏大的东西，和平时的软件开发工作相去甚远。我认为这种观点是狭隘的，因为一方面：我们不能 「因为害怕被批评而拒绝公开作品 」而放弃提升自我的机会。另一方面，开源并不是什么高大上的东西，可以肯定的是，99.99的仓库对于别人而言没有任何价值。99的仓库是彻底的垃圾，但这又如何呢？ 一个软件开发者，把自己的代码，share到github上，和一个视觉设计师，把自己的作品，发布到behance上，有什么本质上的区别吗？ 反过来，如果一个程序员不关注开源社区，正如一个设计师，从来不去关注优秀作品，有多大可能是一个优秀的设计师呢？</p><p>可能你解决了一个小的问题，你也有机会把它公开出来，但是你会觉得这个问题太冷门，别人不大可能用的到，自己的解法也说不上好，完全没有这个开源的必要。但我认为即便是这种情况，也是有价值的。我今年在工作中遇到了不少棘手的问题，在看了一些一些无人问津的代码，问了一些至关重要的问题之后才得以解决。这件事情给我一个感觉是：你公开的代码和信息，事实上是汇入了文明的集体智慧中，这些领域的可以被感兴趣的人检索到。写开源代码正如写博客一样，是件很cool的事情。在互联网的时代，我们不必把所有的心得，领悟，落于纸上，收藏在厚重的笔记中，而是变成可以分享传播的数据。互联网是印刷术般对于历史进程有着革命性影响的东西，这个道理是不言自明的。</p><p>去年圣诞节，著名的开源ui，antdesign因为彩蛋翻车了。。 这件事情又让我对开源又了新的认识。就是github不仅仅是behance，这仅仅是他的展示的分享的属性的。但其实最最重要的，是程序，是代码的发布平台。成熟的开源项目，是产品，「是产品，就要对用户负责」。对于产品级别的开源项目，我们要有足够的敬畏，如果用户因为我们的无谓随意，业余和失误，而造成损失，那么这个产品就是失败的。这无关开不开源，只是开源意味着公益，意味着免费，但公益和免费，并不意味着质量低下。很多人认为，开源的软件产品不如商业产品，这个说法不对，应该是，开源产品中好的比例远远低于商业产品。毕竟因为没有利益的保障。但是因为用户群是如此之广，优秀的开源软件，生命力和质量往往无可匹敌。所以理论上，其实成熟的开源产品质量是不错的。antd的问题是，少部分owner并没有质量的意识，这个问题别的开发者也看到了，但项目写的怎么样，准备怎么搞，话语权都是在owener里的，这同时决定了质量。而具体的问题最后也会反过来形成反馈的机制，这和商业软件并无二致。只是这个antd太过出名，自然是轩然大波。</p><p>最后我想说的是，我们几乎都是开源软件的受益者，记得要饮水思源。公司的项目主要是在一个著名的开源项目上进行定制的，虽然我们经常吐槽这个库的质量，但当我们发现新的缺陷都会尽快的提出issues和pr，帮助开发者进行解决。我们也会提出设计上的建议。我自己使用的一些库，当缺少了我想要的功能，热心的开发者竟然很快的加入了实现。伟大的软件就是这样建造出来的，能参与其中是件美妙的事情。不过去年，一些来自我国的低素质软件开发者在deno的仓库中随意调侃和发泄，这种事情是很不光彩的。如果你没有资格讲话，就应该闭嘴，如果不能添砖加瓦，就别浪费别人的时间。</p><p>都是一些很简单的道理，希望你能和我一样，热爱软件开发，乐于分享，乐于付出和收获，和我一起参与到 构建 自由开放优秀软件的 美好事业中来。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;GitHub是我使用的最频繁的网站之一，我有几个属于自己的长期经营的开源项目，在这些项目上工作了很多时间。我也向著名的大型项目提交过pr，有些也成功合并了。我是一个开源爱好者。&lt;/p&gt;&lt;p&gt;早些时候，我喜欢将自己写的代码公开出来出于很简单的理由：我写的程序是我的作品，我想要
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>设计工具的框选实现</title>
    <link href="http://mikialex.github.io/2019/06/04/cpu-area-pick/"/>
    <id>http://mikialex.github.io/2019/06/04/cpu-area-pick/</id>
    <published>2019-06-03T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.627Z</updated>
    
    <content type="html"><![CDATA[<p>做设计的朋友们对设计软件中的框选是非常熟悉的。整理一下最近在产品中调研的cpu框选的技术实现。</p><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>所谓框选，就是用户交互式的拖出一个屏幕上的矩形区域用来选择场景对象。这里根据不同的业务存在几种不同的需求：</p><p>比如：遮挡情况：是否需要只选中最前面的物体，而排除那些完全被遮挡住的物体， 还是即便是被完全遮挡住的物体也要选中？ 某些在空间上完全处于被遮挡的情况，在某些渲染模式下（比如线框），被遮挡的物体依然完全可见，这种情况下又如何处理？某些情况下，物体没有被完全遮挡，只有一个像素暴露在外，甚至因为渲染的原因，只有半个像素糊在边界上，这种情况用户似乎又不是需要选中的，那实现上又如何应该处理呢？ 当我们实现点选，选择最前面的，是很好实现和分辨的，因为总归是一个ray的事情，而对于框选来说，遮挡/最前面，从实现的角度而言，这个需求就显得复杂和含糊。从我过去作为一个设计出身的经历而言，我已经很适应在一个mesh上框出一堆face，但是反面也会被框住的事情。事实上因为这些种种的原因，这设计软件中，灵巧的调整各种视图，使用不同的工具，快速的选中需要的东西其实也是关于生产力的技巧。</p><p>又比如：相交还是包含？ 相交是指框选框和物体相接触就认为选中，包含是指框选框完整包含物体才认为选中。设计软件一般这两种模式都会提供，某些情况下，使用相交会使得选择变得容易，不过又容易多选，在我看来是更符合我的直觉的，当然，这其实是使用习惯上的分别</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>在不考虑遮挡关系，考虑如何实现一个cpu版的框选。</p><p>由于我们的实现是在threejs的基础上，three的场景数据种类比较丰富，对象的类型mesh？ line？ points？几何的类型，Geometry？ BufferGeometry？ BufferGeometry里有没有index， Material是array还是一个，Attributes是interleaved怎么办？各种事情导致code写起来非常复杂。three也没有提供一个简单的针对drawable的东西foreach primitive的通用方法，这些因素归结于codebase提供的复杂性我们不必深究。 核心还是mesh， line， points三种不同的primitive的讨论。</p><p>通过屏幕空间范围和相机的参数，可以确定出一个世界空间的frustum。</p><p>bounding的提前退出：如果一个物体的bounding完全处于这个frustum之外，那么肯定是选不中的，提前退出。 如果一个物体的bounding完全处于这个frustum之内，在包含模式下，肯定是选中了，提前退出。这里需要额外考虑，bounding需要使用数据的，而不是渲染的，因为shadow之类的会产生影响。</p><p>如果frustum和box相交，那么计算就变得额外的多，简而言之：</p><p>相交模式：foreach primitive，依次测试和frustum是否相交， 相交则提前退出，该物体框选成功。否则失败。<br>包含模式：foreach primitive，依次测试和frustum是否包含， 不包含则提前退出，该物体框选不成功。否则成功。<br>以上的 primitive 需要根据情况做面序剔除。</p><p>在使用BVH的情况下，利用空间结构我们可以做更多的提前退出：</p><p>相交模式：traverse bvh tree每一个tree节点， 如果node被frustum contain，且该node的所有的pimitives中至少有一个可见，则bvh提前退出框选成功。<br>包含模式：traverse bvh tree每一个tree节点， 如果node被frustum contain，那么此node被剪枝。</p><p>性能评估：</p><p>框选的成本比点选高很多，估计可能在5-10倍。contain模式可能开销会高。</p><p>frustum有6个面要判断。每个面和primitive和位置关系判断似乎都比ray要开销高。需要深入进入mesh内进行判断的情况也比raycast多很多。</p><p>其他社区实现或者讨论：</p><p>有用的：</p><p><a href="https://cesiumjs.org/Cesium/Build/Documentation/Scene.html#pick" target="_blank" rel="noopener">https://cesiumjs.org/Cesium/Build/Documentation/Scene.html#pick</a></p><p><a href="https://cesiumjs.org/Cesium/Build/Documentation/Scene.html#drillPick" target="_blank" rel="noopener">https://cesiumjs.org/Cesium/Build/Documentation/Scene.html#drillPick</a></p><p><a href="https://github.com/AnalyticalGraphicsInc/cesium/blob/1.57/Source/Scene/PickFramebuffer.js" target="_blank" rel="noopener">https://github.com/AnalyticalGraphicsInc/cesium/blob/1.57/Source/Scene/PickFramebuffer.js</a></p><p>cesium主要是应该gpu实现的， gpu做不到遮挡后面的pick</p><p>osg intersector, 抽象了普通的多面体求交， 使用kd tree</p><p><a href="https://github.com/openscenegraph/OpenSceneGraph/blob/master/src/osgUtil/PolytopeIntersector.cpp" target="_blank" rel="noopener">https://github.com/openscenegraph/OpenSceneGraph/blob/master/src/osgUtil/PolytopeIntersector.cpp</a></p><p>其他：</p><p><a href="https://github.com/mrdoob/three.js/issues/1826" target="_blank" rel="noopener">https://github.com/mrdoob/three.js/issues/1826</a></p><p><a href="https://github.com/vasturiano/react-force-graph/issues/43" target="_blank" rel="noopener">https://github.com/vasturiano/react-force-graph/issues/43</a> 2d的，简单，没有太多可比性</p><p><a href="http://output.jsbin.com/tamoce/3/" target="_blank" rel="noopener">http://output.jsbin.com/tamoce/3/</a> three的，实现不是很正确？</p><p><a href="https://community.khronos.org/t/intersecting-a-3d-segment-with-perspective-frustum/59537/3" target="_blank" rel="noopener">https://community.khronos.org/t/intersecting-a-3d-segment-with-perspective-frustum/59537/3</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;做设计的朋友们对设计软件中的框选是非常熟悉的。整理一下最近在产品中调研的cpu框选的技术实现。&lt;/p&gt;&lt;h2 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h2&gt;&lt;p&gt;所谓框选，就是用户交互式的拖出一
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>WebAssembly 3D 场景树加速原型验证</title>
    <link href="http://mikialex.github.io/2019/04/30/wasm-scene/"/>
    <id>http://mikialex.github.io/2019/04/30/wasm-scene/</id>
    <published>2019-04-29T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.631Z</updated>
    
    <content type="html"><![CDATA[<p>继上次 「WebAssembly零拷贝批量数据交换和计算」 一文中的想法，我在我的webgl引擎项目中进行了初步实践。相应的代码可以在 <a href="https://github.com/mikialex/artgl" target="_blank" rel="noopener">artgl</a> 中找到。基本验证了上次的设想（使用wasm加速渲染数据生成更新并batch drawcall）是可行的。</p><h2 id="TLDR"><a href="#TLDR" class="headerlink" title="TLDR"></a>TLDR</h2><p>主要实现了一些基本的场景数据和渲染数据存储在wasm 的memory中，场景节点提供普通的 js api。</p><p><strong>实测使用6层6叉的超大场景树，约6w节点，全部计算更新世界矩阵，耗时是threejs的不到一半。</strong>（～6ms ／ ～14ms）</p><p>这基本证明了其性能优势是无法忽视的。</p><p>local矩阵的更新，世界bounding信息的更新，以及这些的按需行为，视锥剔除 细节剔除 drawcall排序 基数排序 这些将在后续完成实现</p><h2 id="基本设计"><a href="#基本设计" class="headerlink" title="基本设计"></a>基本设计</h2><p>scene对象负责管理用户描述场景的sceneNode节点，以及渲染数据的更新。</p><p>实际的数据存储在多个float32array／ int32array 中，这些array的视图建立在wasm内存arraybuffer上，初始化和扩容时调用scene对应的wasmscene的扩容方法，完成wasm内的扩容，返回这些array的ptr，用以更新typearray的视图。sceneNode上的场景数据，会以getter和setter的形式直接访问wasm内存中的数据。例如用户设置了某个节点的position， 数据会直接通过typedarray写入wasm内存中。</p><p>比如目前就已经实现了下列数据的包装：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">local_transform_array: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">local_position_array: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">local_rotation_array: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">local_scale_array: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">world_transform_array: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;，</span><br><span class="line"></span><br><span class="line">local_aabb_array: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">world_aabb_array: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">local_bsphere_array: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">world_bsphere_array: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line"></span><br><span class="line">empty_array: <span class="built_in">Vec</span>&lt;<span class="built_in">u8</span>&gt;,</span><br><span class="line">empty_list_array: <span class="built_in">Vec</span>&lt;<span class="built_in">u16</span>&gt;,</span><br><span class="line">empty_count: <span class="built_in">u16</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// [parent, left brother, right brother, first child]</span></span><br><span class="line">nodes_indexs: <span class="built_in">Vec</span>&lt;<span class="built_in">i32</span>&gt;,</span><br></pre></td></tr></table></figure><p>为了实现将tree存储于array中，tree的children使用双链表实现，每一个node存储前后一个兄弟，父亲，第一个child的索引位置。由于用户几乎没有随机访问某一个节点的children的需求，查询操作基本不受影响。sceneNode的js api 暴露add和remove方法会自动维护相关的索引。</p><p>empty_array和empty_list_array用以做标记删除</p><p>在后续会加入：</p><p>一个uint32的array使用位信息来表示每一个数据的change情况用以按需优化。</p><p>一个f32表示距离，一个f32表示屏幕投影大小。 一个uint32表示gl状态，包括shader／blend／culling ／visibility。这些可以组合起来做基数排序。</p><p>每次渲染时，scene通知wasmscene batch drawcall， 在wasm中完成所有计算，生成一个index list ，返回这个result indexlist的ptr和count， 然后js renderer加个接口直接读取就可以。 另外可以考虑的是直接使用wasm webgl的bindgen 这方面没有了解，可能需要调研和测试。</p><h2 id="遇到的坑·已知风险·考虑："><a href="#遇到的坑·已知风险·考虑：" class="headerlink" title="遇到的坑·已知风险·考虑："></a>遇到的坑·已知风险·考虑：</h2><p>wasm 的部分在chrome pref测量会导致性能问题。对实际运行无影响。</p><p>rust要开o3编译。</p><p>需要考虑asmjs的fallback，uc qq浏览器支持不好。</p><p>wasm scene和其他的比如three的scene有一个区别是，sceneNode 有attach状态并且只能属于一个scene，这个可能会引起上层设计改动。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;继上次 「WebAssembly零拷贝批量数据交换和计算」 一文中的想法，我在我的webgl引擎项目中进行了初步实践。相应的代码可以在 &lt;a href=&quot;https://github.com/mikialex/artgl&quot; target=&quot;_blank&quot; rel=&quot;noop
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>WebAssembly零拷贝批量数据交换和计算</title>
    <link href="http://mikialex.github.io/2019/03/28/wasm-memory-as-data-container/"/>
    <id>http://mikialex.github.io/2019/03/28/wasm-memory-as-data-container/</id>
    <published>2019-03-27T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.630Z</updated>
    
    <content type="html"><![CDATA[<p>最近在尝试将wasm用以webgl渲染引擎加速，有2个问题比较担心，1是据说js call wasm overhead很高，难以做函数级别的优化，最好批量处理，虽然mozila后来优化了相关问题，但是目前还没有bench过，包括其他浏览器也不是很确定，2是担心批量处理，需要从js端copy数据，再copy回来，这个开销比较难受。所以做了一翻调研。</p><p>假设我有一个很大的array需要传给webassembly，wasm-bindgen 可以生成 number slice的<a href="https://rustwasm.github.io/docs/wasm-bindgen/reference/types/number-slices.html" target="_blank" rel="noopener">接口</a>, 大概类似这样：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">take_number_slice_by_shared_ref(<span class="keyword">new</span> <span class="built_in">Float64Array</span>(<span class="number">100</span>));</span><br><span class="line">take_number_slice_by_exclusive_ref(<span class="keyword">new</span> <span class="built_in">Uint8Array</span>(<span class="number">100</span>));</span><br></pre></td></tr></table></figure><p>大致是用户需要new一个typedarray来作为输入，需要在js端完成一次copy，临时内存分配和销毁带来的overhead并不合理，所以wasm能够真正应用得当需要寻找更合理的方式</p><p><a href="https://github.com/rustwasm/wasm-bindgen/issues/270" target="_blank" rel="noopener">这个issue</a>，以及<a href="https://stackoverflow.com/questions/41875728/pass-a-javascript-array-as-argument-to-a-webassembly-function" target="_blank" rel="noopener">这个</a> 看到比较合理的从js端传送批量数据到webassembly进行处理的方案。</p><p>大致流程是：</p><p>1 调用wasm的方法，在wasm内存中分配空间，返回指针位置<br>2 js端在wasm的memory arraybuffer上，按指针位置和数据量建立view，把数据写入<br>3 调用wasm方法完成计算， 返回计算好的批量结果的指针位置和大小<br>4 js端在wasm的memory arraybuffer上，按指针位置和数据量建立view，把数据读出</p><p>主要情况是： wasm模块会有一个线性的内存，js端看就是一个arraybuffer，js端可以自由的读写。所以批量的数据写入可以通过直接在这个memory的arraybuffer上建立view来实现。甚至说，<strong>我们可以直接将wasm的memory当作js部分的紧凑数据容器</strong>，某些批量的数据处理和计算，可以直接调用wasm的方法来实现，js端可以直接在结果的读容器中获得。</p><p>在 rust 的webassembly的官方 game of life 的例子中我们可以看到这个<a href="https://rustwasm.github.io/docs/book/game-of-life/implementing.html" target="_blank" rel="noopener">实现</a>, 直接访问wasm memory的数据</p><p>我自己测试了一下这种使用模式，似乎没有什么问题</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[wasm_bindgen]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="class"><span class="keyword">struct</span> <span class="title">Batcher</span></span> &#123;</span><br><span class="line">    data: <span class="built_in">Vec</span>&lt;<span class="built_in">f32</span>&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[wasm_bindgen]</span></span><br><span class="line"><span class="keyword">impl</span> Batcher &#123;</span><br><span class="line">    <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">new</span></span>() -&gt; Batcher&#123;</span><br><span class="line">        Batcher &#123;</span><br><span class="line">            data:<span class="built_in">Vec</span>::with_capacity(<span class="number">100</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">allocate</span></span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, capacity: <span class="built_in">u32</span>) -&gt; *<span class="keyword">const</span> <span class="built_in">f32</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.data = <span class="built_in">vec!</span>[<span class="number">0.0</span>; capacity <span class="keyword">as</span> <span class="built_in">usize</span>];</span><br><span class="line">        <span class="keyword">self</span>.data.as_ptr()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pub</span> <span class="function"><span class="keyword">fn</span> <span class="title">batch</span></span>(&amp;<span class="keyword">self</span>, batchLength: <span class="built_in">u32</span>)&#123;</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> &amp;<span class="keyword">self</span>.data &#123;</span><br><span class="line">            log_f32(*d);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> dataLength = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">const</span> batcher = wasm.Batcher.new();</span><br><span class="line"><span class="built_in">console</span>.log(batcher)</span><br><span class="line"><span class="keyword">const</span> ptr = batcher.allocate(dataLength);</span><br><span class="line"><span class="keyword">const</span> dataview = <span class="keyword">new</span> <span class="built_in">Float32Array</span>(memory.buffer, ptr, dataLength);</span><br><span class="line"></span><br><span class="line">dataview[<span class="number">0</span>] = <span class="number">1.5</span>;</span><br><span class="line">dataview[<span class="number">1</span>] = <span class="number">2</span>;</span><br><span class="line">dataview[<span class="number">2</span>] = <span class="number">3</span>;</span><br><span class="line">dataview[<span class="number">3</span>] = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">batcher.batch(<span class="number">5</span>);</span><br></pre></td></tr></table></figure><p>这个原型大致可以推测出一种使用wasm memory作为数据容器以实现前端零拷贝高性能计算的模式： 将wasm的memory直接存储js数据。当然，我们在不考虑性能的情况下可以wrap一群js对象，通过getter setter，或者其他数据同步的设施，使得用户可以直接操作普通对象的方式操作wasm中的数据。在某些情况下，wasm可以直接对存储的数据进行重计算的操作，然后零拷贝的暴露出计算结果。这可能是wasm用法的一个比较好的实践。</p><p>实际的应用其实渲染引擎的确可以作为不错的尝试的例子，场景树，节点的js对象直接读写数据到wasm中，在每一帧渲染时，wasm模块自身负责高性能的渲染数据生成／同步，包括优化，排序，最后的renderlist直接暴露在memory中，js外层再一个batch读结果，完成gl调用。 在这个过程中js和wasm之间0数据拷贝，最小化直接交互调用，似乎没什么问题。</p><p>by the way, rust相关的wasm工具链包括rust自身的使用体验非常优秀。值得推荐。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近在尝试将wasm用以webgl渲染引擎加速，有2个问题比较担心，1是据说js call wasm overhead很高，难以做函数级别的优化，最好批量处理，虽然mozila后来优化了相关问题，但是目前还没有bench过，包括其他浏览器也不是很确定，2是担心批量处理，需要
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Artgl，a webgl framework</title>
    <link href="http://mikialex.github.io/2019/03/12/artgl-about/"/>
    <id>http://mikialex.github.io/2019/03/12/artgl-about/</id>
    <published>2019-03-11T16:00:00.000Z</published>
    <updated>2020-08-23T07:00:50.626Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关于ARTGL"><a href="#关于ARTGL" class="headerlink" title="关于ARTGL"></a>关于ARTGL</h1><p>自2018四月以来从事web端图形渲染的相关工作以来，ARTGL一直作为我个人学习webgl渲染的side project，一直作为一个实践想法和探索的平台。今日，项目整体的设计已经初具雏形，在渲染引擎的整体设计方面也有了一些自己的积累。借此稍作整理。</p><h2 id="想要解决的问题和创新？"><a href="#想要解决的问题和创新？" class="headerlink" title="想要解决的问题和创新？"></a>想要解决的问题和创新？</h2><p>最早我在我的个人网站的主页想做一个很简单的3d特效，使用threejs导致前端的js文件尺寸暴涨，而three内部据说由于大量使用 Object.defineproperties 等方法修改和扩展对象，导致无论对编译配置做出怎样的调整都无法实现tree shaking优化。而我也没有意愿寻找其他简单的webgl库。这反映一个问题是，three类型的webgl库，默认包含了过多我们根本不需要的东西，数学库可以全一点，这个没有问题，但那么多其他的Geometry， Material，Loader，等等我根本不需要，很多像动画/压缩纹理支持 等等，我都不需要，但是我却很难搞掉它们。</p><p>所以我希望一个好的webgl封装， 应该只提供最小最核心的实现，而那些各种各样的material ，light， geometry，应该能够非常方便的让用户自己扩展实现，或者引入独立的外部资源库，不会有多余的东西。我不希望我的项目里有一大堆的code是根本没有用的，虽然理论上我可以不care这些。</p><p>所以： <strong>要充分隔离资源类型的支持和资源实现本身，一方面要做到用户能够清楚的方便的自己扩展和实现</strong>， 另一方面，应当<strong>仅提供最小化的核心实现， 并能够将资源的实现以最小粒度library化，</strong> 说的简单一点就是，material ，light， geometry这种东西，也不说其他更高级的，应当做成独立的库，并且用户很容易扩展出自己的东西，不要一堆的都塞到我手里。</p><p>关于资源的library化，还很好做，主要的挑战在于：用户能够清楚的方便的自己扩展和实现。一方面这是引擎定位的考虑，比如three这个库，易于使用却不易扩展：当你的需求超出了他能支持的范围一点点，你就要开始看上万行源码，投身到webgl渲染的学习中来，然后fork改代码。库的作者并没有很好的整理封装了这么哪些概念，以及更重要的如何自由的扩展和实现你自己的东西，然后在已有的体系下完美运作。但如果真的能做到这样那岂不是更好。</p><p>另一方面，我想尝试的是诸多架构上的改进： <strong>目前市面上大多数的webgl封装， 都是webgl库，并不是框架。 使用库，我可以完成我的工作我的目的，但是这个世界上每一个人每一家企业，每一个项目，都有不同的需求。</strong> 当然，如果你不得不说要仅仅完成任务，那么大可不必如此追求。但我认为是时候要在架构上做出反思，打造出更好的东西出来。</p><p>关于framework， 一个是要<strong>做好分层的设计，webgl渲染层，webgl数据层，渲染数据层， 场景数据层，渲染策略层，各个层面要做好充分的隔离</strong>，甚至使得用户可以做到替换自定义实现，去除顶层抽象简化项目等目的。</p><p>为什么要自定义实现？ 举例说，场景数据层面，有的项目，场景树的设计完全是多余的，那么场景数据的组织是不是可以换成其他更简单的实现？ 或者另一个极端的例子，如果层与层之间的接口设计的很清楚，那么我理论上可以用canvas2d作为我的renderapi。</p><p>去除顶层抽象则是简化实现的考虑，举例说假设用户只要用webgl做一个shader的特效，那么用户其实只要引入webgl渲染层一个层的实现，gl的数据就几个自己处理，就非常的简洁轻量高效。或者仅仅单纯就是渲染一堆的东西，不想添加任何复杂的后处理，或者优化逻辑，那么渲染策略层也是可以忽略的东西。</p><p>关于framework， 另一个设计主要关于最顶层的渲染策略层。我们绝大多数看到的webgl库，都是把整个渲染流程，包括后处理的流程，全部用代码hardcode出来的，对外只暴露若干接口用以配置。这其实是极度缺乏设计和抽象的。正确的设计是<strong>暴露一套描述渲染流程，优化策略的接口，使得用户可以使用这些轻松的构建自己的动态渲染管线</strong> ，用户再以此封装出自己的配置项。或者说，用户可以使用此接口，设计出多种渲染管线，封装出多种viewer， 以支持不同场景的优化和使用需求。</p><p>关于这一点，是我非常兴奋的一处创新，在我公司项目的实践中，真的是深深感受到，渲染流程缺乏合理抽象的巨大缺陷。无论是代码质量，调试难度，创新原型，效果调优，通过合理的架构设计其实可以通过好的框架设计，全方位的解决问题并提高效率。而目前基于rendergraph的方案，已经经过TAA多pass的实践，取得了很好的成果。</p><p>总结下来，<strong>ARTGL将提供 清晰的多层的webgl渲染基础设施，每一层都会针对具体的资源高度支持用户的定制和扩展，以最合理的方式，配合高度定制化的可扩展性，支持最广泛用户群体的不同应用场景。</strong></p><h2 id="milestone-和-release-计划？"><a href="#milestone-和-release-计划？" class="headerlink" title="milestone 和 release 计划？"></a>milestone 和 release 计划？</h2><p>受制于我的业余时间，和考虑到接口稳定性，我预计会在今年年底完成第一个稳定api的release版本，其中包含：基本webgl底层支持， 基本的资源抽象定义，场景树，rendergraph， 并基于此架构实现一个包含复杂后处理和复杂优化逻辑的viewer。由于使用了typescript 所以代码的重构和优化非常频繁和自信，api的接口变动非常频繁。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;关于ARTGL&quot;&gt;&lt;a href=&quot;#关于ARTGL&quot; class=&quot;headerlink&quot; title=&quot;关于ARTGL&quot;&gt;&lt;/a&gt;关于ARTGL&lt;/h1&gt;&lt;p&gt;自2018四月以来从事web端图形渲染的相关工作以来，ARTGL一直作为我个人学习webgl渲染的s
      
    
    </summary>
    
    
  </entry>
  
</feed>
